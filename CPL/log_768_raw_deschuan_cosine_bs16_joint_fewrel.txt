#############params############
cuda
Task=FewRel, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/train.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/valid.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0]
Losses:  11.790603637695312 1.7594553232192993
CurrentTrain: epoch  0, batch     0 | loss: 13.5500593Losses:  13.682466506958008 2.0315165519714355
CurrentTrain: epoch  0, batch     1 | loss: 15.7139835Losses:  14.034322738647461 1.702423334121704
CurrentTrain: epoch  0, batch     2 | loss: 15.7367458Losses:  13.648759841918945 1.7143104076385498
CurrentTrain: epoch  0, batch     3 | loss: 15.3630705Losses:  13.654373168945312 1.594337821006775
CurrentTrain: epoch  0, batch     4 | loss: 15.2487106Losses:  13.979019165039062 1.345777988433838
CurrentTrain: epoch  0, batch     5 | loss: 15.3247967Losses:  13.331493377685547 1.6575284004211426
CurrentTrain: epoch  0, batch     6 | loss: 14.9890213Losses:  13.278135299682617 1.5257227420806885
CurrentTrain: epoch  0, batch     7 | loss: 14.8038578Losses:  13.099559783935547 1.4815958738327026
CurrentTrain: epoch  0, batch     8 | loss: 14.5811558Losses:  13.093423843383789 1.6073386669158936
CurrentTrain: epoch  0, batch     9 | loss: 14.7007627Losses:  12.877452850341797 1.4994263648986816
CurrentTrain: epoch  0, batch    10 | loss: 14.3768787Losses:  12.462100982666016 1.1915364265441895
CurrentTrain: epoch  0, batch    11 | loss: 13.6536369Losses:  12.46331787109375 1.5705676078796387
CurrentTrain: epoch  0, batch    12 | loss: 14.0338860Losses:  12.353076934814453 1.485105276107788
CurrentTrain: epoch  0, batch    13 | loss: 13.8381824Losses:  11.808126449584961 1.4098190069198608
CurrentTrain: epoch  0, batch    14 | loss: 13.2179451Losses:  12.27126407623291 1.9499590396881104
CurrentTrain: epoch  0, batch    15 | loss: 14.2212229Losses:  11.936487197875977 1.4389901161193848
CurrentTrain: epoch  0, batch    16 | loss: 13.3754768Losses:  12.261301040649414 1.9599578380584717
CurrentTrain: epoch  0, batch    17 | loss: 14.2212591Losses:  12.395072937011719 1.674590826034546
CurrentTrain: epoch  0, batch    18 | loss: 14.0696640Losses:  11.875862121582031 1.8036457300186157
CurrentTrain: epoch  0, batch    19 | loss: 13.6795082Losses:  11.566125869750977 1.3249311447143555
CurrentTrain: epoch  0, batch    20 | loss: 12.8910570Losses:  11.541086196899414 1.5817079544067383
CurrentTrain: epoch  0, batch    21 | loss: 13.1227942Losses:  11.282257080078125 1.4965643882751465
CurrentTrain: epoch  0, batch    22 | loss: 12.7788219Losses:  10.592658996582031 1.0834293365478516
CurrentTrain: epoch  0, batch    23 | loss: 11.6760883Losses:  10.89211368560791 1.369812250137329
CurrentTrain: epoch  0, batch    24 | loss: 12.2619257Losses:  10.621260643005371 1.2400144338607788
CurrentTrain: epoch  0, batch    25 | loss: 11.8612747Losses:  10.67090129852295 1.1606827974319458
CurrentTrain: epoch  0, batch    26 | loss: 11.8315840Losses:  10.250312805175781 1.2553417682647705
CurrentTrain: epoch  0, batch    27 | loss: 11.5056543Losses:  10.35694408416748 1.2594647407531738
CurrentTrain: epoch  0, batch    28 | loss: 11.6164093Losses:  9.981945037841797 1.220753788948059
CurrentTrain: epoch  0, batch    29 | loss: 11.2026987Losses:  10.106027603149414 1.305058479309082
CurrentTrain: epoch  0, batch    30 | loss: 11.4110861Losses:  9.845255851745605 1.0697214603424072
CurrentTrain: epoch  0, batch    31 | loss: 10.9149771Losses:  9.930680274963379 0.982740044593811
CurrentTrain: epoch  0, batch    32 | loss: 10.9134207Losses:  10.008277893066406 1.0285639762878418
CurrentTrain: epoch  0, batch    33 | loss: 11.0368423Losses:  9.65690803527832 1.21815025806427
CurrentTrain: epoch  0, batch    34 | loss: 10.8750582Losses:  9.431595802307129 1.268465280532837
CurrentTrain: epoch  0, batch    35 | loss: 10.7000608Losses:  9.753740310668945 1.312032699584961
CurrentTrain: epoch  0, batch    36 | loss: 11.0657730Losses:  9.104009628295898 1.1503500938415527
CurrentTrain: epoch  0, batch    37 | loss: 10.2543602Losses:  9.760576248168945 1.3568493127822876
CurrentTrain: epoch  0, batch    38 | loss: 11.1174259Losses:  9.266861915588379 1.3399916887283325
CurrentTrain: epoch  0, batch    39 | loss: 10.6068535Losses:  9.206745147705078 1.3089148998260498
CurrentTrain: epoch  0, batch    40 | loss: 10.5156603Losses:  8.851737022399902 1.0859079360961914
CurrentTrain: epoch  0, batch    41 | loss: 9.9376450Losses:  8.549545288085938 0.9866769313812256
CurrentTrain: epoch  0, batch    42 | loss: 9.5362225Losses:  8.542085647583008 0.8060406446456909
CurrentTrain: epoch  0, batch    43 | loss: 9.3481264Losses:  8.335978507995605 0.9883715510368347
CurrentTrain: epoch  0, batch    44 | loss: 9.3243504Losses:  8.006866455078125 1.1901606321334839
CurrentTrain: epoch  0, batch    45 | loss: 9.1970272Losses:  8.594583511352539 0.933395266532898
CurrentTrain: epoch  0, batch    46 | loss: 9.5279789Losses:  7.5698323249816895 0.9873981475830078
CurrentTrain: epoch  0, batch    47 | loss: 8.5572300Losses:  8.159524917602539 1.104015827178955
CurrentTrain: epoch  0, batch    48 | loss: 9.2635403Losses:  7.685914039611816 1.1043095588684082
CurrentTrain: epoch  0, batch    49 | loss: 8.7902241Losses:  7.787552833557129 1.0672043561935425
CurrentTrain: epoch  0, batch    50 | loss: 8.8547573Losses:  7.388337135314941 1.00850510597229
CurrentTrain: epoch  0, batch    51 | loss: 8.3968420Losses:  7.413851261138916 0.9967650175094604
CurrentTrain: epoch  0, batch    52 | loss: 8.4106159Losses:  7.3802385330200195 0.937433660030365
CurrentTrain: epoch  0, batch    53 | loss: 8.3176718Losses:  7.4262919425964355 1.2549917697906494
CurrentTrain: epoch  0, batch    54 | loss: 8.6812840Losses:  6.873319625854492 0.8858728408813477
CurrentTrain: epoch  0, batch    55 | loss: 7.7591925Losses:  6.594416618347168 0.8762006163597107
CurrentTrain: epoch  0, batch    56 | loss: 7.4706173Losses:  6.83458137512207 1.0122411251068115
CurrentTrain: epoch  0, batch    57 | loss: 7.8468227Losses:  6.390944480895996 0.8524683713912964
CurrentTrain: epoch  0, batch    58 | loss: 7.2434130Losses:  6.837586879730225 0.7620159387588501
CurrentTrain: epoch  0, batch    59 | loss: 7.5996027Losses:  5.958681106567383 0.7564908862113953
CurrentTrain: epoch  0, batch    60 | loss: 6.7151718Losses:  6.46633768081665 0.7285090684890747
CurrentTrain: epoch  0, batch    61 | loss: 7.1948466Losses:  7.214729309082031 0.9381710290908813
CurrentTrain: epoch  0, batch    62 | loss: 8.1529007Losses:  6.252416610717773 0.8670048713684082
CurrentTrain: epoch  1, batch     0 | loss: 7.1194215Losses:  5.7955217361450195 0.7113893032073975
CurrentTrain: epoch  1, batch     1 | loss: 6.5069113Losses:  5.992944717407227 0.7808797359466553
CurrentTrain: epoch  1, batch     2 | loss: 6.7738247Losses:  5.785682201385498 0.8321069478988647
CurrentTrain: epoch  1, batch     3 | loss: 6.6177893Losses:  6.3654985427856445 1.098475694656372
CurrentTrain: epoch  1, batch     4 | loss: 7.4639740Losses:  5.7143025398254395 0.7327515482902527
CurrentTrain: epoch  1, batch     5 | loss: 6.4470539Losses:  5.7114081382751465 0.6788333654403687
CurrentTrain: epoch  1, batch     6 | loss: 6.3902416Losses:  5.544033050537109 0.6922463178634644
CurrentTrain: epoch  1, batch     7 | loss: 6.2362795Losses:  5.558575630187988 0.62508225440979
CurrentTrain: epoch  1, batch     8 | loss: 6.1836576Losses:  5.852944374084473 0.8411304354667664
CurrentTrain: epoch  1, batch     9 | loss: 6.6940746Losses:  5.938150405883789 0.8914943933486938
CurrentTrain: epoch  1, batch    10 | loss: 6.8296447Losses:  5.764688491821289 0.7577188014984131
CurrentTrain: epoch  1, batch    11 | loss: 6.5224075Losses:  5.929907321929932 0.8981533050537109
CurrentTrain: epoch  1, batch    12 | loss: 6.8280606Losses:  6.168447971343994 0.6856001615524292
CurrentTrain: epoch  1, batch    13 | loss: 6.8540483Losses:  5.603470802307129 0.7425236701965332
CurrentTrain: epoch  1, batch    14 | loss: 6.3459945Losses:  6.3109331130981445 0.9242535829544067
CurrentTrain: epoch  1, batch    15 | loss: 7.2351866Losses:  5.921636581420898 0.6205123662948608
CurrentTrain: epoch  1, batch    16 | loss: 6.5421491Losses:  5.379992485046387 0.4948118329048157
CurrentTrain: epoch  1, batch    17 | loss: 5.8748045Losses:  5.598435401916504 0.6244919300079346
CurrentTrain: epoch  1, batch    18 | loss: 6.2229271Losses:  5.595221519470215 0.5605360269546509
CurrentTrain: epoch  1, batch    19 | loss: 6.1557574Losses:  5.894783020019531 0.8090085983276367
CurrentTrain: epoch  1, batch    20 | loss: 6.7037916Losses:  5.841619491577148 0.6852920651435852
CurrentTrain: epoch  1, batch    21 | loss: 6.5269117Losses:  5.583704471588135 0.6933430433273315
CurrentTrain: epoch  1, batch    22 | loss: 6.2770476Losses:  5.923163414001465 0.5746089816093445
CurrentTrain: epoch  1, batch    23 | loss: 6.4977722Losses:  5.7950897216796875 0.6708730459213257
CurrentTrain: epoch  1, batch    24 | loss: 6.4659629Losses:  5.218391418457031 0.5634535551071167
CurrentTrain: epoch  1, batch    25 | loss: 5.7818451Losses:  5.5377326011657715 0.682655930519104
CurrentTrain: epoch  1, batch    26 | loss: 6.2203884Losses:  5.557980537414551 0.6650377511978149
CurrentTrain: epoch  1, batch    27 | loss: 6.2230182Losses:  5.411910057067871 0.5938494801521301
CurrentTrain: epoch  1, batch    28 | loss: 6.0057597Losses:  5.276311874389648 0.6287234425544739
CurrentTrain: epoch  1, batch    29 | loss: 5.9050355Losses:  5.39810848236084 0.482754111289978
CurrentTrain: epoch  1, batch    30 | loss: 5.8808627Losses:  5.093801498413086 0.6298081278800964
CurrentTrain: epoch  1, batch    31 | loss: 5.7236094Losses:  5.096513748168945 0.5863481760025024
CurrentTrain: epoch  1, batch    32 | loss: 5.6828618Losses:  5.169973373413086 0.43242743611335754
CurrentTrain: epoch  1, batch    33 | loss: 5.6024008Losses:  5.576104164123535 0.7144420742988586
CurrentTrain: epoch  1, batch    34 | loss: 6.2905464Losses:  5.072144985198975 0.5208301544189453
CurrentTrain: epoch  1, batch    35 | loss: 5.5929751Losses:  5.592464923858643 0.48892539739608765
CurrentTrain: epoch  1, batch    36 | loss: 6.0813904Losses:  5.505560874938965 0.7246788144111633
CurrentTrain: epoch  1, batch    37 | loss: 6.2302399Losses:  5.6726884841918945 0.7102937698364258
CurrentTrain: epoch  1, batch    38 | loss: 6.3829823Losses:  5.04550313949585 0.5405368208885193
CurrentTrain: epoch  1, batch    39 | loss: 5.5860400Losses:  5.510761737823486 0.5849936604499817
CurrentTrain: epoch  1, batch    40 | loss: 6.0957556Losses:  5.900789737701416 0.9068843722343445
CurrentTrain: epoch  1, batch    41 | loss: 6.8076739Losses:  5.397911071777344 0.6153227090835571
CurrentTrain: epoch  1, batch    42 | loss: 6.0132337Losses:  5.679277420043945 0.5949154496192932
CurrentTrain: epoch  1, batch    43 | loss: 6.2741928Losses:  5.853238582611084 0.7475808262825012
CurrentTrain: epoch  1, batch    44 | loss: 6.6008196Losses:  5.033329010009766 0.49072501063346863
CurrentTrain: epoch  1, batch    45 | loss: 5.5240541Losses:  4.862005233764648 0.4473850429058075
CurrentTrain: epoch  1, batch    46 | loss: 5.3093901Losses:  5.439601898193359 0.712946891784668
CurrentTrain: epoch  1, batch    47 | loss: 6.1525488Losses:  5.316396236419678 0.5660512447357178
CurrentTrain: epoch  1, batch    48 | loss: 5.8824472Losses:  5.140956878662109 0.528292179107666
CurrentTrain: epoch  1, batch    49 | loss: 5.6692491Losses:  5.181567192077637 0.5447912812232971
CurrentTrain: epoch  1, batch    50 | loss: 5.7263584Losses:  5.6309309005737305 0.6206912994384766
CurrentTrain: epoch  1, batch    51 | loss: 6.2516222Losses:  5.289214611053467 0.49443185329437256
CurrentTrain: epoch  1, batch    52 | loss: 5.7836466Losses:  5.188560485839844 0.4707143008708954
CurrentTrain: epoch  1, batch    53 | loss: 5.6592746Losses:  5.323020935058594 0.5272469520568848
CurrentTrain: epoch  1, batch    54 | loss: 5.8502679Losses:  4.677272796630859 0.2962729334831238
CurrentTrain: epoch  1, batch    55 | loss: 4.9735456Losses:  4.762861251831055 0.3333193361759186
CurrentTrain: epoch  1, batch    56 | loss: 5.0961804Losses:  5.060980796813965 0.5934293270111084
CurrentTrain: epoch  1, batch    57 | loss: 5.6544104Losses:  4.887787818908691 0.410993754863739
CurrentTrain: epoch  1, batch    58 | loss: 5.2987814Losses:  5.408565044403076 0.669072151184082
CurrentTrain: epoch  1, batch    59 | loss: 6.0776372Losses:  5.127996444702148 0.6565781235694885
CurrentTrain: epoch  1, batch    60 | loss: 5.7845745Losses:  4.860248565673828 0.5808762311935425
CurrentTrain: epoch  1, batch    61 | loss: 5.4411249Losses:  4.314300060272217 0.1994340717792511
CurrentTrain: epoch  1, batch    62 | loss: 4.5137343Losses:  5.02942419052124 0.39418530464172363
CurrentTrain: epoch  2, batch     0 | loss: 5.4236097Losses:  4.970291614532471 0.44890183210372925
CurrentTrain: epoch  2, batch     1 | loss: 5.4191933Losses:  4.928603172302246 0.48899292945861816
CurrentTrain: epoch  2, batch     2 | loss: 5.4175959Losses:  4.66591739654541 0.375438928604126
CurrentTrain: epoch  2, batch     3 | loss: 5.0413561Losses:  4.891819000244141 0.37467363476753235
CurrentTrain: epoch  2, batch     4 | loss: 5.2664928Losses:  4.771476745605469 0.49651774764060974
CurrentTrain: epoch  2, batch     5 | loss: 5.2679944Losses:  4.796387672424316 0.33531051874160767
CurrentTrain: epoch  2, batch     6 | loss: 5.1316981Losses:  5.0273566246032715 0.45051541924476624
CurrentTrain: epoch  2, batch     7 | loss: 5.4778719Losses:  5.379398345947266 0.4866296052932739
CurrentTrain: epoch  2, batch     8 | loss: 5.8660278Losses:  4.564716815948486 0.26112043857574463
CurrentTrain: epoch  2, batch     9 | loss: 4.8258371Losses:  4.586234092712402 0.32453370094299316
CurrentTrain: epoch  2, batch    10 | loss: 4.9107676Losses:  5.144465446472168 0.5018446445465088
CurrentTrain: epoch  2, batch    11 | loss: 5.6463099Losses:  5.147753715515137 0.47221627831459045
CurrentTrain: epoch  2, batch    12 | loss: 5.6199698Losses:  5.14776611328125 0.5142012238502502
CurrentTrain: epoch  2, batch    13 | loss: 5.6619673Losses:  5.083804130554199 0.4941752552986145
CurrentTrain: epoch  2, batch    14 | loss: 5.5779796Losses:  4.660116195678711 0.38386908173561096
CurrentTrain: epoch  2, batch    15 | loss: 5.0439854Losses:  4.4359130859375 0.29245689511299133
CurrentTrain: epoch  2, batch    16 | loss: 4.7283702Losses:  4.353539943695068 0.17603325843811035
CurrentTrain: epoch  2, batch    17 | loss: 4.5295734Losses:  5.133001804351807 0.5158621072769165
CurrentTrain: epoch  2, batch    18 | loss: 5.6488638Losses:  4.8149518966674805 0.38296282291412354
CurrentTrain: epoch  2, batch    19 | loss: 5.1979146Losses:  4.600884437561035 0.3145334720611572
CurrentTrain: epoch  2, batch    20 | loss: 4.9154177Losses:  4.545456886291504 0.2740079164505005
CurrentTrain: epoch  2, batch    21 | loss: 4.8194647Losses:  4.47284460067749 0.32579517364501953
CurrentTrain: epoch  2, batch    22 | loss: 4.7986398Losses:  4.86517333984375 0.39119282364845276
CurrentTrain: epoch  2, batch    23 | loss: 5.2563663Losses:  4.8260498046875 0.3566156327724457
CurrentTrain: epoch  2, batch    24 | loss: 5.1826653Losses:  4.600647449493408 0.33155280351638794
CurrentTrain: epoch  2, batch    25 | loss: 4.9322004Losses:  4.555769920349121 0.31168901920318604
CurrentTrain: epoch  2, batch    26 | loss: 4.8674588Losses:  4.627155303955078 0.2466641068458557
CurrentTrain: epoch  2, batch    27 | loss: 4.8738194Losses:  4.529202461242676 0.284373939037323
CurrentTrain: epoch  2, batch    28 | loss: 4.8135762Losses:  4.606637001037598 0.374727725982666
CurrentTrain: epoch  2, batch    29 | loss: 4.9813647Losses:  4.736891269683838 0.3934090733528137
CurrentTrain: epoch  2, batch    30 | loss: 5.1303005Losses:  4.6101393699646 0.368386447429657
CurrentTrain: epoch  2, batch    31 | loss: 4.9785256Losses:  5.388802528381348 0.45435482263565063
CurrentTrain: epoch  2, batch    32 | loss: 5.8431573Losses:  4.423622131347656 0.2516437768936157
CurrentTrain: epoch  2, batch    33 | loss: 4.6752658Losses:  4.753368377685547 0.3670927882194519
CurrentTrain: epoch  2, batch    34 | loss: 5.1204610Losses:  4.875467777252197 0.31152623891830444
CurrentTrain: epoch  2, batch    35 | loss: 5.1869941Losses:  4.466617584228516 0.25054728984832764
CurrentTrain: epoch  2, batch    36 | loss: 4.7171650Losses:  4.742432594299316 0.28812408447265625
CurrentTrain: epoch  2, batch    37 | loss: 5.0305567Losses:  4.55397891998291 0.26806339621543884
CurrentTrain: epoch  2, batch    38 | loss: 4.8220425Losses:  4.27305793762207 0.16780242323875427
CurrentTrain: epoch  2, batch    39 | loss: 4.4408603Losses:  4.674473762512207 0.27448078989982605
CurrentTrain: epoch  2, batch    40 | loss: 4.9489546Losses:  5.070289611816406 0.27836310863494873
CurrentTrain: epoch  2, batch    41 | loss: 5.3486528Losses:  4.5742597579956055 0.26201778650283813
CurrentTrain: epoch  2, batch    42 | loss: 4.8362775Losses:  4.706764221191406 0.34625887870788574
CurrentTrain: epoch  2, batch    43 | loss: 5.0530233Losses:  4.470552444458008 0.3710123896598816
CurrentTrain: epoch  2, batch    44 | loss: 4.8415647Losses:  4.654720783233643 0.3572028577327728
CurrentTrain: epoch  2, batch    45 | loss: 5.0119238Losses:  4.362732887268066 0.22259557247161865
CurrentTrain: epoch  2, batch    46 | loss: 4.5853286Losses:  4.872588634490967 0.3961198031902313
CurrentTrain: epoch  2, batch    47 | loss: 5.2687082Losses:  4.4274492263793945 0.26043951511383057
CurrentTrain: epoch  2, batch    48 | loss: 4.6878886Losses:  4.558991432189941 0.3449985980987549
CurrentTrain: epoch  2, batch    49 | loss: 4.9039898Losses:  4.443699359893799 0.20952826738357544
CurrentTrain: epoch  2, batch    50 | loss: 4.6532278Losses:  4.363522529602051 0.2871580719947815
CurrentTrain: epoch  2, batch    51 | loss: 4.6506805Losses:  4.598209381103516 0.2982129454612732
CurrentTrain: epoch  2, batch    52 | loss: 4.8964224Losses:  4.401217460632324 0.3455674648284912
CurrentTrain: epoch  2, batch    53 | loss: 4.7467852Losses:  4.36752986907959 0.29024598002433777
CurrentTrain: epoch  2, batch    54 | loss: 4.6577759Losses:  4.387941360473633 0.3073815107345581
CurrentTrain: epoch  2, batch    55 | loss: 4.6953230Losses:  4.552615642547607 0.4522050619125366
CurrentTrain: epoch  2, batch    56 | loss: 5.0048208Losses:  4.6196370124816895 0.3582974076271057
CurrentTrain: epoch  2, batch    57 | loss: 4.9779344Losses:  4.41609001159668 0.27818262577056885
CurrentTrain: epoch  2, batch    58 | loss: 4.6942725Losses:  4.428468704223633 0.26200419664382935
CurrentTrain: epoch  2, batch    59 | loss: 4.6904731Losses:  4.34776496887207 0.3423769176006317
CurrentTrain: epoch  2, batch    60 | loss: 4.6901417Losses:  4.502135276794434 0.2856777608394623
CurrentTrain: epoch  2, batch    61 | loss: 4.7878132Losses:  4.303842544555664 0.14681199193000793
CurrentTrain: epoch  2, batch    62 | loss: 4.4506545Losses:  4.620965957641602 0.2934609353542328
CurrentTrain: epoch  3, batch     0 | loss: 4.9144268Losses:  4.980372428894043 0.42527616024017334
CurrentTrain: epoch  3, batch     1 | loss: 5.4056487Losses:  4.376816749572754 0.2931286692619324
CurrentTrain: epoch  3, batch     2 | loss: 4.6699452Losses:  4.4661664962768555 0.19435840845108032
CurrentTrain: epoch  3, batch     3 | loss: 4.6605248Losses:  4.4668378829956055 0.22235582768917084
CurrentTrain: epoch  3, batch     4 | loss: 4.6891937Losses:  4.37531852722168 0.22873961925506592
CurrentTrain: epoch  3, batch     5 | loss: 4.6040583Losses:  4.352190971374512 0.24606913328170776
CurrentTrain: epoch  3, batch     6 | loss: 4.5982599Losses:  4.3383684158325195 0.23947399854660034
CurrentTrain: epoch  3, batch     7 | loss: 4.5778422Losses:  4.7573699951171875 0.3547806143760681
CurrentTrain: epoch  3, batch     8 | loss: 5.1121507Losses:  4.485474109649658 0.25164610147476196
CurrentTrain: epoch  3, batch     9 | loss: 4.7371202Losses:  4.550580978393555 0.3340680003166199
CurrentTrain: epoch  3, batch    10 | loss: 4.8846488Losses:  4.386197090148926 0.23811772465705872
CurrentTrain: epoch  3, batch    11 | loss: 4.6243148Losses:  4.172565460205078 0.18238995969295502
CurrentTrain: epoch  3, batch    12 | loss: 4.3549552Losses:  4.391581058502197 0.3171057105064392
CurrentTrain: epoch  3, batch    13 | loss: 4.7086868Losses:  4.250497341156006 0.2384968101978302
CurrentTrain: epoch  3, batch    14 | loss: 4.4889941Losses:  4.244781017303467 0.22676800191402435
CurrentTrain: epoch  3, batch    15 | loss: 4.4715490Losses:  4.2588419914245605 0.2618173360824585
CurrentTrain: epoch  3, batch    16 | loss: 4.5206594Losses:  4.802944183349609 0.313590943813324
CurrentTrain: epoch  3, batch    17 | loss: 5.1165352Losses:  4.422202110290527 0.17005732655525208
CurrentTrain: epoch  3, batch    18 | loss: 4.5922594Losses:  4.366545677185059 0.2511104345321655
CurrentTrain: epoch  3, batch    19 | loss: 4.6176562Losses:  4.2880144119262695 0.27613312005996704
CurrentTrain: epoch  3, batch    20 | loss: 4.5641475Losses:  4.322900772094727 0.2128775268793106
CurrentTrain: epoch  3, batch    21 | loss: 4.5357785Losses:  4.438255310058594 0.3071717917919159
CurrentTrain: epoch  3, batch    22 | loss: 4.7454271Losses:  4.27192497253418 0.22865155339241028
CurrentTrain: epoch  3, batch    23 | loss: 4.5005765Losses:  4.263727188110352 0.13730230927467346
CurrentTrain: epoch  3, batch    24 | loss: 4.4010296Losses:  4.184218406677246 0.24735255539417267
CurrentTrain: epoch  3, batch    25 | loss: 4.4315710Losses:  4.264216899871826 0.24079957604408264
CurrentTrain: epoch  3, batch    26 | loss: 4.5050163Losses:  4.234752655029297 0.2193065881729126
CurrentTrain: epoch  3, batch    27 | loss: 4.4540591Losses:  4.374578475952148 0.2897910475730896
CurrentTrain: epoch  3, batch    28 | loss: 4.6643696Losses:  4.942872047424316 0.3405589461326599
CurrentTrain: epoch  3, batch    29 | loss: 5.2834311Losses:  4.671982765197754 0.34184014797210693
CurrentTrain: epoch  3, batch    30 | loss: 5.0138230Losses:  4.239206314086914 0.22384139895439148
CurrentTrain: epoch  3, batch    31 | loss: 4.4630475Losses:  4.48419189453125 0.17918291687965393
CurrentTrain: epoch  3, batch    32 | loss: 4.6633749Losses:  4.312195777893066 0.18596644699573517
CurrentTrain: epoch  3, batch    33 | loss: 4.4981623Losses:  4.19173526763916 0.18034213781356812
CurrentTrain: epoch  3, batch    34 | loss: 4.3720775Losses:  4.233254909515381 0.19767145812511444
CurrentTrain: epoch  3, batch    35 | loss: 4.4309263Losses:  4.782649517059326 0.3342156708240509
CurrentTrain: epoch  3, batch    36 | loss: 5.1168652Losses:  4.230025768280029 0.17461273074150085
CurrentTrain: epoch  3, batch    37 | loss: 4.4046383Losses:  4.181438446044922 0.19195029139518738
CurrentTrain: epoch  3, batch    38 | loss: 4.3733888Losses:  4.70038366317749 0.22319704294204712
CurrentTrain: epoch  3, batch    39 | loss: 4.9235806Losses:  4.263776779174805 0.2127344012260437
CurrentTrain: epoch  3, batch    40 | loss: 4.4765110Losses:  4.174283981323242 0.15912899374961853
CurrentTrain: epoch  3, batch    41 | loss: 4.3334131Losses:  4.858770370483398 0.244186669588089
CurrentTrain: epoch  3, batch    42 | loss: 5.1029572Losses:  4.236250877380371 0.14778001606464386
CurrentTrain: epoch  3, batch    43 | loss: 4.3840308Losses:  4.4431610107421875 0.23157024383544922
CurrentTrain: epoch  3, batch    44 | loss: 4.6747313Losses:  4.549411773681641 0.18285375833511353
CurrentTrain: epoch  3, batch    45 | loss: 4.7322655Losses:  4.184174537658691 0.17843377590179443
CurrentTrain: epoch  3, batch    46 | loss: 4.3626084Losses:  4.3197221755981445 0.2064952552318573
CurrentTrain: epoch  3, batch    47 | loss: 4.5262175Losses:  4.210954666137695 0.12825797498226166
CurrentTrain: epoch  3, batch    48 | loss: 4.3392124Losses:  4.348284721374512 0.20177602767944336
CurrentTrain: epoch  3, batch    49 | loss: 4.5500607Losses:  4.220328330993652 0.20584282279014587
CurrentTrain: epoch  3, batch    50 | loss: 4.4261713Losses:  4.4019389152526855 0.17100755870342255
CurrentTrain: epoch  3, batch    51 | loss: 4.5729465Losses:  4.202293395996094 0.20756807923316956
CurrentTrain: epoch  3, batch    52 | loss: 4.4098616Losses:  4.663803577423096 0.22668203711509705
CurrentTrain: epoch  3, batch    53 | loss: 4.8904858Losses:  4.202208518981934 0.18398968875408173
CurrentTrain: epoch  3, batch    54 | loss: 4.3861980Losses:  4.287744998931885 0.21437227725982666
CurrentTrain: epoch  3, batch    55 | loss: 4.5021172Losses:  4.20049524307251 0.17055478692054749
CurrentTrain: epoch  3, batch    56 | loss: 4.3710499Losses:  4.360700607299805 0.20323339104652405
CurrentTrain: epoch  3, batch    57 | loss: 4.5639338Losses:  4.269558906555176 0.17314478754997253
CurrentTrain: epoch  3, batch    58 | loss: 4.4427037Losses:  4.250947952270508 0.125556081533432
CurrentTrain: epoch  3, batch    59 | loss: 4.3765039Losses:  4.304868221282959 0.1997871696949005
CurrentTrain: epoch  3, batch    60 | loss: 4.5046554Losses:  4.11776065826416 0.1594133973121643
CurrentTrain: epoch  3, batch    61 | loss: 4.2771740Losses:  4.137667655944824 0.09431611001491547
CurrentTrain: epoch  3, batch    62 | loss: 4.2319837Losses:  4.162039756774902 0.12786386907100677
CurrentTrain: epoch  4, batch     0 | loss: 4.2899036Losses:  4.152064323425293 0.1803886592388153
CurrentTrain: epoch  4, batch     1 | loss: 4.3324528Losses:  4.15380859375 0.15229737758636475
CurrentTrain: epoch  4, batch     2 | loss: 4.3061061Losses:  4.027809143066406 0.13804124295711517
CurrentTrain: epoch  4, batch     3 | loss: 4.1658502Losses:  4.224843978881836 0.2407866269350052
CurrentTrain: epoch  4, batch     4 | loss: 4.4656305Losses:  4.209836006164551 0.22189649939537048
CurrentTrain: epoch  4, batch     5 | loss: 4.4317327Losses:  4.223739147186279 0.15270432829856873
CurrentTrain: epoch  4, batch     6 | loss: 4.3764434Losses:  4.169211387634277 0.15231022238731384
CurrentTrain: epoch  4, batch     7 | loss: 4.3215218Losses:  4.131495952606201 0.1769924759864807
CurrentTrain: epoch  4, batch     8 | loss: 4.3084884Losses:  4.18756103515625 0.16623704135417938
CurrentTrain: epoch  4, batch     9 | loss: 4.3537979Losses:  4.147313117980957 0.16726890206336975
CurrentTrain: epoch  4, batch    10 | loss: 4.3145819Losses:  4.250924110412598 0.2003578394651413
CurrentTrain: epoch  4, batch    11 | loss: 4.4512820Losses:  4.17268180847168 0.16353163123130798
CurrentTrain: epoch  4, batch    12 | loss: 4.3362136Losses:  4.216676712036133 0.20296891033649445
CurrentTrain: epoch  4, batch    13 | loss: 4.4196458Losses:  4.000930309295654 0.13490749895572662
CurrentTrain: epoch  4, batch    14 | loss: 4.1358380Losses:  4.146785259246826 0.13104839622974396
CurrentTrain: epoch  4, batch    15 | loss: 4.2778335Losses:  4.21742582321167 0.20042985677719116
CurrentTrain: epoch  4, batch    16 | loss: 4.4178557Losses:  4.101161956787109 0.138325497508049
CurrentTrain: epoch  4, batch    17 | loss: 4.2394876Losses:  4.1668243408203125 0.17461711168289185
CurrentTrain: epoch  4, batch    18 | loss: 4.3414416Losses:  4.123630523681641 0.2097601592540741
CurrentTrain: epoch  4, batch    19 | loss: 4.3333907Losses:  4.423731327056885 0.2313317060470581
CurrentTrain: epoch  4, batch    20 | loss: 4.6550632Losses:  4.302011489868164 0.11454927176237106
CurrentTrain: epoch  4, batch    21 | loss: 4.4165606Losses:  4.070192813873291 0.12834900617599487
CurrentTrain: epoch  4, batch    22 | loss: 4.1985416Losses:  4.052631855010986 0.07463563978672028
CurrentTrain: epoch  4, batch    23 | loss: 4.1272674Losses:  4.316067695617676 0.16919833421707153
CurrentTrain: epoch  4, batch    24 | loss: 4.4852662Losses:  4.104287147521973 0.15923741459846497
CurrentTrain: epoch  4, batch    25 | loss: 4.2635245Losses:  4.0359649658203125 0.17205408215522766
CurrentTrain: epoch  4, batch    26 | loss: 4.2080193Losses:  4.007022857666016 0.11652952432632446
CurrentTrain: epoch  4, batch    27 | loss: 4.1235523Losses:  4.2488017082214355 0.15329799056053162
CurrentTrain: epoch  4, batch    28 | loss: 4.4020996Losses:  4.159589767456055 0.155374214053154
CurrentTrain: epoch  4, batch    29 | loss: 4.3149638Losses:  4.020351409912109 0.11013904213905334
CurrentTrain: epoch  4, batch    30 | loss: 4.1304903Losses:  4.241365909576416 0.15757174789905548
CurrentTrain: epoch  4, batch    31 | loss: 4.3989377Losses:  4.152575492858887 0.16375789046287537
CurrentTrain: epoch  4, batch    32 | loss: 4.3163333Losses:  4.178048133850098 0.17183199524879456
CurrentTrain: epoch  4, batch    33 | loss: 4.3498802Losses:  4.083260536193848 0.10494080185890198
CurrentTrain: epoch  4, batch    34 | loss: 4.1882014Losses:  4.166820526123047 0.18245342373847961
CurrentTrain: epoch  4, batch    35 | loss: 4.3492742Losses:  4.121950149536133 0.13994735479354858
CurrentTrain: epoch  4, batch    36 | loss: 4.2618976Losses:  4.284980773925781 0.209661066532135
CurrentTrain: epoch  4, batch    37 | loss: 4.4946418Losses:  4.05726432800293 0.1207117885351181
CurrentTrain: epoch  4, batch    38 | loss: 4.1779761Losses:  4.0747809410095215 0.12364941090345383
CurrentTrain: epoch  4, batch    39 | loss: 4.1984305Losses:  4.025165557861328 0.15221789479255676
CurrentTrain: epoch  4, batch    40 | loss: 4.1773834Losses:  4.007892608642578 0.16460159420967102
CurrentTrain: epoch  4, batch    41 | loss: 4.1724944Losses:  4.848113059997559 0.32540079951286316
CurrentTrain: epoch  4, batch    42 | loss: 5.1735139Losses:  4.1724348068237305 0.1395193338394165
CurrentTrain: epoch  4, batch    43 | loss: 4.3119540Losses:  4.006380558013916 0.12244061380624771
CurrentTrain: epoch  4, batch    44 | loss: 4.1288214Losses:  4.374178886413574 0.2042018175125122
CurrentTrain: epoch  4, batch    45 | loss: 4.5783806Losses:  4.334315299987793 0.1525508314371109
CurrentTrain: epoch  4, batch    46 | loss: 4.4868660Losses:  4.15461540222168 0.15682876110076904
CurrentTrain: epoch  4, batch    47 | loss: 4.3114443Losses:  4.157737731933594 0.15343840420246124
CurrentTrain: epoch  4, batch    48 | loss: 4.3111763Losses:  4.044219970703125 0.146266371011734
CurrentTrain: epoch  4, batch    49 | loss: 4.1904864Losses:  4.219953536987305 0.20140399038791656
CurrentTrain: epoch  4, batch    50 | loss: 4.4213576Losses:  4.051487445831299 0.10373096168041229
CurrentTrain: epoch  4, batch    51 | loss: 4.1552186Losses:  4.041140079498291 0.12386977672576904
CurrentTrain: epoch  4, batch    52 | loss: 4.1650100Losses:  4.111995697021484 0.1599542647600174
CurrentTrain: epoch  4, batch    53 | loss: 4.2719498Losses:  4.355490684509277 0.14217239618301392
CurrentTrain: epoch  4, batch    54 | loss: 4.4976630Losses:  4.031092166900635 0.15587691962718964
CurrentTrain: epoch  4, batch    55 | loss: 4.1869693Losses:  4.159652233123779 0.11799561977386475
CurrentTrain: epoch  4, batch    56 | loss: 4.2776480Losses:  4.115268707275391 0.15988895297050476
CurrentTrain: epoch  4, batch    57 | loss: 4.2751575Losses:  4.036462783813477 0.11603862047195435
CurrentTrain: epoch  4, batch    58 | loss: 4.1525016Losses:  4.085563659667969 0.11309638619422913
CurrentTrain: epoch  4, batch    59 | loss: 4.1986599Losses:  4.025152206420898 0.15140026807785034
CurrentTrain: epoch  4, batch    60 | loss: 4.1765523Losses:  4.1038408279418945 0.13899022340774536
CurrentTrain: epoch  4, batch    61 | loss: 4.2428312Losses:  4.074840545654297 0.0790170431137085
CurrentTrain: epoch  4, batch    62 | loss: 4.1538577Losses:  4.103885650634766 0.16629599034786224
CurrentTrain: epoch  5, batch     0 | loss: 4.2701817Losses:  4.05165958404541 0.14743921160697937
CurrentTrain: epoch  5, batch     1 | loss: 4.1990986Losses:  4.041961193084717 0.13075430691242218
CurrentTrain: epoch  5, batch     2 | loss: 4.1727157Losses:  4.035161018371582 0.11572249978780746
CurrentTrain: epoch  5, batch     3 | loss: 4.1508837Losses:  4.0969462394714355 0.14668330550193787
CurrentTrain: epoch  5, batch     4 | loss: 4.2436295Losses:  4.187262535095215 0.13481423258781433
CurrentTrain: epoch  5, batch     5 | loss: 4.3220768Losses:  4.083359718322754 0.14683666825294495
CurrentTrain: epoch  5, batch     6 | loss: 4.2301965Losses:  3.9914729595184326 0.1615365594625473
CurrentTrain: epoch  5, batch     7 | loss: 4.1530094Losses:  4.076564311981201 0.1614447981119156
CurrentTrain: epoch  5, batch     8 | loss: 4.2380090Losses:  4.027032375335693 0.08081835508346558
CurrentTrain: epoch  5, batch     9 | loss: 4.1078506Losses:  4.150392532348633 0.1860361099243164
CurrentTrain: epoch  5, batch    10 | loss: 4.3364286Losses:  4.040641784667969 0.13315674662590027
CurrentTrain: epoch  5, batch    11 | loss: 4.1737986Losses:  4.095670700073242 0.12413402646780014
CurrentTrain: epoch  5, batch    12 | loss: 4.2198048Losses:  4.010458946228027 0.14791955053806305
CurrentTrain: epoch  5, batch    13 | loss: 4.1583786Losses:  3.9810309410095215 0.15319301187992096
CurrentTrain: epoch  5, batch    14 | loss: 4.1342239Losses:  4.053109169006348 0.12965652346611023
CurrentTrain: epoch  5, batch    15 | loss: 4.1827655Losses:  4.027442932128906 0.15916380286216736
CurrentTrain: epoch  5, batch    16 | loss: 4.1866069Losses:  3.993865489959717 0.14452463388442993
CurrentTrain: epoch  5, batch    17 | loss: 4.1383901Losses:  4.04975700378418 0.1756252944469452
CurrentTrain: epoch  5, batch    18 | loss: 4.2253823Losses:  4.043367385864258 0.12261420488357544
CurrentTrain: epoch  5, batch    19 | loss: 4.1659818Losses:  4.001354217529297 0.1213608905673027
CurrentTrain: epoch  5, batch    20 | loss: 4.1227150Losses:  4.103363037109375 0.11085257679224014
CurrentTrain: epoch  5, batch    21 | loss: 4.2142158Losses:  4.0535759925842285 0.11731243878602982
CurrentTrain: epoch  5, batch    22 | loss: 4.1708884Losses:  4.042013168334961 0.1313236951828003
CurrentTrain: epoch  5, batch    23 | loss: 4.1733370Losses:  4.021383285522461 0.09499694406986237
CurrentTrain: epoch  5, batch    24 | loss: 4.1163802Losses:  4.112865447998047 0.1323278844356537
CurrentTrain: epoch  5, batch    25 | loss: 4.2451935Losses:  4.040911674499512 0.15762624144554138
CurrentTrain: epoch  5, batch    26 | loss: 4.1985378Losses:  4.017436504364014 0.12866556644439697
CurrentTrain: epoch  5, batch    27 | loss: 4.1461020Losses:  4.038732528686523 0.1458909958600998
CurrentTrain: epoch  5, batch    28 | loss: 4.1846237Losses:  4.000493049621582 0.1371574103832245
CurrentTrain: epoch  5, batch    29 | loss: 4.1376505Losses:  3.981349468231201 0.08509787172079086
CurrentTrain: epoch  5, batch    30 | loss: 4.0664473Losses:  4.0318708419799805 0.11591242998838425
CurrentTrain: epoch  5, batch    31 | loss: 4.1477833Losses:  4.052919864654541 0.09533574432134628
CurrentTrain: epoch  5, batch    32 | loss: 4.1482558Losses:  4.012870788574219 0.08344749361276627
CurrentTrain: epoch  5, batch    33 | loss: 4.0963182Losses:  4.10302209854126 0.12877124547958374
CurrentTrain: epoch  5, batch    34 | loss: 4.2317934Losses:  4.627595901489258 0.18013359606266022
CurrentTrain: epoch  5, batch    35 | loss: 4.8077297Losses:  4.014331817626953 0.08293615281581879
CurrentTrain: epoch  5, batch    36 | loss: 4.0972681Losses:  4.001893997192383 0.11171813309192657
CurrentTrain: epoch  5, batch    37 | loss: 4.1136122Losses:  4.013585090637207 0.13241061568260193
CurrentTrain: epoch  5, batch    38 | loss: 4.1459956Losses:  4.033184051513672 0.12639741599559784
CurrentTrain: epoch  5, batch    39 | loss: 4.1595817Losses:  4.048267364501953 0.14372199773788452
CurrentTrain: epoch  5, batch    40 | loss: 4.1919894Losses:  4.106699466705322 0.11778406798839569
CurrentTrain: epoch  5, batch    41 | loss: 4.2244835Losses:  4.056971549987793 0.1532641053199768
CurrentTrain: epoch  5, batch    42 | loss: 4.2102356Losses:  4.054764747619629 0.1658732146024704
CurrentTrain: epoch  5, batch    43 | loss: 4.2206378Losses:  3.9993956089019775 0.11366667598485947
CurrentTrain: epoch  5, batch    44 | loss: 4.1130624Losses:  3.992642641067505 0.1229306012392044
CurrentTrain: epoch  5, batch    45 | loss: 4.1155734Losses:  4.1733174324035645 0.1317930817604065
CurrentTrain: epoch  5, batch    46 | loss: 4.3051105Losses:  4.076827049255371 0.11826001852750778
CurrentTrain: epoch  5, batch    47 | loss: 4.1950870Losses:  3.9507155418395996 0.1292533278465271
CurrentTrain: epoch  5, batch    48 | loss: 4.0799689Losses:  3.9996509552001953 0.12364525347948074
CurrentTrain: epoch  5, batch    49 | loss: 4.1232963Losses:  4.042130470275879 0.11156906187534332
CurrentTrain: epoch  5, batch    50 | loss: 4.1536994Losses:  4.091409206390381 0.11022664606571198
CurrentTrain: epoch  5, batch    51 | loss: 4.2016358Losses:  3.9994096755981445 0.15281885862350464
CurrentTrain: epoch  5, batch    52 | loss: 4.1522284Losses:  4.01303768157959 0.10651103407144547
CurrentTrain: epoch  5, batch    53 | loss: 4.1195488Losses:  3.953768730163574 0.15360909700393677
CurrentTrain: epoch  5, batch    54 | loss: 4.1073780Losses:  4.071771144866943 0.12327951192855835
CurrentTrain: epoch  5, batch    55 | loss: 4.1950507Losses:  3.989798069000244 0.12879320979118347
CurrentTrain: epoch  5, batch    56 | loss: 4.1185913Losses:  4.168453693389893 0.16252776980400085
CurrentTrain: epoch  5, batch    57 | loss: 4.3309813Losses:  3.980135202407837 0.11524496972560883
CurrentTrain: epoch  5, batch    58 | loss: 4.0953803Losses:  4.158838272094727 0.10816824436187744
CurrentTrain: epoch  5, batch    59 | loss: 4.2670064Losses:  3.9686107635498047 0.0794372409582138
CurrentTrain: epoch  5, batch    60 | loss: 4.0480480Losses:  3.9807355403900146 0.09702757000923157
CurrentTrain: epoch  5, batch    61 | loss: 4.0777631Losses:  4.024991989135742 0.07632765173912048
CurrentTrain: epoch  5, batch    62 | loss: 4.1013198Losses:  4.004999160766602 0.11913381516933441
CurrentTrain: epoch  6, batch     0 | loss: 4.1241331Losses:  3.987924337387085 0.14666834473609924
CurrentTrain: epoch  6, batch     1 | loss: 4.1345925Losses:  3.9697084426879883 0.08502320945262909
CurrentTrain: epoch  6, batch     2 | loss: 4.0547318Losses:  4.090296745300293 0.15626764297485352
CurrentTrain: epoch  6, batch     3 | loss: 4.2465644Losses:  3.9921200275421143 0.07785363495349884
CurrentTrain: epoch  6, batch     4 | loss: 4.0699735Losses:  3.9862582683563232 0.10538391768932343
CurrentTrain: epoch  6, batch     5 | loss: 4.0916424Losses:  4.021480560302734 0.14672362804412842
CurrentTrain: epoch  6, batch     6 | loss: 4.1682043Losses:  3.992555856704712 0.12134011089801788
CurrentTrain: epoch  6, batch     7 | loss: 4.1138959Losses:  3.9610958099365234 0.11324527859687805
CurrentTrain: epoch  6, batch     8 | loss: 4.0743413Losses:  4.003086566925049 0.11068813502788544
CurrentTrain: epoch  6, batch     9 | loss: 4.1137748Losses:  3.9833359718322754 0.10765258967876434
CurrentTrain: epoch  6, batch    10 | loss: 4.0909886Losses:  4.048540115356445 0.09210095554590225
CurrentTrain: epoch  6, batch    11 | loss: 4.1406412Losses:  4.013721466064453 0.13096489012241364
CurrentTrain: epoch  6, batch    12 | loss: 4.1446862Losses:  4.000725746154785 0.09269532561302185
CurrentTrain: epoch  6, batch    13 | loss: 4.0934210Losses:  3.9960014820098877 0.11831460893154144
CurrentTrain: epoch  6, batch    14 | loss: 4.1143160Losses:  3.9657065868377686 0.14389589428901672
CurrentTrain: epoch  6, batch    15 | loss: 4.1096025Losses:  3.974891424179077 0.11124507337808609
CurrentTrain: epoch  6, batch    16 | loss: 4.0861363Losses:  3.9795756340026855 0.12705504894256592
CurrentTrain: epoch  6, batch    17 | loss: 4.1066308Losses:  4.010613441467285 0.06136438995599747
CurrentTrain: epoch  6, batch    18 | loss: 4.0719776Losses:  3.9544248580932617 0.11836501955986023
CurrentTrain: epoch  6, batch    19 | loss: 4.0727897Losses:  3.9784300327301025 0.13200759887695312
CurrentTrain: epoch  6, batch    20 | loss: 4.1104374Losses:  4.034028053283691 0.12378297746181488
CurrentTrain: epoch  6, batch    21 | loss: 4.1578112Losses:  4.008865833282471 0.09287497401237488
CurrentTrain: epoch  6, batch    22 | loss: 4.1017408Losses:  4.065343856811523 0.11751691997051239
CurrentTrain: epoch  6, batch    23 | loss: 4.1828609Losses:  4.002108573913574 0.09769658744335175
CurrentTrain: epoch  6, batch    24 | loss: 4.0998054Losses:  4.016849517822266 0.11394232511520386
CurrentTrain: epoch  6, batch    25 | loss: 4.1307917Losses:  4.001441955566406 0.10761977732181549
CurrentTrain: epoch  6, batch    26 | loss: 4.1090617Losses:  3.9692625999450684 0.11663826555013657
CurrentTrain: epoch  6, batch    27 | loss: 4.0859008Losses:  3.962191104888916 0.12466548383235931
CurrentTrain: epoch  6, batch    28 | loss: 4.0868564Losses:  3.976069927215576 0.09501208364963531
CurrentTrain: epoch  6, batch    29 | loss: 4.0710821Losses:  3.9762368202209473 0.12175561487674713
CurrentTrain: epoch  6, batch    30 | loss: 4.0979924Losses:  3.9159255027770996 0.06671839952468872
CurrentTrain: epoch  6, batch    31 | loss: 3.9826438Losses:  4.004028797149658 0.0860292911529541
CurrentTrain: epoch  6, batch    32 | loss: 4.0900583Losses:  3.982311248779297 0.09988545626401901
CurrentTrain: epoch  6, batch    33 | loss: 4.0821967Losses:  4.017364501953125 0.10976416617631912
CurrentTrain: epoch  6, batch    34 | loss: 4.1271286Losses:  3.9727234840393066 0.08945812284946442
CurrentTrain: epoch  6, batch    35 | loss: 4.0621815Losses:  4.034979343414307 0.06212729960680008
CurrentTrain: epoch  6, batch    36 | loss: 4.0971065Losses:  3.9756863117218018 0.12068329751491547
CurrentTrain: epoch  6, batch    37 | loss: 4.0963697Losses:  3.9764151573181152 0.12747450172901154
CurrentTrain: epoch  6, batch    38 | loss: 4.1038895Losses:  3.943068027496338 0.06698369979858398
CurrentTrain: epoch  6, batch    39 | loss: 4.0100517Losses:  3.9729247093200684 0.12057419121265411
CurrentTrain: epoch  6, batch    40 | loss: 4.0934987Losses:  3.9734861850738525 0.1238410472869873
CurrentTrain: epoch  6, batch    41 | loss: 4.0973272Losses:  3.9604177474975586 0.12042129039764404
CurrentTrain: epoch  6, batch    42 | loss: 4.0808392Losses:  3.927314043045044 0.08681688457727432
CurrentTrain: epoch  6, batch    43 | loss: 4.0141311Losses:  3.9578561782836914 0.08906799554824829
CurrentTrain: epoch  6, batch    44 | loss: 4.0469241Losses:  3.9742913246154785 0.10248632729053497
CurrentTrain: epoch  6, batch    45 | loss: 4.0767775Losses:  3.973446846008301 0.09206608682870865
CurrentTrain: epoch  6, batch    46 | loss: 4.0655131Losses:  3.9745259284973145 0.07933852076530457
CurrentTrain: epoch  6, batch    47 | loss: 4.0538645Losses:  3.9534690380096436 0.11206144839525223
CurrentTrain: epoch  6, batch    48 | loss: 4.0655303Losses:  3.969897747039795 0.0663411021232605
CurrentTrain: epoch  6, batch    49 | loss: 4.0362387Losses:  3.9748940467834473 0.10490459203720093
CurrentTrain: epoch  6, batch    50 | loss: 4.0797987Losses:  3.9483237266540527 0.11015871167182922
CurrentTrain: epoch  6, batch    51 | loss: 4.0584826Losses:  3.969517707824707 0.11762116849422455
CurrentTrain: epoch  6, batch    52 | loss: 4.0871387Losses:  3.955784320831299 0.0481707826256752
CurrentTrain: epoch  6, batch    53 | loss: 4.0039549Losses:  3.958059787750244 0.08795897662639618
CurrentTrain: epoch  6, batch    54 | loss: 4.0460186Losses:  3.9465479850769043 0.09216533601284027
CurrentTrain: epoch  6, batch    55 | loss: 4.0387135Losses:  4.008738040924072 0.07044118642807007
CurrentTrain: epoch  6, batch    56 | loss: 4.0791793Losses:  3.965643882751465 0.10080690681934357
CurrentTrain: epoch  6, batch    57 | loss: 4.0664506Losses:  3.9455912113189697 0.08720547705888748
CurrentTrain: epoch  6, batch    58 | loss: 4.0327969Losses:  3.977459192276001 0.10144776850938797
CurrentTrain: epoch  6, batch    59 | loss: 4.0789070Losses:  3.9983575344085693 0.06521406769752502
CurrentTrain: epoch  6, batch    60 | loss: 4.0635715Losses:  3.9791946411132812 0.09062137454748154
CurrentTrain: epoch  6, batch    61 | loss: 4.0698161Losses:  3.9592390060424805 0.0780191421508789
CurrentTrain: epoch  6, batch    62 | loss: 4.0372581Losses:  4.021343231201172 0.06945545971393585
CurrentTrain: epoch  7, batch     0 | loss: 4.0907989Losses:  3.993440866470337 0.081790030002594
CurrentTrain: epoch  7, batch     1 | loss: 4.0752311Losses:  3.9658045768737793 0.09069104492664337
CurrentTrain: epoch  7, batch     2 | loss: 4.0564957Losses:  3.9504311084747314 0.10027284175157547
CurrentTrain: epoch  7, batch     3 | loss: 4.0507040Losses:  3.962630271911621 0.07952979952096939
CurrentTrain: epoch  7, batch     4 | loss: 4.0421600Losses:  3.9531846046447754 0.09037746489048004
CurrentTrain: epoch  7, batch     5 | loss: 4.0435619Losses:  3.9537947177886963 0.10010919719934464
CurrentTrain: epoch  7, batch     6 | loss: 4.0539041Losses:  4.000951766967773 0.12724073231220245
CurrentTrain: epoch  7, batch     7 | loss: 4.1281924Losses:  3.922452926635742 0.06271998584270477
CurrentTrain: epoch  7, batch     8 | loss: 3.9851730Losses:  3.932955265045166 0.07984223961830139
CurrentTrain: epoch  7, batch     9 | loss: 4.0127974Losses:  3.9711577892303467 0.09495703130960464
CurrentTrain: epoch  7, batch    10 | loss: 4.0661149Losses:  3.91756534576416 0.069308802485466
CurrentTrain: epoch  7, batch    11 | loss: 3.9868741Losses:  3.9357075691223145 0.06503402441740036
CurrentTrain: epoch  7, batch    12 | loss: 4.0007415Losses:  3.963710308074951 0.07898949086666107
CurrentTrain: epoch  7, batch    13 | loss: 4.0426998Losses:  3.9304981231689453 0.0796070396900177
CurrentTrain: epoch  7, batch    14 | loss: 4.0101051Losses:  3.898092031478882 0.09576719999313354
CurrentTrain: epoch  7, batch    15 | loss: 3.9938593Losses:  4.008247375488281 0.08849858492612839
CurrentTrain: epoch  7, batch    16 | loss: 4.0967460Losses:  4.0028581619262695 0.11667260527610779
CurrentTrain: epoch  7, batch    17 | loss: 4.1195307Losses:  3.9487905502319336 0.08979333937168121
CurrentTrain: epoch  7, batch    18 | loss: 4.0385838Losses:  4.007622718811035 0.0990765243768692
CurrentTrain: epoch  7, batch    19 | loss: 4.1066995Losses:  3.997765302658081 0.0790230929851532
CurrentTrain: epoch  7, batch    20 | loss: 4.0767884Losses:  3.9393069744110107 0.08787290751934052
CurrentTrain: epoch  7, batch    21 | loss: 4.0271797Losses:  3.9505884647369385 0.07998490333557129
CurrentTrain: epoch  7, batch    22 | loss: 4.0305734Losses:  3.964329242706299 0.07601987570524216
CurrentTrain: epoch  7, batch    23 | loss: 4.0403490Losses:  3.9594922065734863 0.09128465503454208
CurrentTrain: epoch  7, batch    24 | loss: 4.0507770Losses:  4.037755966186523 0.07324272394180298
CurrentTrain: epoch  7, batch    25 | loss: 4.1109986Losses:  3.9440536499023438 0.07575210928916931
CurrentTrain: epoch  7, batch    26 | loss: 4.0198059Losses:  3.961911678314209 0.09638260304927826
CurrentTrain: epoch  7, batch    27 | loss: 4.0582943Losses:  3.9669017791748047 0.0675203949213028
CurrentTrain: epoch  7, batch    28 | loss: 4.0344224Losses:  3.97432279586792 0.06343226134777069
CurrentTrain: epoch  7, batch    29 | loss: 4.0377550Losses:  3.9876646995544434 0.07722911983728409
CurrentTrain: epoch  7, batch    30 | loss: 4.0648937Losses:  3.96394419670105 0.10143493115901947
CurrentTrain: epoch  7, batch    31 | loss: 4.0653791Losses:  3.973493814468384 0.055492766201496124
CurrentTrain: epoch  7, batch    32 | loss: 4.0289865Losses:  4.039948463439941 0.08081406354904175
CurrentTrain: epoch  7, batch    33 | loss: 4.1207623Losses:  3.9965686798095703 0.07362031936645508
CurrentTrain: epoch  7, batch    34 | loss: 4.0701890Losses:  3.942713975906372 0.09324288368225098
CurrentTrain: epoch  7, batch    35 | loss: 4.0359569Losses:  4.025649070739746 0.08748514950275421
CurrentTrain: epoch  7, batch    36 | loss: 4.1131344Losses:  3.9322335720062256 0.05757109075784683
CurrentTrain: epoch  7, batch    37 | loss: 3.9898047Losses:  3.9508094787597656 0.0829058513045311
CurrentTrain: epoch  7, batch    38 | loss: 4.0337152Losses:  3.9376091957092285 0.06894323229789734
CurrentTrain: epoch  7, batch    39 | loss: 4.0065522Losses:  3.94512939453125 0.09062635898590088
CurrentTrain: epoch  7, batch    40 | loss: 4.0357556Losses:  3.938568115234375 0.04964108020067215
CurrentTrain: epoch  7, batch    41 | loss: 3.9882092Losses:  3.9378483295440674 0.09208011627197266
CurrentTrain: epoch  7, batch    42 | loss: 4.0299282Losses:  3.936007499694824 0.06926082819700241
CurrentTrain: epoch  7, batch    43 | loss: 4.0052681Losses:  3.948483467102051 0.07864178717136383
CurrentTrain: epoch  7, batch    44 | loss: 4.0271254Losses:  3.9101550579071045 0.08252149820327759
CurrentTrain: epoch  7, batch    45 | loss: 3.9926765Losses:  3.9601337909698486 0.08498048037290573
CurrentTrain: epoch  7, batch    46 | loss: 4.0451140Losses:  3.9546689987182617 0.08459015190601349
CurrentTrain: epoch  7, batch    47 | loss: 4.0392590Losses:  3.9476070404052734 0.08568260073661804
CurrentTrain: epoch  7, batch    48 | loss: 4.0332894Losses:  3.921739101409912 0.09357192367315292
CurrentTrain: epoch  7, batch    49 | loss: 4.0153112Losses:  3.897127628326416 0.06105645000934601
CurrentTrain: epoch  7, batch    50 | loss: 3.9581840Losses:  3.9421801567077637 0.08625462651252747
CurrentTrain: epoch  7, batch    51 | loss: 4.0284348Losses:  4.001678466796875 0.0660402774810791
CurrentTrain: epoch  7, batch    52 | loss: 4.0677185Losses:  3.9820921421051025 0.08026377111673355
CurrentTrain: epoch  7, batch    53 | loss: 4.0623560Losses:  3.97404146194458 0.08235436677932739
CurrentTrain: epoch  7, batch    54 | loss: 4.0563960Losses:  3.960235834121704 0.06216829642653465
CurrentTrain: epoch  7, batch    55 | loss: 4.0224042Losses:  3.958303928375244 0.07530593127012253
CurrentTrain: epoch  7, batch    56 | loss: 4.0336099Losses:  3.9304842948913574 0.07972254604101181
CurrentTrain: epoch  7, batch    57 | loss: 4.0102067Losses:  3.921292543411255 0.09743983298540115
CurrentTrain: epoch  7, batch    58 | loss: 4.0187325Losses:  3.9815120697021484 0.051068082451820374
CurrentTrain: epoch  7, batch    59 | loss: 4.0325804Losses:  3.9763057231903076 0.09035483002662659
CurrentTrain: epoch  7, batch    60 | loss: 4.0666604Losses:  3.9519524574279785 0.08605237305164337
CurrentTrain: epoch  7, batch    61 | loss: 4.0380049Losses:  4.00342321395874 0.0452921986579895
CurrentTrain: epoch  7, batch    62 | loss: 4.0487156Losses:  3.962137460708618 0.09665143489837646
CurrentTrain: epoch  8, batch     0 | loss: 4.0587888Losses:  3.985945701599121 0.09023895859718323
CurrentTrain: epoch  8, batch     1 | loss: 4.0761847Losses:  3.939131259918213 0.0733749270439148
CurrentTrain: epoch  8, batch     2 | loss: 4.0125060Losses:  3.974529504776001 0.05602651834487915
CurrentTrain: epoch  8, batch     3 | loss: 4.0305562Losses:  3.9139139652252197 0.0622188039124012
CurrentTrain: epoch  8, batch     4 | loss: 3.9761329Losses:  3.946354389190674 0.06508781760931015
CurrentTrain: epoch  8, batch     5 | loss: 4.0114422Losses:  3.9578473567962646 0.08636893332004547
CurrentTrain: epoch  8, batch     6 | loss: 4.0442162Losses:  3.9740920066833496 0.08292853087186813
CurrentTrain: epoch  8, batch     7 | loss: 4.0570207Losses:  3.9440722465515137 0.08278127014636993
CurrentTrain: epoch  8, batch     8 | loss: 4.0268536Losses:  3.9529685974121094 0.08333464711904526
CurrentTrain: epoch  8, batch     9 | loss: 4.0363030Losses:  3.919501543045044 0.08542084693908691
CurrentTrain: epoch  8, batch    10 | loss: 4.0049224Losses:  3.9262399673461914 0.09943221509456635
CurrentTrain: epoch  8, batch    11 | loss: 4.0256720Losses:  3.955904483795166 0.09233687072992325
CurrentTrain: epoch  8, batch    12 | loss: 4.0482411Losses:  3.948472023010254 0.08842064440250397
CurrentTrain: epoch  8, batch    13 | loss: 4.0368929Losses:  3.9140982627868652 0.07388260960578918
CurrentTrain: epoch  8, batch    14 | loss: 3.9879808Losses:  3.93452787399292 0.056152623146772385
CurrentTrain: epoch  8, batch    15 | loss: 3.9906805Losses:  3.919013500213623 0.07397671788930893
CurrentTrain: epoch  8, batch    16 | loss: 3.9929903Losses:  3.956963539123535 0.08478455245494843
CurrentTrain: epoch  8, batch    17 | loss: 4.0417480Losses:  3.9494571685791016 0.08146999776363373
CurrentTrain: epoch  8, batch    18 | loss: 4.0309272Losses:  3.970703601837158 0.06977453827857971
CurrentTrain: epoch  8, batch    19 | loss: 4.0404782Losses:  3.875985622406006 0.06745211780071259
CurrentTrain: epoch  8, batch    20 | loss: 3.9434378Losses:  3.928910970687866 0.06305287778377533
CurrentTrain: epoch  8, batch    21 | loss: 3.9919639Losses:  3.943176746368408 0.05802416801452637
CurrentTrain: epoch  8, batch    22 | loss: 4.0012007Losses:  3.956892490386963 0.08921604603528976
CurrentTrain: epoch  8, batch    23 | loss: 4.0461087Losses:  3.9598591327667236 0.09317674487829208
CurrentTrain: epoch  8, batch    24 | loss: 4.0530357Losses:  3.936542510986328 0.05106838792562485
CurrentTrain: epoch  8, batch    25 | loss: 3.9876108Losses:  3.9528732299804688 0.07361961901187897
CurrentTrain: epoch  8, batch    26 | loss: 4.0264931Losses:  3.9922866821289062 0.07321123033761978
CurrentTrain: epoch  8, batch    27 | loss: 4.0654979Losses:  3.943617820739746 0.0883423462510109
CurrentTrain: epoch  8, batch    28 | loss: 4.0319600Losses:  3.9506845474243164 0.07357548177242279
CurrentTrain: epoch  8, batch    29 | loss: 4.0242600Losses:  3.9253041744232178 0.07087285071611404
CurrentTrain: epoch  8, batch    30 | loss: 3.9961770Losses:  3.9478912353515625 0.07220719754695892
CurrentTrain: epoch  8, batch    31 | loss: 4.0200982Losses:  3.976078987121582 0.04450717568397522
CurrentTrain: epoch  8, batch    32 | loss: 4.0205860Losses:  3.93294620513916 0.09485935419797897
CurrentTrain: epoch  8, batch    33 | loss: 4.0278053Losses:  3.9508724212646484 0.08298644423484802
CurrentTrain: epoch  8, batch    34 | loss: 4.0338588Losses:  3.9419710636138916 0.06078614294528961
CurrentTrain: epoch  8, batch    35 | loss: 4.0027571Losses:  3.9482028484344482 0.06862971186637878
CurrentTrain: epoch  8, batch    36 | loss: 4.0168324Losses:  3.9761223793029785 0.05760319530963898
CurrentTrain: epoch  8, batch    37 | loss: 4.0337257Losses:  3.9156177043914795 0.05327901616692543
CurrentTrain: epoch  8, batch    38 | loss: 3.9688966Losses:  3.983100175857544 0.07503688335418701
CurrentTrain: epoch  8, batch    39 | loss: 4.0581369Losses:  3.977538585662842 0.08454066514968872
CurrentTrain: epoch  8, batch    40 | loss: 4.0620794Losses:  3.958279609680176 0.08259319514036179
CurrentTrain: epoch  8, batch    41 | loss: 4.0408726Losses:  3.9721202850341797 0.0872475802898407
CurrentTrain: epoch  8, batch    42 | loss: 4.0593677Losses:  3.9606432914733887 0.0728984922170639
CurrentTrain: epoch  8, batch    43 | loss: 4.0335417Losses:  3.9669418334960938 0.0804692804813385
CurrentTrain: epoch  8, batch    44 | loss: 4.0474110Losses:  3.9963808059692383 0.06444696336984634
CurrentTrain: epoch  8, batch    45 | loss: 4.0608277Losses:  3.90873384475708 0.05441581830382347
CurrentTrain: epoch  8, batch    46 | loss: 3.9631495Losses:  3.96602201461792 0.05943303927779198
CurrentTrain: epoch  8, batch    47 | loss: 4.0254550Losses:  3.978987216949463 0.05740795657038689
CurrentTrain: epoch  8, batch    48 | loss: 4.0363951Losses:  3.943480968475342 0.06321435421705246
CurrentTrain: epoch  8, batch    49 | loss: 4.0066953Losses:  3.9469988346099854 0.06953193992376328
CurrentTrain: epoch  8, batch    50 | loss: 4.0165310Losses:  3.9584293365478516 0.04310737922787666
CurrentTrain: epoch  8, batch    51 | loss: 4.0015368Losses:  3.9582314491271973 0.08174367994070053
CurrentTrain: epoch  8, batch    52 | loss: 4.0399752Losses:  3.9706459045410156 0.08342478424310684
CurrentTrain: epoch  8, batch    53 | loss: 4.0540705Losses:  3.9357876777648926 0.07268907129764557
CurrentTrain: epoch  8, batch    54 | loss: 4.0084767Losses:  3.9415440559387207 0.045126453042030334
CurrentTrain: epoch  8, batch    55 | loss: 3.9866705Losses:  3.9531867504119873 0.07373258471488953
CurrentTrain: epoch  8, batch    56 | loss: 4.0269194Losses:  3.9448485374450684 0.0858168825507164
CurrentTrain: epoch  8, batch    57 | loss: 4.0306654Losses:  3.9795784950256348 0.06650205701589584
CurrentTrain: epoch  8, batch    58 | loss: 4.0460806Losses:  3.9680073261260986 0.06902264058589935
CurrentTrain: epoch  8, batch    59 | loss: 4.0370297Losses:  3.904834747314453 0.07272440195083618
CurrentTrain: epoch  8, batch    60 | loss: 3.9775591Losses:  3.959826946258545 0.08400721848011017
CurrentTrain: epoch  8, batch    61 | loss: 4.0438342Losses:  3.926974296569824 0.03035157546401024
CurrentTrain: epoch  8, batch    62 | loss: 3.9573259Losses:  3.9358744621276855 0.06353786587715149
CurrentTrain: epoch  9, batch     0 | loss: 3.9994123Losses:  3.9967598915100098 0.05380786210298538
CurrentTrain: epoch  9, batch     1 | loss: 4.0505676Losses:  3.9686813354492188 0.07664968818426132
CurrentTrain: epoch  9, batch     2 | loss: 4.0453310Losses:  3.9953722953796387 0.0686800628900528
CurrentTrain: epoch  9, batch     3 | loss: 4.0640526Losses:  3.9397239685058594 0.059997715055942535
CurrentTrain: epoch  9, batch     4 | loss: 3.9997218Losses:  3.945923328399658 0.061956532299518585
CurrentTrain: epoch  9, batch     5 | loss: 4.0078797Losses:  3.953218698501587 0.052317455410957336
CurrentTrain: epoch  9, batch     6 | loss: 4.0055361Losses:  3.9379191398620605 0.05777611583471298
CurrentTrain: epoch  9, batch     7 | loss: 3.9956954Losses:  3.9104177951812744 0.04180843010544777
CurrentTrain: epoch  9, batch     8 | loss: 3.9522262Losses:  3.9387199878692627 0.08118066191673279
CurrentTrain: epoch  9, batch     9 | loss: 4.0199008Losses:  3.940218925476074 0.08598215132951736
CurrentTrain: epoch  9, batch    10 | loss: 4.0262012Losses:  3.971762180328369 0.07386284321546555
CurrentTrain: epoch  9, batch    11 | loss: 4.0456252Losses:  3.951619863510132 0.08092688024044037
CurrentTrain: epoch  9, batch    12 | loss: 4.0325465Losses:  3.9519476890563965 0.06611649692058563
CurrentTrain: epoch  9, batch    13 | loss: 4.0180640Losses:  3.952648639678955 0.09257522225379944
CurrentTrain: epoch  9, batch    14 | loss: 4.0452237Losses:  3.9663140773773193 0.07992453873157501
CurrentTrain: epoch  9, batch    15 | loss: 4.0462384Losses:  3.9396090507507324 0.07051259279251099
CurrentTrain: epoch  9, batch    16 | loss: 4.0101218Losses:  3.9739882946014404 0.08230738341808319
CurrentTrain: epoch  9, batch    17 | loss: 4.0562959Losses:  3.9454903602600098 0.07200080156326294
CurrentTrain: epoch  9, batch    18 | loss: 4.0174913Losses:  3.88620662689209 0.05712719261646271
CurrentTrain: epoch  9, batch    19 | loss: 3.9433339Losses:  3.977766275405884 0.08277711272239685
CurrentTrain: epoch  9, batch    20 | loss: 4.0605435Losses:  3.9316248893737793 0.06459213048219681
CurrentTrain: epoch  9, batch    21 | loss: 3.9962170Losses:  3.982252597808838 0.06540930271148682
CurrentTrain: epoch  9, batch    22 | loss: 4.0476618Losses:  3.9335079193115234 0.06211145967245102
CurrentTrain: epoch  9, batch    23 | loss: 3.9956193Losses:  3.9516592025756836 0.054742008447647095
CurrentTrain: epoch  9, batch    24 | loss: 4.0064011Losses:  3.9659900665283203 0.0639047920703888
CurrentTrain: epoch  9, batch    25 | loss: 4.0298948Losses:  3.9209132194519043 0.07414403557777405
CurrentTrain: epoch  9, batch    26 | loss: 3.9950573Losses:  3.9373669624328613 0.06342610716819763
CurrentTrain: epoch  9, batch    27 | loss: 4.0007930Losses:  3.9384217262268066 0.0790155827999115
CurrentTrain: epoch  9, batch    28 | loss: 4.0174375Losses:  3.9184353351593018 0.07521899044513702
CurrentTrain: epoch  9, batch    29 | loss: 3.9936543Losses:  3.95711612701416 0.07436211407184601
CurrentTrain: epoch  9, batch    30 | loss: 4.0314784Losses:  3.9257116317749023 0.06853853166103363
CurrentTrain: epoch  9, batch    31 | loss: 3.9942501Losses:  3.902616024017334 0.05786798521876335
CurrentTrain: epoch  9, batch    32 | loss: 3.9604840Losses:  3.907089948654175 0.0375053733587265
CurrentTrain: epoch  9, batch    33 | loss: 3.9445953Losses:  3.9339895248413086 0.0732303336262703
CurrentTrain: epoch  9, batch    34 | loss: 4.0072198Losses:  3.929975748062134 0.08887582272291183
CurrentTrain: epoch  9, batch    35 | loss: 4.0188518Losses:  3.92572283744812 0.03933723270893097
CurrentTrain: epoch  9, batch    36 | loss: 3.9650600Losses:  3.9178433418273926 0.08216167241334915
CurrentTrain: epoch  9, batch    37 | loss: 4.0000052Losses:  3.9847261905670166 0.05819900333881378
CurrentTrain: epoch  9, batch    38 | loss: 4.0429254Losses:  3.9474987983703613 0.0738968700170517
CurrentTrain: epoch  9, batch    39 | loss: 4.0213957Losses:  4.014360427856445 0.055056869983673096
CurrentTrain: epoch  9, batch    40 | loss: 4.0694175Losses:  3.9279141426086426 0.049522995948791504
CurrentTrain: epoch  9, batch    41 | loss: 3.9774370Losses:  3.9533114433288574 0.052053794264793396
CurrentTrain: epoch  9, batch    42 | loss: 4.0053654Losses:  3.9348087310791016 0.04845816269516945
CurrentTrain: epoch  9, batch    43 | loss: 3.9832668Losses:  3.9459502696990967 0.05353635549545288
CurrentTrain: epoch  9, batch    44 | loss: 3.9994867Losses:  3.9160666465759277 0.0517120361328125
CurrentTrain: epoch  9, batch    45 | loss: 3.9677787Losses:  3.920067310333252 0.04478020593523979
CurrentTrain: epoch  9, batch    46 | loss: 3.9648476Losses:  3.965264320373535 0.041214875876903534
CurrentTrain: epoch  9, batch    47 | loss: 4.0064793Losses:  3.935871124267578 0.06461238861083984
CurrentTrain: epoch  9, batch    48 | loss: 4.0004835Losses:  4.002085208892822 0.06587795168161392
CurrentTrain: epoch  9, batch    49 | loss: 4.0679631Losses:  3.951021909713745 0.07155817002058029
CurrentTrain: epoch  9, batch    50 | loss: 4.0225801Losses:  3.962510108947754 0.0653170645236969
CurrentTrain: epoch  9, batch    51 | loss: 4.0278273Losses:  3.9473493099212646 0.06176309287548065
CurrentTrain: epoch  9, batch    52 | loss: 4.0091124Losses:  3.9223737716674805 0.060956407338380814
CurrentTrain: epoch  9, batch    53 | loss: 3.9833302Losses:  3.9391095638275146 0.06381689012050629
CurrentTrain: epoch  9, batch    54 | loss: 4.0029263Losses:  3.929210662841797 0.06686221063137054
CurrentTrain: epoch  9, batch    55 | loss: 3.9960728Losses:  3.9031662940979004 0.06506551057100296
CurrentTrain: epoch  9, batch    56 | loss: 3.9682319Losses:  3.9452319145202637 0.07334085553884506
CurrentTrain: epoch  9, batch    57 | loss: 4.0185728Losses:  3.9048900604248047 0.06492292881011963
CurrentTrain: epoch  9, batch    58 | loss: 3.9698129Losses:  3.909623622894287 0.0627448558807373
CurrentTrain: epoch  9, batch    59 | loss: 3.9723685Losses:  3.9525914192199707 0.06829098612070084
CurrentTrain: epoch  9, batch    60 | loss: 4.0208826Losses:  3.938060998916626 0.06103646010160446
CurrentTrain: epoch  9, batch    61 | loss: 3.9990973Losses:  3.9408369064331055 0.041596997529268265
CurrentTrain: epoch  9, batch    62 | loss: 3.9824338
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 86.72%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 88.19%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 89.20%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 90.10%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.38%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 90.83%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 91.41%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 91.91%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 92.01%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 92.43%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 92.81%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 93.15%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 92.90%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 93.21%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 93.23%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 93.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 93.27%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 93.29%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 93.30%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 93.32%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 93.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 93.95%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 94.13%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 94.30%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 94.29%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 94.44%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 94.59%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 94.57%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 94.71%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 94.84%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 94.97%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 95.09%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 95.06%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 95.17%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 95.28%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 95.38%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 95.35%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 95.41%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 95.50%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 95.47%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 95.31%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 95.28%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 95.37%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 95.11%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 95.09%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 95.18%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 95.26%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 95.34%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 95.39%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 95.36%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 94.64%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 86.72%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 88.19%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 89.20%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 90.10%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.38%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 90.83%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 91.41%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 91.91%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 92.01%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 92.43%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 92.81%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 93.15%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 92.90%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 93.21%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 93.23%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 93.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 93.27%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 93.29%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 93.30%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 93.32%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 93.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 93.95%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 94.13%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 94.30%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 94.29%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 94.44%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 94.59%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 94.57%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 94.71%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 94.84%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 94.97%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 95.09%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 95.06%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 95.17%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 95.28%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 95.38%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 95.35%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 95.41%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 95.50%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 95.47%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 95.31%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 95.28%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 95.37%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 95.11%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 95.09%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 95.18%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 95.26%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 95.34%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 95.39%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 95.36%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 94.64%   
cur_acc:  ['0.9464']
his_acc:  ['0.9464']
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  8.038056373596191 1.9088565111160278
CurrentTrain: epoch  0, batch     0 | loss: 9.9469128Losses:  11.095834732055664 1.7062947750091553
CurrentTrain: epoch  0, batch     1 | loss: 12.8021297Losses:  9.367908477783203 1.5760053396224976
CurrentTrain: epoch  0, batch     2 | loss: 10.9439135Losses:  8.293981552124023 1.4911954402923584
CurrentTrain: epoch  0, batch     3 | loss: 9.7851772Losses:  4.377620697021484 1.247406005859375
CurrentTrain: epoch  1, batch     0 | loss: 5.6250267Losses:  4.991725921630859 1.6265745162963867
CurrentTrain: epoch  1, batch     1 | loss: 6.6183004Losses:  4.241397857666016 1.472503900527954
CurrentTrain: epoch  1, batch     2 | loss: 5.7139015Losses:  3.7035536766052246 1.0067105293273926
CurrentTrain: epoch  1, batch     3 | loss: 4.7102642Losses:  3.425936698913574 1.3241316080093384
CurrentTrain: epoch  2, batch     0 | loss: 4.7500682Losses:  3.0655627250671387 1.1593735218048096
CurrentTrain: epoch  2, batch     1 | loss: 4.2249365Losses:  3.7985520362854004 1.302858829498291
CurrentTrain: epoch  2, batch     2 | loss: 5.1014109Losses:  3.740652084350586 1.0910885334014893
CurrentTrain: epoch  2, batch     3 | loss: 4.8317404Losses:  3.27873158454895 1.3046135902404785
CurrentTrain: epoch  3, batch     0 | loss: 4.5833454Losses:  2.6486196517944336 1.3503211736679077
CurrentTrain: epoch  3, batch     1 | loss: 3.9989409Losses:  3.5017786026000977 0.9529003500938416
CurrentTrain: epoch  3, batch     2 | loss: 4.4546790Losses:  3.527153730392456 1.0368983745574951
CurrentTrain: epoch  3, batch     3 | loss: 4.5640521Losses:  3.2036876678466797 1.1818103790283203
CurrentTrain: epoch  4, batch     0 | loss: 4.3854980Losses:  2.9276204109191895 0.9931046962738037
CurrentTrain: epoch  4, batch     1 | loss: 3.9207251Losses:  2.742333173751831 0.9833561182022095
CurrentTrain: epoch  4, batch     2 | loss: 3.7256894Losses:  3.723219871520996 0.6957751512527466
CurrentTrain: epoch  4, batch     3 | loss: 4.4189949Losses:  3.2206320762634277 1.1721031665802002
CurrentTrain: epoch  5, batch     0 | loss: 4.3927355Losses:  2.835024356842041 0.9589809775352478
CurrentTrain: epoch  5, batch     1 | loss: 3.7940054Losses:  2.6101646423339844 1.063710331916809
CurrentTrain: epoch  5, batch     2 | loss: 3.6738749Losses:  3.347890853881836 1.0137722492218018
CurrentTrain: epoch  5, batch     3 | loss: 4.3616629Losses:  3.6397781372070312 1.166623830795288
CurrentTrain: epoch  6, batch     0 | loss: 4.8064022Losses:  2.5168051719665527 0.8466227054595947
CurrentTrain: epoch  6, batch     1 | loss: 3.3634279Losses:  2.422714948654175 0.8819018602371216
CurrentTrain: epoch  6, batch     2 | loss: 3.3046169Losses:  2.455427408218384 1.0534623861312866
CurrentTrain: epoch  6, batch     3 | loss: 3.5088897Losses:  2.3593554496765137 0.8429316282272339
CurrentTrain: epoch  7, batch     0 | loss: 3.2022872Losses:  2.6366474628448486 0.9103182554244995
CurrentTrain: epoch  7, batch     1 | loss: 3.5469656Losses:  2.873227119445801 0.9365545511245728
CurrentTrain: epoch  7, batch     2 | loss: 3.8097816Losses:  2.5612215995788574 0.9593214392662048
CurrentTrain: epoch  7, batch     3 | loss: 3.5205431Losses:  2.6790013313293457 0.927267849445343
CurrentTrain: epoch  8, batch     0 | loss: 3.6062691Losses:  2.159592390060425 0.7505923509597778
CurrentTrain: epoch  8, batch     1 | loss: 2.9101849Losses:  2.7417263984680176 0.9746994972229004
CurrentTrain: epoch  8, batch     2 | loss: 3.7164259Losses:  2.202434539794922 0.5834872722625732
CurrentTrain: epoch  8, batch     3 | loss: 2.7859218Losses:  2.007026195526123 0.8030223250389099
CurrentTrain: epoch  9, batch     0 | loss: 2.8100486Losses:  1.988023042678833 0.6713413000106812
CurrentTrain: epoch  9, batch     1 | loss: 2.6593642Losses:  3.0057597160339355 0.8562930226325989
CurrentTrain: epoch  9, batch     2 | loss: 3.8620527Losses:  2.3592891693115234 0.84816974401474
CurrentTrain: epoch  9, batch     3 | loss: 3.2074590
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 95.83%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 96.88%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 96.25%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 96.88%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 97.32%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 96.88%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 95.83%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 93.75%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 92.61%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 92.71%   [EVAL] batch:   12 | acc: 81.25%,  total acc: 91.83%   [EVAL] batch:   13 | acc: 81.25%,  total acc: 91.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 89.58%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 89.84%   [EVAL] batch:   16 | acc: 68.75%,  total acc: 88.60%   [EVAL] batch:   17 | acc: 81.25%,  total acc: 88.19%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 88.82%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 87.81%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 87.20%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 86.93%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 86.41%   [EVAL] batch:   23 | acc: 68.75%,  total acc: 85.68%   [EVAL] batch:   24 | acc: 75.00%,  total acc: 85.25%   [EVAL] batch:   25 | acc: 62.50%,  total acc: 84.38%   [EVAL] batch:   26 | acc: 68.75%,  total acc: 83.80%   [EVAL] batch:   27 | acc: 56.25%,  total acc: 82.81%   [EVAL] batch:   28 | acc: 81.25%,  total acc: 82.76%   [EVAL] batch:   29 | acc: 37.50%,  total acc: 81.25%   [EVAL] batch:   30 | acc: 31.25%,  total acc: 79.64%   [EVAL] batch:   31 | acc: 31.25%,  total acc: 78.12%   [EVAL] batch:   32 | acc: 43.75%,  total acc: 77.08%   [EVAL] batch:   33 | acc: 43.75%,  total acc: 76.10%   [EVAL] batch:   34 | acc: 43.75%,  total acc: 75.18%   [EVAL] batch:   35 | acc: 56.25%,  total acc: 74.65%   [EVAL] batch:   36 | acc: 37.50%,  total acc: 73.65%   [EVAL] batch:   37 | acc: 50.00%,  total acc: 73.03%   [EVAL] batch:   38 | acc: 68.75%,  total acc: 72.92%   [EVAL] batch:   39 | acc: 68.75%,  total acc: 72.81%   [EVAL] batch:   40 | acc: 68.75%,  total acc: 72.71%   [EVAL] batch:   41 | acc: 50.00%,  total acc: 72.17%   [EVAL] batch:   42 | acc: 81.25%,  total acc: 72.38%   [EVAL] batch:   43 | acc: 56.25%,  total acc: 72.02%   [EVAL] batch:   44 | acc: 25.00%,  total acc: 70.97%   [EVAL] batch:   45 | acc: 37.50%,  total acc: 70.24%   [EVAL] batch:   46 | acc: 43.75%,  total acc: 69.68%   [EVAL] batch:   47 | acc: 31.25%,  total acc: 68.88%   [EVAL] batch:   48 | acc: 25.00%,  total acc: 67.98%   [EVAL] batch:   49 | acc: 43.75%,  total acc: 67.50%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 68.14%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 68.75%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 69.34%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 69.91%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 70.45%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 70.98%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 71.27%   [EVAL] batch:   57 | acc: 87.50%,  total acc: 71.55%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 71.93%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 72.29%   [EVAL] batch:   60 | acc: 93.75%,  total acc: 72.64%   [EVAL] batch:   61 | acc: 100.00%,  total acc: 73.08%   [EVAL] batch:   62 | acc: 43.75%,  total acc: 72.62%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 89.58%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 81.25%,  total acc: 87.50%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 88.54%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 88.39%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 90.91%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 91.35%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 91.52%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 92.19%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 92.65%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 92.71%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 93.09%   [EVAL] batch:   19 | acc: 93.75%,  total acc: 93.12%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 93.15%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 92.61%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 92.39%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 92.19%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 92.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 92.31%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 92.36%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 92.41%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 92.67%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 92.92%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 93.15%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 93.16%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 93.18%   [EVAL] batch:   33 | acc: 68.75%,  total acc: 92.46%   [EVAL] batch:   34 | acc: 75.00%,  total acc: 91.96%   [EVAL] batch:   35 | acc: 81.25%,  total acc: 91.67%   [EVAL] batch:   36 | acc: 87.50%,  total acc: 91.55%   [EVAL] batch:   37 | acc: 87.50%,  total acc: 91.45%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 91.88%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 92.07%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 92.26%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 92.30%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 92.47%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 92.64%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 92.80%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 92.69%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 92.71%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 92.86%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 93.00%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 93.01%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 93.03%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 93.16%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 93.29%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 93.18%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 93.19%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 92.87%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 92.46%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 92.37%   [EVAL] batch:   59 | acc: 81.25%,  total acc: 92.19%   [EVAL] batch:   60 | acc: 81.25%,  total acc: 92.01%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 91.94%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 91.96%   [EVAL] batch:   63 | acc: 87.50%,  total acc: 91.89%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 92.02%   [EVAL] batch:   65 | acc: 100.00%,  total acc: 92.14%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 92.26%   [EVAL] batch:   67 | acc: 93.75%,  total acc: 92.28%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 92.39%   [EVAL] batch:   69 | acc: 93.75%,  total acc: 92.41%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 92.52%   [EVAL] batch:   71 | acc: 75.00%,  total acc: 92.27%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 92.21%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 92.06%   [EVAL] batch:   74 | acc: 81.25%,  total acc: 91.92%   [EVAL] batch:   75 | acc: 87.50%,  total acc: 91.86%   [EVAL] batch:   76 | acc: 75.00%,  total acc: 91.64%   [EVAL] batch:   77 | acc: 81.25%,  total acc: 91.51%   [EVAL] batch:   78 | acc: 81.25%,  total acc: 91.38%   [EVAL] batch:   79 | acc: 68.75%,  total acc: 91.09%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 91.13%   [EVAL] batch:   81 | acc: 93.75%,  total acc: 91.16%   [EVAL] batch:   82 | acc: 56.25%,  total acc: 90.74%   [EVAL] batch:   83 | acc: 87.50%,  total acc: 90.70%   [EVAL] batch:   84 | acc: 68.75%,  total acc: 90.44%   [EVAL] batch:   85 | acc: 75.00%,  total acc: 90.26%   [EVAL] batch:   86 | acc: 68.75%,  total acc: 90.01%   [EVAL] batch:   87 | acc: 81.25%,  total acc: 89.91%   [EVAL] batch:   88 | acc: 62.50%,  total acc: 89.61%   [EVAL] batch:   89 | acc: 50.00%,  total acc: 89.17%   [EVAL] batch:   90 | acc: 75.00%,  total acc: 89.01%   [EVAL] batch:   91 | acc: 62.50%,  total acc: 88.72%   [EVAL] batch:   92 | acc: 37.50%,  total acc: 88.17%   [EVAL] batch:   93 | acc: 31.25%,  total acc: 87.57%   [EVAL] batch:   94 | acc: 37.50%,  total acc: 87.04%   [EVAL] batch:   95 | acc: 31.25%,  total acc: 86.46%   [EVAL] batch:   96 | acc: 56.25%,  total acc: 86.15%   [EVAL] batch:   97 | acc: 43.75%,  total acc: 85.71%   [EVAL] batch:   98 | acc: 62.50%,  total acc: 85.48%   [EVAL] batch:   99 | acc: 25.00%,  total acc: 84.88%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 84.59%   [EVAL] batch:  101 | acc: 75.00%,  total acc: 84.50%   [EVAL] batch:  102 | acc: 68.75%,  total acc: 84.34%   [EVAL] batch:  103 | acc: 56.25%,  total acc: 84.07%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 83.93%   [EVAL] batch:  105 | acc: 75.00%,  total acc: 83.84%   [EVAL] batch:  106 | acc: 43.75%,  total acc: 83.47%   [EVAL] batch:  107 | acc: 25.00%,  total acc: 82.93%   [EVAL] batch:  108 | acc: 43.75%,  total acc: 82.57%   [EVAL] batch:  109 | acc: 31.25%,  total acc: 82.10%   [EVAL] batch:  110 | acc: 25.00%,  total acc: 81.59%   [EVAL] batch:  111 | acc: 43.75%,  total acc: 81.25%   [EVAL] batch:  112 | acc: 68.75%,  total acc: 81.14%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 81.30%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 81.47%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 81.63%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 81.78%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 81.94%   [EVAL] batch:  118 | acc: 93.75%,  total acc: 82.04%   [EVAL] batch:  119 | acc: 81.25%,  total acc: 82.03%   [EVAL] batch:  120 | acc: 93.75%,  total acc: 82.13%   [EVAL] batch:  121 | acc: 93.75%,  total acc: 82.22%   [EVAL] batch:  122 | acc: 100.00%,  total acc: 82.37%   [EVAL] batch:  123 | acc: 93.75%,  total acc: 82.46%   [EVAL] batch:  124 | acc: 93.75%,  total acc: 82.55%   
cur_acc:  ['0.9464', '0.7262']
his_acc:  ['0.9464', '0.8255']
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.42041015625 1.7102506160736084
CurrentTrain: epoch  0, batch     0 | loss: 9.1306610Losses:  10.141033172607422 1.6918766498565674
CurrentTrain: epoch  0, batch     1 | loss: 11.8329096Losses:  8.832748413085938 1.7637474536895752
CurrentTrain: epoch  0, batch     2 | loss: 10.5964956Losses:  9.4554443359375 1.2870525121688843
CurrentTrain: epoch  0, batch     3 | loss: 10.7424965Losses:  8.86431884765625 1.1022124290466309
CurrentTrain: epoch  0, batch     4 | loss: 9.9665318Losses:  3.776312828063965 1.5461692810058594
CurrentTrain: epoch  1, batch     0 | loss: 5.3224821Losses:  4.243958473205566 1.2302310466766357
CurrentTrain: epoch  1, batch     1 | loss: 5.4741898Losses:  3.7862722873687744 1.4633357524871826
CurrentTrain: epoch  1, batch     2 | loss: 5.2496080Losses:  3.132256031036377 1.3013700246810913
CurrentTrain: epoch  1, batch     3 | loss: 4.4336262Losses:  2.8154714107513428 0.7585451006889343
CurrentTrain: epoch  1, batch     4 | loss: 3.5740166Losses:  3.098212718963623 1.4626394510269165
CurrentTrain: epoch  2, batch     0 | loss: 4.5608521Losses:  3.4919586181640625 1.3912041187286377
CurrentTrain: epoch  2, batch     1 | loss: 4.8831625Losses:  3.176116466522217 1.3674230575561523
CurrentTrain: epoch  2, batch     2 | loss: 4.5435395Losses:  3.662853479385376 1.160658836364746
CurrentTrain: epoch  2, batch     3 | loss: 4.8235121Losses:  2.6753578186035156 0.7129400968551636
CurrentTrain: epoch  2, batch     4 | loss: 3.3882980Losses:  3.1872000694274902 1.3458423614501953
CurrentTrain: epoch  3, batch     0 | loss: 4.5330424Losses:  3.6127376556396484 1.3155038356781006
CurrentTrain: epoch  3, batch     1 | loss: 4.9282417Losses:  2.691793441772461 1.0771098136901855
CurrentTrain: epoch  3, batch     2 | loss: 3.7689033Losses:  2.5669808387756348 1.1397114992141724
CurrentTrain: epoch  3, batch     3 | loss: 3.7066922Losses:  2.8092970848083496 0.6602177619934082
CurrentTrain: epoch  3, batch     4 | loss: 3.4695148Losses:  3.0042147636413574 1.213735818862915
CurrentTrain: epoch  4, batch     0 | loss: 4.2179508Losses:  2.560129404067993 0.9255929589271545
CurrentTrain: epoch  4, batch     1 | loss: 3.4857223Losses:  2.7934489250183105 1.4470608234405518
CurrentTrain: epoch  4, batch     2 | loss: 4.2405100Losses:  2.8600592613220215 1.14734947681427
CurrentTrain: epoch  4, batch     3 | loss: 4.0074086Losses:  2.9148852825164795 0.5346941351890564
CurrentTrain: epoch  4, batch     4 | loss: 3.4495795Losses:  2.541893482208252 1.2964808940887451
CurrentTrain: epoch  5, batch     0 | loss: 3.8383744Losses:  3.3052616119384766 0.9385356903076172
CurrentTrain: epoch  5, batch     1 | loss: 4.2437973Losses:  2.168588161468506 0.8703811168670654
CurrentTrain: epoch  5, batch     2 | loss: 3.0389693Losses:  2.5160627365112305 1.153273105621338
CurrentTrain: epoch  5, batch     3 | loss: 3.6693358Losses:  2.8541831970214844 0.6042904853820801
CurrentTrain: epoch  5, batch     4 | loss: 3.4584737Losses:  2.8757543563842773 1.1510529518127441
CurrentTrain: epoch  6, batch     0 | loss: 4.0268073Losses:  2.6199231147766113 1.0842869281768799
CurrentTrain: epoch  6, batch     1 | loss: 3.7042100Losses:  2.2228779792785645 1.107756495475769
CurrentTrain: epoch  6, batch     2 | loss: 3.3306346Losses:  2.160205364227295 0.8637580871582031
CurrentTrain: epoch  6, batch     3 | loss: 3.0239635Losses:  2.450039863586426 0.5678734183311462
CurrentTrain: epoch  6, batch     4 | loss: 3.0179133Losses:  2.42508602142334 0.8942556381225586
CurrentTrain: epoch  7, batch     0 | loss: 3.3193417Losses:  2.3543803691864014 1.0284152030944824
CurrentTrain: epoch  7, batch     1 | loss: 3.3827956Losses:  1.7873263359069824 0.9698368906974792
CurrentTrain: epoch  7, batch     2 | loss: 2.7571633Losses:  2.467111587524414 1.0806330442428589
CurrentTrain: epoch  7, batch     3 | loss: 3.5477448Losses:  3.0619189739227295 0.8192986249923706
CurrentTrain: epoch  7, batch     4 | loss: 3.8812175Losses:  2.1275558471679688 1.0399068593978882
CurrentTrain: epoch  8, batch     0 | loss: 3.1674628Losses:  2.2324609756469727 1.006809949874878
CurrentTrain: epoch  8, batch     1 | loss: 3.2392709Losses:  2.530548095703125 0.9415555596351624
CurrentTrain: epoch  8, batch     2 | loss: 3.4721036Losses:  2.210622787475586 0.6834076642990112
CurrentTrain: epoch  8, batch     3 | loss: 2.8940306Losses:  2.0033748149871826 0.4398075342178345
CurrentTrain: epoch  8, batch     4 | loss: 2.4431825Losses:  1.877216100692749 0.8762209415435791
CurrentTrain: epoch  9, batch     0 | loss: 2.7534370Losses:  2.1340417861938477 0.8129956722259521
CurrentTrain: epoch  9, batch     1 | loss: 2.9470375Losses:  1.978727102279663 0.8439932465553284
CurrentTrain: epoch  9, batch     2 | loss: 2.8227203Losses:  2.460109233856201 0.8438977003097534
CurrentTrain: epoch  9, batch     3 | loss: 3.3040071Losses:  2.5431458950042725 0.6728967428207397
CurrentTrain: epoch  9, batch     4 | loss: 3.2160425
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 68.75%,  total acc: 75.00%   [EVAL] batch:    2 | acc: 68.75%,  total acc: 72.92%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 75.00%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 77.08%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 79.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 82.03%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 82.64%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 83.12%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 84.09%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 83.85%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 83.17%   [EVAL] batch:   13 | acc: 18.75%,  total acc: 78.57%   [EVAL] batch:   14 | acc: 31.25%,  total acc: 75.42%   [EVAL] batch:   15 | acc: 25.00%,  total acc: 72.27%   [EVAL] batch:   16 | acc: 50.00%,  total acc: 70.96%   [EVAL] batch:   17 | acc: 43.75%,  total acc: 69.44%   [EVAL] batch:   18 | acc: 31.25%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 69.06%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 70.54%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 71.59%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 72.83%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 73.96%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 75.00%   [EVAL] batch:   25 | acc: 37.50%,  total acc: 73.56%   [EVAL] batch:   26 | acc: 6.25%,  total acc: 71.06%   [EVAL] batch:   27 | acc: 25.00%,  total acc: 69.42%   [EVAL] batch:   28 | acc: 18.75%,  total acc: 67.67%   [EVAL] batch:   29 | acc: 12.50%,  total acc: 65.83%   [EVAL] batch:   30 | acc: 18.75%,  total acc: 64.31%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 64.65%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 65.53%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 66.36%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 67.14%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 67.88%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 68.58%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 69.41%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 70.19%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 70.94%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 71.65%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 72.32%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 72.97%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 73.58%   [EVAL] batch:   44 | acc: 87.50%,  total acc: 73.89%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 74.18%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 74.47%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 74.61%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 75.13%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 75.50%   [EVAL] batch:   50 | acc: 81.25%,  total acc: 75.61%   [EVAL] batch:   51 | acc: 81.25%,  total acc: 75.72%   [EVAL] batch:   52 | acc: 68.75%,  total acc: 75.59%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 75.93%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 76.25%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 76.45%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 76.43%   [EVAL] batch:   57 | acc: 81.25%,  total acc: 76.51%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 76.69%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 76.67%   [EVAL] batch:   60 | acc: 87.50%,  total acc: 76.84%   [EVAL] batch:   61 | acc: 68.75%,  total acc: 76.71%   [EVAL] batch:   62 | acc: 37.50%,  total acc: 76.09%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 82.50%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 83.93%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 84.03%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 85.62%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 84.66%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 84.62%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 85.27%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 85.83%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 86.72%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 87.85%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 88.49%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 89.06%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 89.29%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 88.92%   [EVAL] batch:   22 | acc: 93.75%,  total acc: 89.13%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 89.06%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 89.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 89.42%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 89.58%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 89.96%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 90.30%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 90.93%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 91.21%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 91.48%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 91.36%   [EVAL] batch:   34 | acc: 75.00%,  total acc: 90.89%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 90.97%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 91.22%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 91.45%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 91.88%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 92.07%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 92.26%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 92.30%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 92.47%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 92.64%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 92.80%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 92.82%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 92.84%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 92.98%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 93.12%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 93.14%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 93.15%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 93.28%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 93.40%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 93.30%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 93.30%   [EVAL] batch:   56 | acc: 62.50%,  total acc: 92.76%   [EVAL] batch:   57 | acc: 56.25%,  total acc: 92.13%   [EVAL] batch:   58 | acc: 56.25%,  total acc: 91.53%   [EVAL] batch:   59 | acc: 68.75%,  total acc: 91.15%   [EVAL] batch:   60 | acc: 56.25%,  total acc: 90.57%   [EVAL] batch:   61 | acc: 75.00%,  total acc: 90.32%   [EVAL] batch:   62 | acc: 87.50%,  total acc: 90.28%   [EVAL] batch:   63 | acc: 75.00%,  total acc: 90.04%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 90.19%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 90.15%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 90.30%   [EVAL] batch:   67 | acc: 87.50%,  total acc: 90.26%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 90.40%   [EVAL] batch:   69 | acc: 93.75%,  total acc: 90.45%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 90.58%   [EVAL] batch:   71 | acc: 75.00%,  total acc: 90.36%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 90.33%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 90.20%   [EVAL] batch:   74 | acc: 87.50%,  total acc: 90.17%   [EVAL] batch:   75 | acc: 93.75%,  total acc: 90.21%   [EVAL] batch:   76 | acc: 81.25%,  total acc: 90.10%   [EVAL] batch:   77 | acc: 81.25%,  total acc: 89.98%   [EVAL] batch:   78 | acc: 81.25%,  total acc: 89.87%   [EVAL] batch:   79 | acc: 87.50%,  total acc: 89.84%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 89.89%   [EVAL] batch:   81 | acc: 81.25%,  total acc: 89.79%   [EVAL] batch:   82 | acc: 50.00%,  total acc: 89.31%   [EVAL] batch:   83 | acc: 56.25%,  total acc: 88.91%   [EVAL] batch:   84 | acc: 62.50%,  total acc: 88.60%   [EVAL] batch:   85 | acc: 62.50%,  total acc: 88.30%   [EVAL] batch:   86 | acc: 50.00%,  total acc: 87.86%   [EVAL] batch:   87 | acc: 68.75%,  total acc: 87.64%   [EVAL] batch:   88 | acc: 56.25%,  total acc: 87.29%   [EVAL] batch:   89 | acc: 50.00%,  total acc: 86.88%   [EVAL] batch:   90 | acc: 93.75%,  total acc: 86.95%   [EVAL] batch:   91 | acc: 68.75%,  total acc: 86.75%   [EVAL] batch:   92 | acc: 43.75%,  total acc: 86.29%   [EVAL] batch:   93 | acc: 43.75%,  total acc: 85.84%   [EVAL] batch:   94 | acc: 37.50%,  total acc: 85.33%   [EVAL] batch:   95 | acc: 31.25%,  total acc: 84.77%   [EVAL] batch:   96 | acc: 56.25%,  total acc: 84.47%   [EVAL] batch:   97 | acc: 50.00%,  total acc: 84.12%   [EVAL] batch:   98 | acc: 68.75%,  total acc: 83.96%   [EVAL] batch:   99 | acc: 37.50%,  total acc: 83.50%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 83.23%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 83.03%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 82.77%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 82.57%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 82.44%   [EVAL] batch:  105 | acc: 62.50%,  total acc: 82.25%   [EVAL] batch:  106 | acc: 43.75%,  total acc: 81.89%   [EVAL] batch:  107 | acc: 25.00%,  total acc: 81.37%   [EVAL] batch:  108 | acc: 25.00%,  total acc: 80.85%   [EVAL] batch:  109 | acc: 12.50%,  total acc: 80.23%   [EVAL] batch:  110 | acc: 31.25%,  total acc: 79.79%   [EVAL] batch:  111 | acc: 37.50%,  total acc: 79.41%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 79.20%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 79.39%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 79.57%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 79.74%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 79.91%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 80.08%   [EVAL] batch:  118 | acc: 100.00%,  total acc: 80.25%   [EVAL] batch:  119 | acc: 81.25%,  total acc: 80.26%   [EVAL] batch:  120 | acc: 87.50%,  total acc: 80.32%   [EVAL] batch:  121 | acc: 100.00%,  total acc: 80.48%   [EVAL] batch:  122 | acc: 93.75%,  total acc: 80.59%   [EVAL] batch:  123 | acc: 75.00%,  total acc: 80.54%   [EVAL] batch:  124 | acc: 93.75%,  total acc: 80.65%   [EVAL] batch:  125 | acc: 81.25%,  total acc: 80.65%   [EVAL] batch:  126 | acc: 68.75%,  total acc: 80.56%   [EVAL] batch:  127 | acc: 68.75%,  total acc: 80.47%   [EVAL] batch:  128 | acc: 81.25%,  total acc: 80.47%   [EVAL] batch:  129 | acc: 75.00%,  total acc: 80.43%   [EVAL] batch:  130 | acc: 87.50%,  total acc: 80.49%   [EVAL] batch:  131 | acc: 93.75%,  total acc: 80.59%   [EVAL] batch:  132 | acc: 100.00%,  total acc: 80.73%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 80.78%   [EVAL] batch:  134 | acc: 87.50%,  total acc: 80.83%   [EVAL] batch:  135 | acc: 93.75%,  total acc: 80.93%   [EVAL] batch:  136 | acc: 81.25%,  total acc: 80.93%   [EVAL] batch:  137 | acc: 75.00%,  total acc: 80.89%   [EVAL] batch:  138 | acc: 18.75%,  total acc: 80.44%   [EVAL] batch:  139 | acc: 31.25%,  total acc: 80.09%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 79.70%   [EVAL] batch:  141 | acc: 50.00%,  total acc: 79.49%   [EVAL] batch:  142 | acc: 43.75%,  total acc: 79.24%   [EVAL] batch:  143 | acc: 31.25%,  total acc: 78.91%   [EVAL] batch:  144 | acc: 100.00%,  total acc: 79.05%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 79.20%   [EVAL] batch:  146 | acc: 93.75%,  total acc: 79.29%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 79.43%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 79.57%   [EVAL] batch:  149 | acc: 100.00%,  total acc: 79.71%   [EVAL] batch:  150 | acc: 37.50%,  total acc: 79.43%   [EVAL] batch:  151 | acc: 6.25%,  total acc: 78.95%   [EVAL] batch:  152 | acc: 25.00%,  total acc: 78.59%   [EVAL] batch:  153 | acc: 18.75%,  total acc: 78.21%   [EVAL] batch:  154 | acc: 12.50%,  total acc: 77.78%   [EVAL] batch:  155 | acc: 18.75%,  total acc: 77.40%   [EVAL] batch:  156 | acc: 75.00%,  total acc: 77.39%   [EVAL] batch:  157 | acc: 93.75%,  total acc: 77.49%   [EVAL] batch:  158 | acc: 93.75%,  total acc: 77.59%   [EVAL] batch:  159 | acc: 93.75%,  total acc: 77.70%   [EVAL] batch:  160 | acc: 93.75%,  total acc: 77.80%   [EVAL] batch:  161 | acc: 93.75%,  total acc: 77.89%   [EVAL] batch:  162 | acc: 100.00%,  total acc: 78.03%   [EVAL] batch:  163 | acc: 100.00%,  total acc: 78.16%   [EVAL] batch:  164 | acc: 100.00%,  total acc: 78.30%   [EVAL] batch:  165 | acc: 100.00%,  total acc: 78.43%   [EVAL] batch:  166 | acc: 100.00%,  total acc: 78.56%   [EVAL] batch:  167 | acc: 100.00%,  total acc: 78.68%   [EVAL] batch:  168 | acc: 100.00%,  total acc: 78.81%   [EVAL] batch:  169 | acc: 87.50%,  total acc: 78.86%   [EVAL] batch:  170 | acc: 87.50%,  total acc: 78.91%   [EVAL] batch:  171 | acc: 87.50%,  total acc: 78.96%   [EVAL] batch:  172 | acc: 81.25%,  total acc: 78.97%   [EVAL] batch:  173 | acc: 100.00%,  total acc: 79.09%   [EVAL] batch:  174 | acc: 93.75%,  total acc: 79.18%   [EVAL] batch:  175 | acc: 81.25%,  total acc: 79.19%   [EVAL] batch:  176 | acc: 81.25%,  total acc: 79.20%   [EVAL] batch:  177 | acc: 68.75%,  total acc: 79.14%   [EVAL] batch:  178 | acc: 93.75%,  total acc: 79.22%   [EVAL] batch:  179 | acc: 93.75%,  total acc: 79.31%   [EVAL] batch:  180 | acc: 87.50%,  total acc: 79.35%   [EVAL] batch:  181 | acc: 75.00%,  total acc: 79.33%   [EVAL] batch:  182 | acc: 81.25%,  total acc: 79.34%   [EVAL] batch:  183 | acc: 87.50%,  total acc: 79.38%   [EVAL] batch:  184 | acc: 75.00%,  total acc: 79.36%   [EVAL] batch:  185 | acc: 87.50%,  total acc: 79.40%   [EVAL] batch:  186 | acc: 68.75%,  total acc: 79.34%   [EVAL] batch:  187 | acc: 37.50%,  total acc: 79.12%   
cur_acc:  ['0.9464', '0.7262', '0.7609']
his_acc:  ['0.9464', '0.8255', '0.7912']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0]
Losses:  7.1492438316345215 1.0416806936264038
CurrentTrain: epoch  0, batch     0 | loss: 8.1909246Losses:  11.442682266235352 1.253596305847168
CurrentTrain: epoch  0, batch     1 | loss: 12.6962786Losses:  9.595638275146484 1.1022312641143799
CurrentTrain: epoch  0, batch     2 | loss: 10.6978693Losses:  9.394940376281738 1.274117112159729
CurrentTrain: epoch  0, batch     3 | loss: 10.6690578Losses:  9.759407043457031 0.9185456037521362
CurrentTrain: epoch  0, batch     4 | loss: 10.6779528Losses:  3.1814491748809814 1.5503830909729004
CurrentTrain: epoch  1, batch     0 | loss: 4.7318325Losses:  2.4175803661346436 1.14247465133667
CurrentTrain: epoch  1, batch     1 | loss: 3.5600550Losses:  3.58174991607666 1.2967909574508667
CurrentTrain: epoch  1, batch     2 | loss: 4.8785410Losses:  2.733750343322754 0.9593753218650818
CurrentTrain: epoch  1, batch     3 | loss: 3.6931257Losses:  3.03609037399292 1.2662851810455322
CurrentTrain: epoch  1, batch     4 | loss: 4.3023758Losses:  2.607701063156128 1.1402931213378906
CurrentTrain: epoch  2, batch     0 | loss: 3.7479942Losses:  2.553110122680664 0.9854349493980408
CurrentTrain: epoch  2, batch     1 | loss: 3.5385451Losses:  2.750749111175537 1.2794619798660278
CurrentTrain: epoch  2, batch     2 | loss: 4.0302110Losses:  2.3440399169921875 1.1678521633148193
CurrentTrain: epoch  2, batch     3 | loss: 3.5118921Losses:  3.0342752933502197 1.0065072774887085
CurrentTrain: epoch  2, batch     4 | loss: 4.0407825Losses:  2.1812591552734375 1.1529536247253418
CurrentTrain: epoch  3, batch     0 | loss: 3.3342128Losses:  2.4886367321014404 0.9903815388679504
CurrentTrain: epoch  3, batch     1 | loss: 3.4790182Losses:  2.446849822998047 1.0429742336273193
CurrentTrain: epoch  3, batch     2 | loss: 3.4898241Losses:  2.31296443939209 1.0930370092391968
CurrentTrain: epoch  3, batch     3 | loss: 3.4060016Losses:  2.479400157928467 1.190468668937683
CurrentTrain: epoch  3, batch     4 | loss: 3.6698689Losses:  1.7714694738388062 0.9866752028465271
CurrentTrain: epoch  4, batch     0 | loss: 2.7581446Losses:  2.3304877281188965 1.0050090551376343
CurrentTrain: epoch  4, batch     1 | loss: 3.3354969Losses:  1.7884364128112793 1.0562900304794312
CurrentTrain: epoch  4, batch     2 | loss: 2.8447266Losses:  2.5708508491516113 0.8224073052406311
CurrentTrain: epoch  4, batch     3 | loss: 3.3932581Losses:  2.4834718704223633 1.020151138305664
CurrentTrain: epoch  4, batch     4 | loss: 3.5036230Losses:  2.092139959335327 0.8232161998748779
CurrentTrain: epoch  5, batch     0 | loss: 2.9153562Losses:  1.6360161304473877 0.9506387710571289
CurrentTrain: epoch  5, batch     1 | loss: 2.5866549Losses:  2.2653465270996094 1.0686854124069214
CurrentTrain: epoch  5, batch     2 | loss: 3.3340321Losses:  2.2064754962921143 1.1856586933135986
CurrentTrain: epoch  5, batch     3 | loss: 3.3921342Losses:  2.125326156616211 0.7067233920097351
CurrentTrain: epoch  5, batch     4 | loss: 2.8320496Losses:  1.664878487586975 0.9454514980316162
CurrentTrain: epoch  6, batch     0 | loss: 2.6103301Losses:  2.067924737930298 0.7902653217315674
CurrentTrain: epoch  6, batch     1 | loss: 2.8581901Losses:  2.160778522491455 0.8792456388473511
CurrentTrain: epoch  6, batch     2 | loss: 3.0400243Losses:  1.7227897644042969 0.8133844137191772
CurrentTrain: epoch  6, batch     3 | loss: 2.5361743Losses:  2.0931081771850586 0.9931237697601318
CurrentTrain: epoch  6, batch     4 | loss: 3.0862319Losses:  1.8432782888412476 0.6456339359283447
CurrentTrain: epoch  7, batch     0 | loss: 2.4889121Losses:  2.076859712600708 0.8791943192481995
CurrentTrain: epoch  7, batch     1 | loss: 2.9560540Losses:  1.6165802478790283 0.7960338592529297
CurrentTrain: epoch  7, batch     2 | loss: 2.4126141Losses:  1.845747709274292 0.9879409670829773
CurrentTrain: epoch  7, batch     3 | loss: 2.8336887Losses:  2.0134119987487793 0.6835190653800964
CurrentTrain: epoch  7, batch     4 | loss: 2.6969311Losses:  1.9591424465179443 0.9258140325546265
CurrentTrain: epoch  8, batch     0 | loss: 2.8849564Losses:  1.6308444738388062 0.818558931350708
CurrentTrain: epoch  8, batch     1 | loss: 2.4494033Losses:  1.6438965797424316 0.7311378717422485
CurrentTrain: epoch  8, batch     2 | loss: 2.3750343Losses:  2.0198028087615967 0.7297357320785522
CurrentTrain: epoch  8, batch     3 | loss: 2.7495384Losses:  1.801303744316101 0.932216227054596
CurrentTrain: epoch  8, batch     4 | loss: 2.7335200Losses:  1.9788517951965332 0.650251030921936
CurrentTrain: epoch  9, batch     0 | loss: 2.6291027Losses:  1.37333083152771 0.6478475332260132
CurrentTrain: epoch  9, batch     1 | loss: 2.0211782Losses:  1.6729536056518555 0.7987329959869385
CurrentTrain: epoch  9, batch     2 | loss: 2.4716866Losses:  1.4947580099105835 0.7752814292907715
CurrentTrain: epoch  9, batch     3 | loss: 2.2700396Losses:  2.090301752090454 0.856550931930542
CurrentTrain: epoch  9, batch     4 | loss: 2.9468527
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 89.58%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 88.39%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 88.89%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 88.07%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 86.46%   [EVAL] batch:   12 | acc: 81.25%,  total acc: 86.06%   [EVAL] batch:   13 | acc: 75.00%,  total acc: 85.27%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 84.58%   [EVAL] batch:   15 | acc: 62.50%,  total acc: 83.20%   [EVAL] batch:   16 | acc: 62.50%,  total acc: 81.99%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 80.90%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 79.93%   [EVAL] batch:   19 | acc: 31.25%,  total acc: 77.50%   [EVAL] batch:   20 | acc: 50.00%,  total acc: 76.19%   [EVAL] batch:   21 | acc: 37.50%,  total acc: 74.43%   [EVAL] batch:   22 | acc: 37.50%,  total acc: 72.83%   [EVAL] batch:   23 | acc: 25.00%,  total acc: 70.83%   [EVAL] batch:   24 | acc: 31.25%,  total acc: 69.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 70.43%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 71.53%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 72.54%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 73.49%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 74.38%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   31 | acc: 87.50%,  total acc: 75.59%   [EVAL] batch:   32 | acc: 81.25%,  total acc: 75.76%   [EVAL] batch:   33 | acc: 81.25%,  total acc: 75.92%   [EVAL] batch:   34 | acc: 87.50%,  total acc: 76.25%   [EVAL] batch:   35 | acc: 75.00%,  total acc: 76.22%   [EVAL] batch:   36 | acc: 81.25%,  total acc: 76.35%   [EVAL] batch:   37 | acc: 75.00%,  total acc: 76.32%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 76.92%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 77.50%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 78.05%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 78.57%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 79.07%   [EVAL] batch:   43 | acc: 93.75%,  total acc: 79.40%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 79.86%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 80.30%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 80.72%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 81.12%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 81.51%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 81.88%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 82.23%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 82.57%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 82.78%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 83.10%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 83.41%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 83.71%   [EVAL] batch:   56 | acc: 93.75%,  total acc: 83.88%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 84.05%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 84.11%   [EVAL] batch:   59 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 84.63%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 84.78%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 84.23%   
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 82.14%   [EVAL] batch:    7 | acc: 75.00%,  total acc: 81.25%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    9 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:   10 | acc: 62.50%,  total acc: 79.55%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 78.65%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 78.37%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 79.46%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 80.42%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 81.64%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 82.35%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 82.99%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 83.88%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 84.06%   [EVAL] batch:   20 | acc: 81.25%,  total acc: 83.93%   [EVAL] batch:   21 | acc: 75.00%,  total acc: 83.52%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 83.42%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 83.59%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 83.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 84.95%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 85.49%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 85.78%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 86.25%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 86.69%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 87.11%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 87.32%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 87.84%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 88.16%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 88.46%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 88.75%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 89.02%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 89.29%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 89.53%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 89.77%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 90.00%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 90.08%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 90.03%   [EVAL] batch:   47 | acc: 87.50%,  total acc: 89.97%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 90.05%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 90.25%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 90.32%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 90.26%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 90.45%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 90.45%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 90.51%   [EVAL] batch:   56 | acc: 62.50%,  total acc: 90.02%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 89.55%   [EVAL] batch:   58 | acc: 68.75%,  total acc: 89.19%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 88.96%   [EVAL] batch:   60 | acc: 68.75%,  total acc: 88.63%   [EVAL] batch:   61 | acc: 75.00%,  total acc: 88.41%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 88.49%   [EVAL] batch:   63 | acc: 81.25%,  total acc: 88.38%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 88.56%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 88.54%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 88.71%   [EVAL] batch:   67 | acc: 93.75%,  total acc: 88.79%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 88.95%   [EVAL] batch:   69 | acc: 93.75%,  total acc: 89.02%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 89.17%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 88.89%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 88.87%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 88.77%   [EVAL] batch:   74 | acc: 93.75%,  total acc: 88.83%   [EVAL] batch:   75 | acc: 87.50%,  total acc: 88.82%   [EVAL] batch:   76 | acc: 81.25%,  total acc: 88.72%   [EVAL] batch:   77 | acc: 81.25%,  total acc: 88.62%   [EVAL] batch:   78 | acc: 81.25%,  total acc: 88.53%   [EVAL] batch:   79 | acc: 81.25%,  total acc: 88.44%   [EVAL] batch:   80 | acc: 87.50%,  total acc: 88.43%   [EVAL] batch:   81 | acc: 75.00%,  total acc: 88.26%   [EVAL] batch:   82 | acc: 43.75%,  total acc: 87.73%   [EVAL] batch:   83 | acc: 50.00%,  total acc: 87.28%   [EVAL] batch:   84 | acc: 50.00%,  total acc: 86.84%   [EVAL] batch:   85 | acc: 75.00%,  total acc: 86.70%   [EVAL] batch:   86 | acc: 37.50%,  total acc: 86.14%   [EVAL] batch:   87 | acc: 75.00%,  total acc: 86.01%   [EVAL] batch:   88 | acc: 68.75%,  total acc: 85.81%   [EVAL] batch:   89 | acc: 68.75%,  total acc: 85.62%   [EVAL] batch:   90 | acc: 93.75%,  total acc: 85.71%   [EVAL] batch:   91 | acc: 75.00%,  total acc: 85.60%   [EVAL] batch:   92 | acc: 68.75%,  total acc: 85.42%   [EVAL] batch:   93 | acc: 56.25%,  total acc: 85.11%   [EVAL] batch:   94 | acc: 37.50%,  total acc: 84.61%   [EVAL] batch:   95 | acc: 31.25%,  total acc: 84.05%   [EVAL] batch:   96 | acc: 50.00%,  total acc: 83.70%   [EVAL] batch:   97 | acc: 37.50%,  total acc: 83.23%   [EVAL] batch:   98 | acc: 56.25%,  total acc: 82.95%   [EVAL] batch:   99 | acc: 37.50%,  total acc: 82.50%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 82.24%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 82.05%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 81.80%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 81.61%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 81.49%   [EVAL] batch:  105 | acc: 62.50%,  total acc: 81.31%   [EVAL] batch:  106 | acc: 43.75%,  total acc: 80.96%   [EVAL] batch:  107 | acc: 6.25%,  total acc: 80.27%   [EVAL] batch:  108 | acc: 18.75%,  total acc: 79.70%   [EVAL] batch:  109 | acc: 6.25%,  total acc: 79.03%   [EVAL] batch:  110 | acc: 25.00%,  total acc: 78.55%   [EVAL] batch:  111 | acc: 31.25%,  total acc: 78.12%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 77.93%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 78.12%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 78.32%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 78.50%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 78.69%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 78.87%   [EVAL] batch:  118 | acc: 100.00%,  total acc: 79.04%   [EVAL] batch:  119 | acc: 93.75%,  total acc: 79.17%   [EVAL] batch:  120 | acc: 93.75%,  total acc: 79.29%   [EVAL] batch:  121 | acc: 100.00%,  total acc: 79.46%   [EVAL] batch:  122 | acc: 100.00%,  total acc: 79.62%   [EVAL] batch:  123 | acc: 87.50%,  total acc: 79.69%   [EVAL] batch:  124 | acc: 100.00%,  total acc: 79.85%   [EVAL] batch:  125 | acc: 81.25%,  total acc: 79.86%   [EVAL] batch:  126 | acc: 50.00%,  total acc: 79.63%   [EVAL] batch:  127 | acc: 68.75%,  total acc: 79.54%   [EVAL] batch:  128 | acc: 81.25%,  total acc: 79.55%   [EVAL] batch:  129 | acc: 62.50%,  total acc: 79.42%   [EVAL] batch:  130 | acc: 75.00%,  total acc: 79.39%   [EVAL] batch:  131 | acc: 93.75%,  total acc: 79.50%   [EVAL] batch:  132 | acc: 100.00%,  total acc: 79.65%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 79.71%   [EVAL] batch:  134 | acc: 87.50%,  total acc: 79.77%   [EVAL] batch:  135 | acc: 93.75%,  total acc: 79.87%   [EVAL] batch:  136 | acc: 81.25%,  total acc: 79.88%   [EVAL] batch:  137 | acc: 75.00%,  total acc: 79.85%   [EVAL] batch:  138 | acc: 18.75%,  total acc: 79.41%   [EVAL] batch:  139 | acc: 31.25%,  total acc: 79.06%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 78.68%   [EVAL] batch:  141 | acc: 43.75%,  total acc: 78.43%   [EVAL] batch:  142 | acc: 43.75%,  total acc: 78.19%   [EVAL] batch:  143 | acc: 31.25%,  total acc: 77.86%   [EVAL] batch:  144 | acc: 100.00%,  total acc: 78.02%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 78.17%   [EVAL] batch:  146 | acc: 93.75%,  total acc: 78.27%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 78.42%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 78.57%   [EVAL] batch:  149 | acc: 100.00%,  total acc: 78.71%   [EVAL] batch:  150 | acc: 25.00%,  total acc: 78.35%   [EVAL] batch:  151 | acc: 6.25%,  total acc: 77.88%   [EVAL] batch:  152 | acc: 12.50%,  total acc: 77.45%   [EVAL] batch:  153 | acc: 12.50%,  total acc: 77.03%   [EVAL] batch:  154 | acc: 0.00%,  total acc: 76.53%   [EVAL] batch:  155 | acc: 18.75%,  total acc: 76.16%   [EVAL] batch:  156 | acc: 75.00%,  total acc: 76.15%   [EVAL] batch:  157 | acc: 93.75%,  total acc: 76.27%   [EVAL] batch:  158 | acc: 100.00%,  total acc: 76.42%   [EVAL] batch:  159 | acc: 93.75%,  total acc: 76.52%   [EVAL] batch:  160 | acc: 100.00%,  total acc: 76.67%   [EVAL] batch:  161 | acc: 93.75%,  total acc: 76.77%   [EVAL] batch:  162 | acc: 75.00%,  total acc: 76.76%   [EVAL] batch:  163 | acc: 62.50%,  total acc: 76.68%   [EVAL] batch:  164 | acc: 68.75%,  total acc: 76.63%   [EVAL] batch:  165 | acc: 50.00%,  total acc: 76.47%   [EVAL] batch:  166 | acc: 56.25%,  total acc: 76.35%   [EVAL] batch:  167 | acc: 68.75%,  total acc: 76.30%   [EVAL] batch:  168 | acc: 75.00%,  total acc: 76.29%   [EVAL] batch:  169 | acc: 87.50%,  total acc: 76.36%   [EVAL] batch:  170 | acc: 87.50%,  total acc: 76.43%   [EVAL] batch:  171 | acc: 87.50%,  total acc: 76.49%   [EVAL] batch:  172 | acc: 81.25%,  total acc: 76.52%   [EVAL] batch:  173 | acc: 100.00%,  total acc: 76.65%   [EVAL] batch:  174 | acc: 93.75%,  total acc: 76.75%   [EVAL] batch:  175 | acc: 68.75%,  total acc: 76.70%   [EVAL] batch:  176 | acc: 81.25%,  total acc: 76.73%   [EVAL] batch:  177 | acc: 62.50%,  total acc: 76.65%   [EVAL] batch:  178 | acc: 93.75%,  total acc: 76.75%   [EVAL] batch:  179 | acc: 87.50%,  total acc: 76.81%   [EVAL] batch:  180 | acc: 75.00%,  total acc: 76.80%   [EVAL] batch:  181 | acc: 62.50%,  total acc: 76.72%   [EVAL] batch:  182 | acc: 87.50%,  total acc: 76.78%   [EVAL] batch:  183 | acc: 93.75%,  total acc: 76.87%   [EVAL] batch:  184 | acc: 81.25%,  total acc: 76.89%   [EVAL] batch:  185 | acc: 93.75%,  total acc: 76.98%   [EVAL] batch:  186 | acc: 81.25%,  total acc: 77.01%   [EVAL] batch:  187 | acc: 75.00%,  total acc: 76.99%   [EVAL] batch:  188 | acc: 87.50%,  total acc: 77.05%   [EVAL] batch:  189 | acc: 87.50%,  total acc: 77.11%   [EVAL] batch:  190 | acc: 100.00%,  total acc: 77.23%   [EVAL] batch:  191 | acc: 81.25%,  total acc: 77.25%   [EVAL] batch:  192 | acc: 100.00%,  total acc: 77.36%   [EVAL] batch:  193 | acc: 93.75%,  total acc: 77.45%   [EVAL] batch:  194 | acc: 62.50%,  total acc: 77.37%   [EVAL] batch:  195 | acc: 100.00%,  total acc: 77.49%   [EVAL] batch:  196 | acc: 87.50%,  total acc: 77.54%   [EVAL] batch:  197 | acc: 100.00%,  total acc: 77.65%   [EVAL] batch:  198 | acc: 62.50%,  total acc: 77.58%   [EVAL] batch:  199 | acc: 75.00%,  total acc: 77.56%   [EVAL] batch:  200 | acc: 68.75%,  total acc: 77.52%   [EVAL] batch:  201 | acc: 87.50%,  total acc: 77.57%   [EVAL] batch:  202 | acc: 75.00%,  total acc: 77.56%   [EVAL] batch:  203 | acc: 50.00%,  total acc: 77.42%   [EVAL] batch:  204 | acc: 56.25%,  total acc: 77.32%   [EVAL] batch:  205 | acc: 68.75%,  total acc: 77.28%   [EVAL] batch:  206 | acc: 50.00%,  total acc: 77.14%   [EVAL] batch:  207 | acc: 31.25%,  total acc: 76.92%   [EVAL] batch:  208 | acc: 37.50%,  total acc: 76.73%   [EVAL] batch:  209 | acc: 43.75%,  total acc: 76.58%   [EVAL] batch:  210 | acc: 43.75%,  total acc: 76.42%   [EVAL] batch:  211 | acc: 18.75%,  total acc: 76.15%   [EVAL] batch:  212 | acc: 68.75%,  total acc: 76.12%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 76.23%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 76.34%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 76.45%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 76.56%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 76.66%   [EVAL] batch:  218 | acc: 100.00%,  total acc: 76.77%   [EVAL] batch:  219 | acc: 68.75%,  total acc: 76.73%   [EVAL] batch:  220 | acc: 93.75%,  total acc: 76.81%   [EVAL] batch:  221 | acc: 87.50%,  total acc: 76.86%   [EVAL] batch:  222 | acc: 68.75%,  total acc: 76.82%   [EVAL] batch:  223 | acc: 87.50%,  total acc: 76.87%   [EVAL] batch:  224 | acc: 62.50%,  total acc: 76.81%   [EVAL] batch:  225 | acc: 100.00%,  total acc: 76.91%   [EVAL] batch:  226 | acc: 100.00%,  total acc: 77.01%   [EVAL] batch:  227 | acc: 100.00%,  total acc: 77.11%   [EVAL] batch:  228 | acc: 100.00%,  total acc: 77.21%   [EVAL] batch:  229 | acc: 100.00%,  total acc: 77.31%   [EVAL] batch:  230 | acc: 93.75%,  total acc: 77.38%   [EVAL] batch:  231 | acc: 100.00%,  total acc: 77.48%   [EVAL] batch:  232 | acc: 100.00%,  total acc: 77.58%   [EVAL] batch:  233 | acc: 100.00%,  total acc: 77.67%   [EVAL] batch:  234 | acc: 100.00%,  total acc: 77.77%   [EVAL] batch:  235 | acc: 100.00%,  total acc: 77.86%   [EVAL] batch:  236 | acc: 100.00%,  total acc: 77.95%   [EVAL] batch:  237 | acc: 100.00%,  total acc: 78.05%   [EVAL] batch:  238 | acc: 100.00%,  total acc: 78.14%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 78.20%   [EVAL] batch:  240 | acc: 100.00%,  total acc: 78.29%   [EVAL] batch:  241 | acc: 100.00%,  total acc: 78.38%   [EVAL] batch:  242 | acc: 100.00%,  total acc: 78.47%   [EVAL] batch:  243 | acc: 93.75%,  total acc: 78.53%   [EVAL] batch:  244 | acc: 100.00%,  total acc: 78.62%   [EVAL] batch:  245 | acc: 87.50%,  total acc: 78.66%   [EVAL] batch:  246 | acc: 93.75%,  total acc: 78.72%   [EVAL] batch:  247 | acc: 100.00%,  total acc: 78.81%   [EVAL] batch:  248 | acc: 100.00%,  total acc: 78.89%   [EVAL] batch:  249 | acc: 93.75%,  total acc: 78.95%   
cur_acc:  ['0.9464', '0.7262', '0.7609', '0.8423']
his_acc:  ['0.9464', '0.8255', '0.7912', '0.7895']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.061871528625488 1.2375669479370117
CurrentTrain: epoch  0, batch     0 | loss: 8.2994385Losses:  9.80894660949707 1.1037096977233887
CurrentTrain: epoch  0, batch     1 | loss: 10.9126568Losses:  9.511316299438477 1.2951089143753052
CurrentTrain: epoch  0, batch     2 | loss: 10.8064251Losses:  9.174581527709961 1.4234156608581543
CurrentTrain: epoch  0, batch     3 | loss: 10.5979977Losses:  9.388328552246094 1.3942928314208984
CurrentTrain: epoch  0, batch     4 | loss: 10.7826214Losses:  8.95000171661377 0.9408979415893555
CurrentTrain: epoch  0, batch     5 | loss: 9.8908997Losses:  2.9065840244293213 1.4418094158172607
CurrentTrain: epoch  1, batch     0 | loss: 4.3483934Losses:  1.854865550994873 1.291235089302063
CurrentTrain: epoch  1, batch     1 | loss: 3.1461005Losses:  2.3534061908721924 1.330688714981079
CurrentTrain: epoch  1, batch     2 | loss: 3.6840949Losses:  3.553344249725342 1.0976954698562622
CurrentTrain: epoch  1, batch     3 | loss: 4.6510396Losses:  2.0087761878967285 1.0172829627990723
CurrentTrain: epoch  1, batch     4 | loss: 3.0260592Losses:  3.8915200233459473 0.9850028157234192
CurrentTrain: epoch  1, batch     5 | loss: 4.8765230Losses:  1.916534423828125 0.9230260252952576
CurrentTrain: epoch  2, batch     0 | loss: 2.8395605Losses:  2.4786200523376465 1.1809277534484863
CurrentTrain: epoch  2, batch     1 | loss: 3.6595478Losses:  2.7088065147399902 1.1967514753341675
CurrentTrain: epoch  2, batch     2 | loss: 3.9055581Losses:  2.913423538208008 1.011634349822998
CurrentTrain: epoch  2, batch     3 | loss: 3.9250579Losses:  2.2478318214416504 1.1199431419372559
CurrentTrain: epoch  2, batch     4 | loss: 3.3677750Losses:  2.2292544841766357 0.852161705493927
CurrentTrain: epoch  2, batch     5 | loss: 3.0814161Losses:  2.190781593322754 1.1174331903457642
CurrentTrain: epoch  3, batch     0 | loss: 3.3082147Losses:  3.057203531265259 0.9033575057983398
CurrentTrain: epoch  3, batch     1 | loss: 3.9605610Losses:  1.7011514902114868 1.006648302078247
CurrentTrain: epoch  3, batch     2 | loss: 2.7077999Losses:  2.106046199798584 0.9743126630783081
CurrentTrain: epoch  3, batch     3 | loss: 3.0803590Losses:  2.2299275398254395 1.1435143947601318
CurrentTrain: epoch  3, batch     4 | loss: 3.3734419Losses:  1.9825111627578735 0.8693825006484985
CurrentTrain: epoch  3, batch     5 | loss: 2.8518937Losses:  2.212428092956543 0.9610652327537537
CurrentTrain: epoch  4, batch     0 | loss: 3.1734934Losses:  2.222764492034912 1.0281181335449219
CurrentTrain: epoch  4, batch     1 | loss: 3.2508826Losses:  1.722747802734375 0.847472608089447
CurrentTrain: epoch  4, batch     2 | loss: 2.5702205Losses:  2.222882032394409 0.853065013885498
CurrentTrain: epoch  4, batch     3 | loss: 3.0759470Losses:  2.253298282623291 0.8728998899459839
CurrentTrain: epoch  4, batch     4 | loss: 3.1261983Losses:  1.3132716417312622 0.5172929763793945
CurrentTrain: epoch  4, batch     5 | loss: 1.8305646Losses:  2.324166774749756 0.9192854762077332
CurrentTrain: epoch  5, batch     0 | loss: 3.2434523Losses:  1.725250244140625 0.9666615724563599
CurrentTrain: epoch  5, batch     1 | loss: 2.6919117Losses:  1.4673553705215454 0.751537024974823
CurrentTrain: epoch  5, batch     2 | loss: 2.2188923Losses:  1.4910876750946045 0.8675762414932251
CurrentTrain: epoch  5, batch     3 | loss: 2.3586640Losses:  2.490828275680542 0.6957281827926636
CurrentTrain: epoch  5, batch     4 | loss: 3.1865563Losses:  2.131777286529541 0.5516058802604675
CurrentTrain: epoch  5, batch     5 | loss: 2.6833832Losses:  1.6035710573196411 0.880630373954773
CurrentTrain: epoch  6, batch     0 | loss: 2.4842014Losses:  1.8667573928833008 0.8327139616012573
CurrentTrain: epoch  6, batch     1 | loss: 2.6994715Losses:  1.947561264038086 0.9913550615310669
CurrentTrain: epoch  6, batch     2 | loss: 2.9389162Losses:  2.091374397277832 0.6855819225311279
CurrentTrain: epoch  6, batch     3 | loss: 2.7769563Losses:  1.9826717376708984 0.9907091856002808
CurrentTrain: epoch  6, batch     4 | loss: 2.9733810Losses:  1.3240669965744019 0.4276197850704193
CurrentTrain: epoch  6, batch     5 | loss: 1.7516868Losses:  1.5633289813995361 0.8018178343772888
CurrentTrain: epoch  7, batch     0 | loss: 2.3651469Losses:  1.3837543725967407 0.9672939777374268
CurrentTrain: epoch  7, batch     1 | loss: 2.3510485Losses:  1.6029016971588135 0.89603590965271
CurrentTrain: epoch  7, batch     2 | loss: 2.4989376Losses:  1.9849605560302734 0.7391901016235352
CurrentTrain: epoch  7, batch     3 | loss: 2.7241507Losses:  2.0018765926361084 0.764577329158783
CurrentTrain: epoch  7, batch     4 | loss: 2.7664540Losses:  1.8935359716415405 0.4894053637981415
CurrentTrain: epoch  7, batch     5 | loss: 2.3829412Losses:  1.554652214050293 0.5661064982414246
CurrentTrain: epoch  8, batch     0 | loss: 2.1207588Losses:  1.5297757387161255 0.8059942722320557
CurrentTrain: epoch  8, batch     1 | loss: 2.3357701Losses:  1.996390461921692 0.736924409866333
CurrentTrain: epoch  8, batch     2 | loss: 2.7333150Losses:  1.456634521484375 0.7313523292541504
CurrentTrain: epoch  8, batch     3 | loss: 2.1879869Losses:  1.7203342914581299 0.7638141512870789
CurrentTrain: epoch  8, batch     4 | loss: 2.4841485Losses:  1.5696783065795898 0.5350307822227478
CurrentTrain: epoch  8, batch     5 | loss: 2.1047091Losses:  1.5228837728500366 0.784738302230835
CurrentTrain: epoch  9, batch     0 | loss: 2.3076220Losses:  1.6223881244659424 0.5091209411621094
CurrentTrain: epoch  9, batch     1 | loss: 2.1315091Losses:  1.3037166595458984 0.8206911087036133
CurrentTrain: epoch  9, batch     2 | loss: 2.1244078Losses:  1.8170950412750244 0.5920619964599609
CurrentTrain: epoch  9, batch     3 | loss: 2.4091570Losses:  1.3744933605194092 0.7136931419372559
CurrentTrain: epoch  9, batch     4 | loss: 2.0881865Losses:  1.7574135065078735 0.5877171158790588
CurrentTrain: epoch  9, batch     5 | loss: 2.3451307
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 88.39%   [EVAL] batch:    7 | acc: 75.00%,  total acc: 86.72%   [EVAL] batch:    8 | acc: 68.75%,  total acc: 84.72%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 83.12%   [EVAL] batch:   10 | acc: 43.75%,  total acc: 79.55%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 78.65%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 79.81%   [EVAL] batch:   13 | acc: 87.50%,  total acc: 80.36%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 80.00%   [EVAL] batch:   15 | acc: 75.00%,  total acc: 79.69%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 79.78%   [EVAL] batch:   17 | acc: 100.00%,  total acc: 80.90%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 81.91%   [EVAL] batch:   19 | acc: 93.75%,  total acc: 82.50%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 83.33%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 83.81%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 84.51%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 84.90%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 85.25%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 84.86%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 83.56%   [EVAL] batch:   27 | acc: 68.75%,  total acc: 83.04%   [EVAL] batch:   28 | acc: 75.00%,  total acc: 82.76%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 82.08%   [EVAL] batch:   30 | acc: 62.50%,  total acc: 81.45%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 81.25%   [EVAL] batch:   32 | acc: 75.00%,  total acc: 81.06%   [EVAL] batch:   33 | acc: 37.50%,  total acc: 79.78%   [EVAL] batch:   34 | acc: 62.50%,  total acc: 79.29%   [EVAL] batch:   35 | acc: 37.50%,  total acc: 78.12%   [EVAL] batch:   36 | acc: 56.25%,  total acc: 77.53%   [EVAL] batch:   37 | acc: 75.00%,  total acc: 77.47%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 77.40%   [EVAL] batch:   39 | acc: 87.50%,  total acc: 77.66%   [EVAL] batch:   40 | acc: 87.50%,  total acc: 77.90%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 78.12%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 78.34%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 78.55%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 78.89%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 79.08%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 79.39%   [EVAL] batch:   47 | acc: 75.00%,  total acc: 79.30%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 79.46%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 79.62%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 80.02%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 80.41%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 80.78%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 81.13%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 81.48%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 81.81%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 82.13%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 82.44%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 82.73%   [EVAL] batch:   59 | acc: 100.00%,  total acc: 83.02%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 83.30%   [EVAL] batch:   61 | acc: 100.00%,  total acc: 83.57%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 83.04%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:    4 | acc: 68.75%,  total acc: 86.25%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 86.46%   [EVAL] batch:    6 | acc: 50.00%,  total acc: 81.25%   [EVAL] batch:    7 | acc: 43.75%,  total acc: 76.56%   [EVAL] batch:    8 | acc: 37.50%,  total acc: 72.22%   [EVAL] batch:    9 | acc: 43.75%,  total acc: 69.38%   [EVAL] batch:   10 | acc: 43.75%,  total acc: 67.05%   [EVAL] batch:   11 | acc: 31.25%,  total acc: 64.06%   [EVAL] batch:   12 | acc: 62.50%,  total acc: 63.94%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 67.92%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 69.92%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 71.69%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 74.34%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 75.00%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 76.19%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 76.42%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 76.90%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 77.34%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 77.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 78.61%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 79.40%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 80.13%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 80.60%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 81.85%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 82.42%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 82.95%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 83.09%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 83.04%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 83.33%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 83.78%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 84.21%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 84.62%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 85.00%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 85.37%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 85.61%   [EVAL] batch:   43 | acc: 93.75%,  total acc: 85.80%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 85.97%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 85.87%   [EVAL] batch:   46 | acc: 75.00%,  total acc: 85.64%   [EVAL] batch:   47 | acc: 75.00%,  total acc: 85.42%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 85.59%   [EVAL] batch:   49 | acc: 81.25%,  total acc: 85.50%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 85.54%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 85.70%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 85.85%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 85.88%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 85.80%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 85.83%   [EVAL] batch:   56 | acc: 68.75%,  total acc: 85.53%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 85.13%   [EVAL] batch:   58 | acc: 75.00%,  total acc: 84.96%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 84.79%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 84.63%   [EVAL] batch:   61 | acc: 75.00%,  total acc: 84.48%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 84.62%   [EVAL] batch:   63 | acc: 81.25%,  total acc: 84.57%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 84.81%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 84.85%   [EVAL] batch:   66 | acc: 93.75%,  total acc: 84.98%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 85.20%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 85.42%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 85.62%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 85.83%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 85.59%   [EVAL] batch:   72 | acc: 93.75%,  total acc: 85.70%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 85.64%   [EVAL] batch:   74 | acc: 93.75%,  total acc: 85.75%   [EVAL] batch:   75 | acc: 68.75%,  total acc: 85.53%   [EVAL] batch:   76 | acc: 56.25%,  total acc: 85.15%   [EVAL] batch:   77 | acc: 62.50%,  total acc: 84.86%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 84.73%   [EVAL] batch:   79 | acc: 81.25%,  total acc: 84.69%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 84.57%   [EVAL] batch:   81 | acc: 56.25%,  total acc: 84.22%   [EVAL] batch:   82 | acc: 37.50%,  total acc: 83.66%   [EVAL] batch:   83 | acc: 56.25%,  total acc: 83.33%   [EVAL] batch:   84 | acc: 43.75%,  total acc: 82.87%   [EVAL] batch:   85 | acc: 50.00%,  total acc: 82.49%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 81.90%   [EVAL] batch:   87 | acc: 75.00%,  total acc: 81.82%   [EVAL] batch:   88 | acc: 68.75%,  total acc: 81.67%   [EVAL] batch:   89 | acc: 75.00%,  total acc: 81.60%   [EVAL] batch:   90 | acc: 87.50%,  total acc: 81.66%   [EVAL] batch:   91 | acc: 81.25%,  total acc: 81.66%   [EVAL] batch:   92 | acc: 62.50%,  total acc: 81.45%   [EVAL] batch:   93 | acc: 62.50%,  total acc: 81.25%   [EVAL] batch:   94 | acc: 37.50%,  total acc: 80.79%   [EVAL] batch:   95 | acc: 31.25%,  total acc: 80.27%   [EVAL] batch:   96 | acc: 56.25%,  total acc: 80.03%   [EVAL] batch:   97 | acc: 37.50%,  total acc: 79.59%   [EVAL] batch:   98 | acc: 68.75%,  total acc: 79.48%   [EVAL] batch:   99 | acc: 43.75%,  total acc: 79.12%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 78.90%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 78.74%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 78.52%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 78.37%   [EVAL] batch:  104 | acc: 75.00%,  total acc: 78.33%   [EVAL] batch:  105 | acc: 68.75%,  total acc: 78.24%   [EVAL] batch:  106 | acc: 43.75%,  total acc: 77.92%   [EVAL] batch:  107 | acc: 12.50%,  total acc: 77.31%   [EVAL] batch:  108 | acc: 18.75%,  total acc: 76.78%   [EVAL] batch:  109 | acc: 12.50%,  total acc: 76.19%   [EVAL] batch:  110 | acc: 18.75%,  total acc: 75.68%   [EVAL] batch:  111 | acc: 31.25%,  total acc: 75.28%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 75.11%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 75.33%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 75.54%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 75.75%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 75.96%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 76.17%   [EVAL] batch:  118 | acc: 93.75%,  total acc: 76.31%   [EVAL] batch:  119 | acc: 81.25%,  total acc: 76.35%   [EVAL] batch:  120 | acc: 87.50%,  total acc: 76.45%   [EVAL] batch:  121 | acc: 93.75%,  total acc: 76.59%   [EVAL] batch:  122 | acc: 100.00%,  total acc: 76.78%   [EVAL] batch:  123 | acc: 81.25%,  total acc: 76.81%   [EVAL] batch:  124 | acc: 100.00%,  total acc: 77.00%   [EVAL] batch:  125 | acc: 75.00%,  total acc: 76.98%   [EVAL] batch:  126 | acc: 56.25%,  total acc: 76.82%   [EVAL] batch:  127 | acc: 75.00%,  total acc: 76.81%   [EVAL] batch:  128 | acc: 75.00%,  total acc: 76.79%   [EVAL] batch:  129 | acc: 68.75%,  total acc: 76.73%   [EVAL] batch:  130 | acc: 68.75%,  total acc: 76.67%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 76.70%   [EVAL] batch:  132 | acc: 87.50%,  total acc: 76.79%   [EVAL] batch:  133 | acc: 56.25%,  total acc: 76.63%   [EVAL] batch:  134 | acc: 68.75%,  total acc: 76.57%   [EVAL] batch:  135 | acc: 75.00%,  total acc: 76.56%   [EVAL] batch:  136 | acc: 68.75%,  total acc: 76.51%   [EVAL] batch:  137 | acc: 50.00%,  total acc: 76.31%   [EVAL] batch:  138 | acc: 18.75%,  total acc: 75.90%   [EVAL] batch:  139 | acc: 31.25%,  total acc: 75.58%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 75.22%   [EVAL] batch:  141 | acc: 43.75%,  total acc: 75.00%   [EVAL] batch:  142 | acc: 43.75%,  total acc: 74.78%   [EVAL] batch:  143 | acc: 37.50%,  total acc: 74.52%   [EVAL] batch:  144 | acc: 93.75%,  total acc: 74.66%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 74.83%   [EVAL] batch:  146 | acc: 100.00%,  total acc: 75.00%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 75.17%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 75.34%   [EVAL] batch:  149 | acc: 93.75%,  total acc: 75.46%   [EVAL] batch:  150 | acc: 25.00%,  total acc: 75.12%   [EVAL] batch:  151 | acc: 0.00%,  total acc: 74.63%   [EVAL] batch:  152 | acc: 6.25%,  total acc: 74.18%   [EVAL] batch:  153 | acc: 6.25%,  total acc: 73.74%   [EVAL] batch:  154 | acc: 0.00%,  total acc: 73.27%   [EVAL] batch:  155 | acc: 12.50%,  total acc: 72.88%   [EVAL] batch:  156 | acc: 75.00%,  total acc: 72.89%   [EVAL] batch:  157 | acc: 93.75%,  total acc: 73.02%   [EVAL] batch:  158 | acc: 93.75%,  total acc: 73.15%   [EVAL] batch:  159 | acc: 93.75%,  total acc: 73.28%   [EVAL] batch:  160 | acc: 100.00%,  total acc: 73.45%   [EVAL] batch:  161 | acc: 93.75%,  total acc: 73.57%   [EVAL] batch:  162 | acc: 75.00%,  total acc: 73.58%   [EVAL] batch:  163 | acc: 62.50%,  total acc: 73.51%   [EVAL] batch:  164 | acc: 68.75%,  total acc: 73.48%   [EVAL] batch:  165 | acc: 50.00%,  total acc: 73.34%   [EVAL] batch:  166 | acc: 62.50%,  total acc: 73.28%   [EVAL] batch:  167 | acc: 75.00%,  total acc: 73.29%   [EVAL] batch:  168 | acc: 81.25%,  total acc: 73.34%   [EVAL] batch:  169 | acc: 87.50%,  total acc: 73.42%   [EVAL] batch:  170 | acc: 100.00%,  total acc: 73.57%   [EVAL] batch:  171 | acc: 87.50%,  total acc: 73.66%   [EVAL] batch:  172 | acc: 81.25%,  total acc: 73.70%   [EVAL] batch:  173 | acc: 100.00%,  total acc: 73.85%   [EVAL] batch:  174 | acc: 93.75%,  total acc: 73.96%   [EVAL] batch:  175 | acc: 68.75%,  total acc: 73.93%   [EVAL] batch:  176 | acc: 75.00%,  total acc: 73.94%   [EVAL] batch:  177 | acc: 62.50%,  total acc: 73.88%   [EVAL] batch:  178 | acc: 87.50%,  total acc: 73.95%   [EVAL] batch:  179 | acc: 87.50%,  total acc: 74.03%   [EVAL] batch:  180 | acc: 75.00%,  total acc: 74.03%   [EVAL] batch:  181 | acc: 62.50%,  total acc: 73.97%   [EVAL] batch:  182 | acc: 81.25%,  total acc: 74.01%   [EVAL] batch:  183 | acc: 93.75%,  total acc: 74.12%   [EVAL] batch:  184 | acc: 81.25%,  total acc: 74.16%   [EVAL] batch:  185 | acc: 93.75%,  total acc: 74.26%   [EVAL] batch:  186 | acc: 75.00%,  total acc: 74.26%   [EVAL] batch:  187 | acc: 87.50%,  total acc: 74.34%   [EVAL] batch:  188 | acc: 93.75%,  total acc: 74.44%   [EVAL] batch:  189 | acc: 81.25%,  total acc: 74.47%   [EVAL] batch:  190 | acc: 87.50%,  total acc: 74.54%   [EVAL] batch:  191 | acc: 81.25%,  total acc: 74.58%   [EVAL] batch:  192 | acc: 100.00%,  total acc: 74.71%   [EVAL] batch:  193 | acc: 93.75%,  total acc: 74.81%   [EVAL] batch:  194 | acc: 75.00%,  total acc: 74.81%   [EVAL] batch:  195 | acc: 93.75%,  total acc: 74.90%   [EVAL] batch:  196 | acc: 87.50%,  total acc: 74.97%   [EVAL] batch:  197 | acc: 93.75%,  total acc: 75.06%   [EVAL] batch:  198 | acc: 62.50%,  total acc: 75.00%   [EVAL] batch:  199 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:  200 | acc: 68.75%,  total acc: 74.97%   [EVAL] batch:  201 | acc: 87.50%,  total acc: 75.03%   [EVAL] batch:  202 | acc: 81.25%,  total acc: 75.06%   [EVAL] batch:  203 | acc: 62.50%,  total acc: 75.00%   [EVAL] batch:  204 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:  205 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:  206 | acc: 50.00%,  total acc: 74.88%   [EVAL] batch:  207 | acc: 25.00%,  total acc: 74.64%   [EVAL] batch:  208 | acc: 25.00%,  total acc: 74.40%   [EVAL] batch:  209 | acc: 31.25%,  total acc: 74.20%   [EVAL] batch:  210 | acc: 43.75%,  total acc: 74.05%   [EVAL] batch:  211 | acc: 12.50%,  total acc: 73.76%   [EVAL] batch:  212 | acc: 68.75%,  total acc: 73.74%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 73.86%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 73.98%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 74.10%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 74.22%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 74.34%   [EVAL] batch:  218 | acc: 93.75%,  total acc: 74.43%   [EVAL] batch:  219 | acc: 62.50%,  total acc: 74.38%   [EVAL] batch:  220 | acc: 75.00%,  total acc: 74.38%   [EVAL] batch:  221 | acc: 68.75%,  total acc: 74.35%   [EVAL] batch:  222 | acc: 68.75%,  total acc: 74.33%   [EVAL] batch:  223 | acc: 81.25%,  total acc: 74.36%   [EVAL] batch:  224 | acc: 43.75%,  total acc: 74.22%   [EVAL] batch:  225 | acc: 100.00%,  total acc: 74.34%   [EVAL] batch:  226 | acc: 100.00%,  total acc: 74.45%   [EVAL] batch:  227 | acc: 100.00%,  total acc: 74.56%   [EVAL] batch:  228 | acc: 100.00%,  total acc: 74.67%   [EVAL] batch:  229 | acc: 100.00%,  total acc: 74.78%   [EVAL] batch:  230 | acc: 93.75%,  total acc: 74.86%   [EVAL] batch:  231 | acc: 100.00%,  total acc: 74.97%   [EVAL] batch:  232 | acc: 100.00%,  total acc: 75.08%   [EVAL] batch:  233 | acc: 100.00%,  total acc: 75.19%   [EVAL] batch:  234 | acc: 100.00%,  total acc: 75.29%   [EVAL] batch:  235 | acc: 100.00%,  total acc: 75.40%   [EVAL] batch:  236 | acc: 100.00%,  total acc: 75.50%   [EVAL] batch:  237 | acc: 100.00%,  total acc: 75.60%   [EVAL] batch:  238 | acc: 100.00%,  total acc: 75.71%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 75.78%   [EVAL] batch:  240 | acc: 100.00%,  total acc: 75.88%   [EVAL] batch:  241 | acc: 100.00%,  total acc: 75.98%   [EVAL] batch:  242 | acc: 100.00%,  total acc: 76.08%   [EVAL] batch:  243 | acc: 93.75%,  total acc: 76.15%   [EVAL] batch:  244 | acc: 100.00%,  total acc: 76.25%   [EVAL] batch:  245 | acc: 87.50%,  total acc: 76.30%   [EVAL] batch:  246 | acc: 100.00%,  total acc: 76.39%   [EVAL] batch:  247 | acc: 100.00%,  total acc: 76.49%   [EVAL] batch:  248 | acc: 100.00%,  total acc: 76.58%   [EVAL] batch:  249 | acc: 93.75%,  total acc: 76.65%   [EVAL] batch:  250 | acc: 75.00%,  total acc: 76.64%   [EVAL] batch:  251 | acc: 87.50%,  total acc: 76.69%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 76.75%   [EVAL] batch:  253 | acc: 100.00%,  total acc: 76.85%   [EVAL] batch:  254 | acc: 93.75%,  total acc: 76.91%   [EVAL] batch:  255 | acc: 100.00%,  total acc: 77.00%   [EVAL] batch:  256 | acc: 68.75%,  total acc: 76.97%   [EVAL] batch:  257 | acc: 75.00%,  total acc: 76.96%   [EVAL] batch:  258 | acc: 68.75%,  total acc: 76.93%   [EVAL] batch:  259 | acc: 68.75%,  total acc: 76.90%   [EVAL] batch:  260 | acc: 43.75%,  total acc: 76.77%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 76.74%   [EVAL] batch:  262 | acc: 93.75%,  total acc: 76.81%   [EVAL] batch:  263 | acc: 87.50%,  total acc: 76.85%   [EVAL] batch:  264 | acc: 75.00%,  total acc: 76.84%   [EVAL] batch:  265 | acc: 75.00%,  total acc: 76.83%   [EVAL] batch:  266 | acc: 81.25%,  total acc: 76.85%   [EVAL] batch:  267 | acc: 100.00%,  total acc: 76.94%   [EVAL] batch:  268 | acc: 100.00%,  total acc: 77.02%   [EVAL] batch:  269 | acc: 93.75%,  total acc: 77.08%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 77.17%   [EVAL] batch:  271 | acc: 93.75%,  total acc: 77.23%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 77.31%   [EVAL] batch:  273 | acc: 93.75%,  total acc: 77.37%   [EVAL] batch:  274 | acc: 93.75%,  total acc: 77.43%   [EVAL] batch:  275 | acc: 75.00%,  total acc: 77.42%   [EVAL] batch:  276 | acc: 50.00%,  total acc: 77.32%   [EVAL] batch:  277 | acc: 68.75%,  total acc: 77.29%   [EVAL] batch:  278 | acc: 75.00%,  total acc: 77.28%   [EVAL] batch:  279 | acc: 62.50%,  total acc: 77.23%   [EVAL] batch:  280 | acc: 62.50%,  total acc: 77.18%   [EVAL] batch:  281 | acc: 75.00%,  total acc: 77.17%   [EVAL] batch:  282 | acc: 75.00%,  total acc: 77.16%   [EVAL] batch:  283 | acc: 37.50%,  total acc: 77.02%   [EVAL] batch:  284 | acc: 62.50%,  total acc: 76.97%   [EVAL] batch:  285 | acc: 37.50%,  total acc: 76.84%   [EVAL] batch:  286 | acc: 56.25%,  total acc: 76.76%   [EVAL] batch:  287 | acc: 75.00%,  total acc: 76.76%   [EVAL] batch:  288 | acc: 75.00%,  total acc: 76.75%   [EVAL] batch:  289 | acc: 87.50%,  total acc: 76.79%   [EVAL] batch:  290 | acc: 87.50%,  total acc: 76.83%   [EVAL] batch:  291 | acc: 87.50%,  total acc: 76.86%   [EVAL] batch:  292 | acc: 87.50%,  total acc: 76.90%   [EVAL] batch:  293 | acc: 87.50%,  total acc: 76.93%   [EVAL] batch:  294 | acc: 93.75%,  total acc: 76.99%   [EVAL] batch:  295 | acc: 87.50%,  total acc: 77.03%   [EVAL] batch:  296 | acc: 93.75%,  total acc: 77.08%   [EVAL] batch:  297 | acc: 75.00%,  total acc: 77.08%   [EVAL] batch:  298 | acc: 87.50%,  total acc: 77.11%   [EVAL] batch:  299 | acc: 87.50%,  total acc: 77.15%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 77.22%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 77.30%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 77.37%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 77.45%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 77.52%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 77.59%   [EVAL] batch:  306 | acc: 100.00%,  total acc: 77.67%   [EVAL] batch:  307 | acc: 100.00%,  total acc: 77.74%   [EVAL] batch:  308 | acc: 100.00%,  total acc: 77.81%   [EVAL] batch:  309 | acc: 100.00%,  total acc: 77.88%   [EVAL] batch:  310 | acc: 100.00%,  total acc: 77.95%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 78.02%   [EVAL] batch:  312 | acc: 50.00%,  total acc: 77.94%   
cur_acc:  ['0.9464', '0.7262', '0.7609', '0.8423', '0.8304']
his_acc:  ['0.9464', '0.8255', '0.7912', '0.7895', '0.7794']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.4543352127075195 1.3616803884506226
CurrentTrain: epoch  0, batch     0 | loss: 8.8160152Losses:  9.127432823181152 1.220961332321167
CurrentTrain: epoch  0, batch     1 | loss: 10.3483944Losses:  10.732841491699219 1.1300909519195557
CurrentTrain: epoch  0, batch     2 | loss: 11.8629322Losses:  10.239994049072266 1.0379993915557861
CurrentTrain: epoch  0, batch     3 | loss: 11.2779932Losses:  9.94544792175293 0.8991409540176392
CurrentTrain: epoch  0, batch     4 | loss: 10.8445892Losses:  8.98853874206543 1.4099384546279907
CurrentTrain: epoch  0, batch     5 | loss: 10.3984776Losses:  7.050114631652832 0.5514840483665466
CurrentTrain: epoch  0, batch     6 | loss: 7.6015987Losses:  2.9638376235961914 1.0084894895553589
CurrentTrain: epoch  1, batch     0 | loss: 3.9723272Losses:  3.1037731170654297 1.26654052734375
CurrentTrain: epoch  1, batch     1 | loss: 4.3703136Losses:  3.0665650367736816 0.808255672454834
CurrentTrain: epoch  1, batch     2 | loss: 3.8748207Losses:  2.880680561065674 1.3145091533660889
CurrentTrain: epoch  1, batch     3 | loss: 4.1951895Losses:  3.370882034301758 1.1708158254623413
CurrentTrain: epoch  1, batch     4 | loss: 4.5416980Losses:  2.4096338748931885 1.0665669441223145
CurrentTrain: epoch  1, batch     5 | loss: 3.4762008Losses:  1.3591289520263672 0.2519075572490692
CurrentTrain: epoch  1, batch     6 | loss: 1.6110365Losses:  2.8582043647766113 1.115955114364624
CurrentTrain: epoch  2, batch     0 | loss: 3.9741595Losses:  2.2695536613464355 1.2109904289245605
CurrentTrain: epoch  2, batch     1 | loss: 3.4805441Losses:  2.9832828044891357 0.754579484462738
CurrentTrain: epoch  2, batch     2 | loss: 3.7378623Losses:  1.849694013595581 1.2184394598007202
CurrentTrain: epoch  2, batch     3 | loss: 3.0681334Losses:  3.4784460067749023 0.9584795236587524
CurrentTrain: epoch  2, batch     4 | loss: 4.4369254Losses:  2.217236042022705 1.1746894121170044
CurrentTrain: epoch  2, batch     5 | loss: 3.3919253Losses:  3.4436161518096924 0.4126323461532593
CurrentTrain: epoch  2, batch     6 | loss: 3.8562484Losses:  2.467038154602051 1.1129732131958008
CurrentTrain: epoch  3, batch     0 | loss: 3.5800114Losses:  1.765568494796753 0.905764639377594
CurrentTrain: epoch  3, batch     1 | loss: 2.6713331Losses:  2.322512626647949 0.9957549571990967
CurrentTrain: epoch  3, batch     2 | loss: 3.3182676Losses:  2.7388505935668945 0.9200689792633057
CurrentTrain: epoch  3, batch     3 | loss: 3.6589196Losses:  2.3124921321868896 1.0610157251358032
CurrentTrain: epoch  3, batch     4 | loss: 3.3735080Losses:  2.6895265579223633 1.1278488636016846
CurrentTrain: epoch  3, batch     5 | loss: 3.8173754Losses:  4.065945625305176 0.5451165437698364
CurrentTrain: epoch  3, batch     6 | loss: 4.6110620Losses:  1.9328768253326416 1.0272935628890991
CurrentTrain: epoch  4, batch     0 | loss: 2.9601703Losses:  1.543163537979126 0.8255661725997925
CurrentTrain: epoch  4, batch     1 | loss: 2.3687296Losses:  2.4984138011932373 1.0309171676635742
CurrentTrain: epoch  4, batch     2 | loss: 3.5293310Losses:  2.6670291423797607 0.9614219665527344
CurrentTrain: epoch  4, batch     3 | loss: 3.6284511Losses:  3.0703999996185303 1.036773443222046
CurrentTrain: epoch  4, batch     4 | loss: 4.1071734Losses:  1.6641755104064941 1.0467764139175415
CurrentTrain: epoch  4, batch     5 | loss: 2.7109518Losses:  2.288693428039551 0.24437110126018524
CurrentTrain: epoch  4, batch     6 | loss: 2.5330646Losses:  1.8814070224761963 0.8092926740646362
CurrentTrain: epoch  5, batch     0 | loss: 2.6906996Losses:  2.1096389293670654 1.0562258958816528
CurrentTrain: epoch  5, batch     1 | loss: 3.1658649Losses:  2.557366371154785 1.0684657096862793
CurrentTrain: epoch  5, batch     2 | loss: 3.6258321Losses:  1.667312502861023 0.9088159799575806
CurrentTrain: epoch  5, batch     3 | loss: 2.5761285Losses:  1.8550361394882202 0.8533269166946411
CurrentTrain: epoch  5, batch     4 | loss: 2.7083631Losses:  2.1736972332000732 1.091098666191101
CurrentTrain: epoch  5, batch     5 | loss: 3.2647958Losses:  2.6454203128814697 0.46800169348716736
CurrentTrain: epoch  5, batch     6 | loss: 3.1134219Losses:  1.3612240552902222 0.9295427799224854
CurrentTrain: epoch  6, batch     0 | loss: 2.2907667Losses:  2.1500039100646973 0.8267378807067871
CurrentTrain: epoch  6, batch     1 | loss: 2.9767418Losses:  2.19339919090271 1.0162768363952637
CurrentTrain: epoch  6, batch     2 | loss: 3.2096760Losses:  1.7158149480819702 0.688687264919281
CurrentTrain: epoch  6, batch     3 | loss: 2.4045022Losses:  1.6208440065383911 0.8555895686149597
CurrentTrain: epoch  6, batch     4 | loss: 2.4764335Losses:  2.5290699005126953 1.0250204801559448
CurrentTrain: epoch  6, batch     5 | loss: 3.5540905Losses:  2.1267199516296387 0.5196031928062439
CurrentTrain: epoch  6, batch     6 | loss: 2.6463232Losses:  2.0636799335479736 0.9738210439682007
CurrentTrain: epoch  7, batch     0 | loss: 3.0375009Losses:  2.0175697803497314 0.8836244344711304
CurrentTrain: epoch  7, batch     1 | loss: 2.9011941Losses:  2.286229133605957 0.7627827525138855
CurrentTrain: epoch  7, batch     2 | loss: 3.0490119Losses:  1.4433709383010864 0.7354254722595215
CurrentTrain: epoch  7, batch     3 | loss: 2.1787963Losses:  1.566598892211914 0.6456596255302429
CurrentTrain: epoch  7, batch     4 | loss: 2.2122586Losses:  1.3344340324401855 0.728168249130249
CurrentTrain: epoch  7, batch     5 | loss: 2.0626023Losses:  2.846842050552368 0.403470903635025
CurrentTrain: epoch  7, batch     6 | loss: 3.2503130Losses:  1.6036443710327148 0.9361259937286377
CurrentTrain: epoch  8, batch     0 | loss: 2.5397704Losses:  2.1477646827697754 0.8123095631599426
CurrentTrain: epoch  8, batch     1 | loss: 2.9600742Losses:  1.2986834049224854 0.7730326056480408
CurrentTrain: epoch  8, batch     2 | loss: 2.0717161Losses:  1.575620412826538 0.737615704536438
CurrentTrain: epoch  8, batch     3 | loss: 2.3132362Losses:  1.493668556213379 0.8545413017272949
CurrentTrain: epoch  8, batch     4 | loss: 2.3482099Losses:  2.329367160797119 0.8085023164749146
CurrentTrain: epoch  8, batch     5 | loss: 3.1378694Losses:  1.5742820501327515 0.20229032635688782
CurrentTrain: epoch  8, batch     6 | loss: 1.7765723Losses:  1.2300381660461426 0.5846600532531738
CurrentTrain: epoch  9, batch     0 | loss: 1.8146982Losses:  1.2539393901824951 0.8170267343521118
CurrentTrain: epoch  9, batch     1 | loss: 2.0709662Losses:  1.8677068948745728 0.8330027461051941
CurrentTrain: epoch  9, batch     2 | loss: 2.7007096Losses:  1.6458903551101685 0.7621632218360901
CurrentTrain: epoch  9, batch     3 | loss: 2.4080536Losses:  1.8269376754760742 0.7419999837875366
CurrentTrain: epoch  9, batch     4 | loss: 2.5689378Losses:  1.8254302740097046 0.927977442741394
CurrentTrain: epoch  9, batch     5 | loss: 2.7534077Losses:  1.4110966920852661 0.41542112827301025
CurrentTrain: epoch  9, batch     6 | loss: 1.8265178
[EVAL] batch:    0 | acc: 56.25%,  total acc: 56.25%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 46.88%   [EVAL] batch:    2 | acc: 43.75%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    4 | acc: 31.25%,  total acc: 41.25%   [EVAL] batch:    5 | acc: 31.25%,  total acc: 39.58%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 45.54%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 52.34%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 56.94%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 61.25%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 64.20%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 66.67%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 67.31%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 64.73%   [EVAL] batch:   14 | acc: 37.50%,  total acc: 62.92%   [EVAL] batch:   15 | acc: 37.50%,  total acc: 61.33%   [EVAL] batch:   16 | acc: 43.75%,  total acc: 60.29%   [EVAL] batch:   17 | acc: 75.00%,  total acc: 61.11%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 61.18%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 63.12%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 64.88%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 66.19%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 67.66%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 69.01%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 70.91%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 71.76%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 72.54%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 73.49%   [EVAL] batch:   29 | acc: 81.25%,  total acc: 73.75%   [EVAL] batch:   30 | acc: 93.75%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 75.95%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 76.47%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 76.96%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 77.43%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 77.87%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 78.29%   [EVAL] batch:   38 | acc: 81.25%,  total acc: 78.37%   [EVAL] batch:   39 | acc: 87.50%,  total acc: 78.59%   [EVAL] batch:   40 | acc: 81.25%,  total acc: 78.66%   [EVAL] batch:   41 | acc: 81.25%,  total acc: 78.72%   [EVAL] batch:   42 | acc: 43.75%,  total acc: 77.91%   [EVAL] batch:   43 | acc: 93.75%,  total acc: 78.27%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 78.75%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 79.08%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 79.52%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 79.95%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 80.10%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 80.38%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 80.51%   [EVAL] batch:   51 | acc: 56.25%,  total acc: 80.05%   [EVAL] batch:   52 | acc: 43.75%,  total acc: 79.36%   [EVAL] batch:   53 | acc: 62.50%,  total acc: 79.05%   [EVAL] batch:   54 | acc: 62.50%,  total acc: 78.75%   [EVAL] batch:   55 | acc: 43.75%,  total acc: 78.12%   [EVAL] batch:   56 | acc: 31.25%,  total acc: 77.30%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 77.16%   [EVAL] batch:   58 | acc: 50.00%,  total acc: 76.69%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 76.67%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 76.64%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 76.92%   [EVAL] batch:   62 | acc: 25.00%,  total acc: 76.09%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 89.58%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 86.25%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 86.46%   [EVAL] batch:    6 | acc: 43.75%,  total acc: 80.36%   [EVAL] batch:    7 | acc: 50.00%,  total acc: 76.56%   [EVAL] batch:    8 | acc: 50.00%,  total acc: 73.61%   [EVAL] batch:    9 | acc: 56.25%,  total acc: 71.88%   [EVAL] batch:   10 | acc: 56.25%,  total acc: 70.45%   [EVAL] batch:   11 | acc: 62.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 68.75%,  total acc: 69.71%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 71.43%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 74.61%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 76.10%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 77.08%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 78.29%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 78.44%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 79.17%   [EVAL] batch:   21 | acc: 62.50%,  total acc: 78.41%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 78.26%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 78.65%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 79.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 79.81%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 80.56%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 81.68%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 82.29%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 82.86%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 83.40%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 83.90%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 84.01%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 83.93%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 84.20%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 84.63%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 85.03%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 85.42%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 85.78%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 86.13%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 86.16%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 86.34%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 86.65%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 86.81%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 86.96%   [EVAL] batch:   46 | acc: 81.25%,  total acc: 86.84%   [EVAL] batch:   47 | acc: 87.50%,  total acc: 86.85%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 87.12%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 87.12%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 87.25%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 87.26%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 87.38%   [EVAL] batch:   53 | acc: 75.00%,  total acc: 87.15%   [EVAL] batch:   54 | acc: 68.75%,  total acc: 86.82%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 86.83%   [EVAL] batch:   56 | acc: 43.75%,  total acc: 86.07%   [EVAL] batch:   57 | acc: 31.25%,  total acc: 85.13%   [EVAL] batch:   58 | acc: 43.75%,  total acc: 84.43%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 83.85%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 83.20%   [EVAL] batch:   61 | acc: 56.25%,  total acc: 82.76%   [EVAL] batch:   62 | acc: 37.50%,  total acc: 82.04%   [EVAL] batch:   63 | acc: 18.75%,  total acc: 81.05%   [EVAL] batch:   64 | acc: 25.00%,  total acc: 80.19%   [EVAL] batch:   65 | acc: 18.75%,  total acc: 79.26%   [EVAL] batch:   66 | acc: 6.25%,  total acc: 78.17%   [EVAL] batch:   67 | acc: 31.25%,  total acc: 77.48%   [EVAL] batch:   68 | acc: 43.75%,  total acc: 76.99%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 77.32%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 77.64%   [EVAL] batch:   71 | acc: 81.25%,  total acc: 77.69%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 78.00%   [EVAL] batch:   73 | acc: 87.50%,  total acc: 78.12%   [EVAL] batch:   74 | acc: 93.75%,  total acc: 78.33%   [EVAL] batch:   75 | acc: 68.75%,  total acc: 78.21%   [EVAL] batch:   76 | acc: 56.25%,  total acc: 77.92%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 77.88%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 77.85%   [EVAL] batch:   79 | acc: 87.50%,  total acc: 77.97%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 77.93%   [EVAL] batch:   81 | acc: 56.25%,  total acc: 77.67%   [EVAL] batch:   82 | acc: 37.50%,  total acc: 77.18%   [EVAL] batch:   83 | acc: 43.75%,  total acc: 76.79%   [EVAL] batch:   84 | acc: 31.25%,  total acc: 76.25%   [EVAL] batch:   85 | acc: 56.25%,  total acc: 76.02%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 75.50%   [EVAL] batch:   87 | acc: 68.75%,  total acc: 75.43%   [EVAL] batch:   88 | acc: 75.00%,  total acc: 75.42%   [EVAL] batch:   89 | acc: 81.25%,  total acc: 75.49%   [EVAL] batch:   90 | acc: 87.50%,  total acc: 75.62%   [EVAL] batch:   91 | acc: 81.25%,  total acc: 75.68%   [EVAL] batch:   92 | acc: 68.75%,  total acc: 75.60%   [EVAL] batch:   93 | acc: 62.50%,  total acc: 75.47%   [EVAL] batch:   94 | acc: 43.75%,  total acc: 75.13%   [EVAL] batch:   95 | acc: 37.50%,  total acc: 74.74%   [EVAL] batch:   96 | acc: 56.25%,  total acc: 74.55%   [EVAL] batch:   97 | acc: 37.50%,  total acc: 74.17%   [EVAL] batch:   98 | acc: 62.50%,  total acc: 74.05%   [EVAL] batch:   99 | acc: 50.00%,  total acc: 73.81%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 73.64%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 73.53%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 73.36%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 73.26%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 73.21%   [EVAL] batch:  105 | acc: 62.50%,  total acc: 73.11%   [EVAL] batch:  106 | acc: 43.75%,  total acc: 72.84%   [EVAL] batch:  107 | acc: 6.25%,  total acc: 72.22%   [EVAL] batch:  108 | acc: 18.75%,  total acc: 71.73%   [EVAL] batch:  109 | acc: 6.25%,  total acc: 71.14%   [EVAL] batch:  110 | acc: 12.50%,  total acc: 70.61%   [EVAL] batch:  111 | acc: 31.25%,  total acc: 70.26%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 70.13%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 70.39%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 70.65%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 70.91%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 71.15%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 71.40%   [EVAL] batch:  118 | acc: 87.50%,  total acc: 71.53%   [EVAL] batch:  119 | acc: 68.75%,  total acc: 71.51%   [EVAL] batch:  120 | acc: 50.00%,  total acc: 71.33%   [EVAL] batch:  121 | acc: 68.75%,  total acc: 71.31%   [EVAL] batch:  122 | acc: 75.00%,  total acc: 71.34%   [EVAL] batch:  123 | acc: 56.25%,  total acc: 71.22%   [EVAL] batch:  124 | acc: 75.00%,  total acc: 71.25%   [EVAL] batch:  125 | acc: 75.00%,  total acc: 71.28%   [EVAL] batch:  126 | acc: 43.75%,  total acc: 71.06%   [EVAL] batch:  127 | acc: 62.50%,  total acc: 71.00%   [EVAL] batch:  128 | acc: 68.75%,  total acc: 70.98%   [EVAL] batch:  129 | acc: 62.50%,  total acc: 70.91%   [EVAL] batch:  130 | acc: 62.50%,  total acc: 70.85%   [EVAL] batch:  131 | acc: 68.75%,  total acc: 70.83%   [EVAL] batch:  132 | acc: 81.25%,  total acc: 70.91%   [EVAL] batch:  133 | acc: 50.00%,  total acc: 70.76%   [EVAL] batch:  134 | acc: 62.50%,  total acc: 70.69%   [EVAL] batch:  135 | acc: 75.00%,  total acc: 70.73%   [EVAL] batch:  136 | acc: 62.50%,  total acc: 70.67%   [EVAL] batch:  137 | acc: 43.75%,  total acc: 70.47%   [EVAL] batch:  138 | acc: 25.00%,  total acc: 70.14%   [EVAL] batch:  139 | acc: 31.25%,  total acc: 69.87%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 69.55%   [EVAL] batch:  141 | acc: 43.75%,  total acc: 69.37%   [EVAL] batch:  142 | acc: 37.50%,  total acc: 69.14%   [EVAL] batch:  143 | acc: 37.50%,  total acc: 68.92%   [EVAL] batch:  144 | acc: 93.75%,  total acc: 69.09%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 69.31%   [EVAL] batch:  146 | acc: 100.00%,  total acc: 69.52%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 69.72%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 69.92%   [EVAL] batch:  149 | acc: 93.75%,  total acc: 70.08%   [EVAL] batch:  150 | acc: 0.00%,  total acc: 69.62%   [EVAL] batch:  151 | acc: 0.00%,  total acc: 69.16%   [EVAL] batch:  152 | acc: 0.00%,  total acc: 68.71%   [EVAL] batch:  153 | acc: 0.00%,  total acc: 68.26%   [EVAL] batch:  154 | acc: 0.00%,  total acc: 67.82%   [EVAL] batch:  155 | acc: 0.00%,  total acc: 67.39%   [EVAL] batch:  156 | acc: 75.00%,  total acc: 67.44%   [EVAL] batch:  157 | acc: 93.75%,  total acc: 67.60%   [EVAL] batch:  158 | acc: 100.00%,  total acc: 67.81%   [EVAL] batch:  159 | acc: 93.75%,  total acc: 67.97%   [EVAL] batch:  160 | acc: 100.00%,  total acc: 68.17%   [EVAL] batch:  161 | acc: 93.75%,  total acc: 68.33%   [EVAL] batch:  162 | acc: 68.75%,  total acc: 68.33%   [EVAL] batch:  163 | acc: 62.50%,  total acc: 68.29%   [EVAL] batch:  164 | acc: 68.75%,  total acc: 68.30%   [EVAL] batch:  165 | acc: 62.50%,  total acc: 68.26%   [EVAL] batch:  166 | acc: 56.25%,  total acc: 68.19%   [EVAL] batch:  167 | acc: 56.25%,  total acc: 68.12%   [EVAL] batch:  168 | acc: 50.00%,  total acc: 68.01%   [EVAL] batch:  169 | acc: 18.75%,  total acc: 67.72%   [EVAL] batch:  170 | acc: 56.25%,  total acc: 67.65%   [EVAL] batch:  171 | acc: 31.25%,  total acc: 67.44%   [EVAL] batch:  172 | acc: 37.50%,  total acc: 67.27%   [EVAL] batch:  173 | acc: 50.00%,  total acc: 67.17%   [EVAL] batch:  174 | acc: 43.75%,  total acc: 67.04%   [EVAL] batch:  175 | acc: 68.75%,  total acc: 67.05%   [EVAL] batch:  176 | acc: 81.25%,  total acc: 67.13%   [EVAL] batch:  177 | acc: 68.75%,  total acc: 67.13%   [EVAL] batch:  178 | acc: 87.50%,  total acc: 67.25%   [EVAL] batch:  179 | acc: 87.50%,  total acc: 67.36%   [EVAL] batch:  180 | acc: 81.25%,  total acc: 67.44%   [EVAL] batch:  181 | acc: 68.75%,  total acc: 67.45%   [EVAL] batch:  182 | acc: 87.50%,  total acc: 67.55%   [EVAL] batch:  183 | acc: 93.75%,  total acc: 67.70%   [EVAL] batch:  184 | acc: 87.50%,  total acc: 67.80%   [EVAL] batch:  185 | acc: 100.00%,  total acc: 67.98%   [EVAL] batch:  186 | acc: 81.25%,  total acc: 68.05%   [EVAL] batch:  187 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:  188 | acc: 93.75%,  total acc: 68.32%   [EVAL] batch:  189 | acc: 93.75%,  total acc: 68.45%   [EVAL] batch:  190 | acc: 100.00%,  total acc: 68.62%   [EVAL] batch:  191 | acc: 81.25%,  total acc: 68.68%   [EVAL] batch:  192 | acc: 100.00%,  total acc: 68.85%   [EVAL] batch:  193 | acc: 81.25%,  total acc: 68.91%   [EVAL] batch:  194 | acc: 37.50%,  total acc: 68.75%   [EVAL] batch:  195 | acc: 50.00%,  total acc: 68.65%   [EVAL] batch:  196 | acc: 62.50%,  total acc: 68.62%   [EVAL] batch:  197 | acc: 56.25%,  total acc: 68.56%   [EVAL] batch:  198 | acc: 37.50%,  total acc: 68.40%   [EVAL] batch:  199 | acc: 50.00%,  total acc: 68.31%   [EVAL] batch:  200 | acc: 62.50%,  total acc: 68.28%   [EVAL] batch:  201 | acc: 81.25%,  total acc: 68.35%   [EVAL] batch:  202 | acc: 68.75%,  total acc: 68.35%   [EVAL] batch:  203 | acc: 50.00%,  total acc: 68.26%   [EVAL] batch:  204 | acc: 75.00%,  total acc: 68.29%   [EVAL] batch:  205 | acc: 68.75%,  total acc: 68.29%   [EVAL] batch:  206 | acc: 50.00%,  total acc: 68.21%   [EVAL] batch:  207 | acc: 43.75%,  total acc: 68.09%   [EVAL] batch:  208 | acc: 25.00%,  total acc: 67.88%   [EVAL] batch:  209 | acc: 43.75%,  total acc: 67.77%   [EVAL] batch:  210 | acc: 50.00%,  total acc: 67.68%   [EVAL] batch:  211 | acc: 12.50%,  total acc: 67.42%   [EVAL] batch:  212 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 67.58%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 67.73%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 67.88%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 68.03%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 68.18%   [EVAL] batch:  218 | acc: 100.00%,  total acc: 68.32%   [EVAL] batch:  219 | acc: 68.75%,  total acc: 68.32%   [EVAL] batch:  220 | acc: 81.25%,  total acc: 68.38%   [EVAL] batch:  221 | acc: 68.75%,  total acc: 68.38%   [EVAL] batch:  222 | acc: 62.50%,  total acc: 68.36%   [EVAL] batch:  223 | acc: 75.00%,  total acc: 68.39%   [EVAL] batch:  224 | acc: 43.75%,  total acc: 68.28%   [EVAL] batch:  225 | acc: 100.00%,  total acc: 68.42%   [EVAL] batch:  226 | acc: 100.00%,  total acc: 68.56%   [EVAL] batch:  227 | acc: 100.00%,  total acc: 68.70%   [EVAL] batch:  228 | acc: 100.00%,  total acc: 68.83%   [EVAL] batch:  229 | acc: 100.00%,  total acc: 68.97%   [EVAL] batch:  230 | acc: 93.75%,  total acc: 69.07%   [EVAL] batch:  231 | acc: 100.00%,  total acc: 69.21%   [EVAL] batch:  232 | acc: 100.00%,  total acc: 69.34%   [EVAL] batch:  233 | acc: 100.00%,  total acc: 69.47%   [EVAL] batch:  234 | acc: 100.00%,  total acc: 69.60%   [EVAL] batch:  235 | acc: 100.00%,  total acc: 69.73%   [EVAL] batch:  236 | acc: 100.00%,  total acc: 69.86%   [EVAL] batch:  237 | acc: 100.00%,  total acc: 69.98%   [EVAL] batch:  238 | acc: 100.00%,  total acc: 70.11%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 70.21%   [EVAL] batch:  240 | acc: 100.00%,  total acc: 70.33%   [EVAL] batch:  241 | acc: 100.00%,  total acc: 70.45%   [EVAL] batch:  242 | acc: 100.00%,  total acc: 70.58%   [EVAL] batch:  243 | acc: 93.75%,  total acc: 70.67%   [EVAL] batch:  244 | acc: 100.00%,  total acc: 70.79%   [EVAL] batch:  245 | acc: 87.50%,  total acc: 70.86%   [EVAL] batch:  246 | acc: 93.75%,  total acc: 70.95%   [EVAL] batch:  247 | acc: 100.00%,  total acc: 71.07%   [EVAL] batch:  248 | acc: 100.00%,  total acc: 71.18%   [EVAL] batch:  249 | acc: 93.75%,  total acc: 71.28%   [EVAL] batch:  250 | acc: 75.00%,  total acc: 71.29%   [EVAL] batch:  251 | acc: 87.50%,  total acc: 71.35%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 71.44%   [EVAL] batch:  253 | acc: 87.50%,  total acc: 71.51%   [EVAL] batch:  254 | acc: 81.25%,  total acc: 71.54%   [EVAL] batch:  255 | acc: 100.00%,  total acc: 71.66%   [EVAL] batch:  256 | acc: 56.25%,  total acc: 71.60%   [EVAL] batch:  257 | acc: 75.00%,  total acc: 71.61%   [EVAL] batch:  258 | acc: 62.50%,  total acc: 71.57%   [EVAL] batch:  259 | acc: 62.50%,  total acc: 71.54%   [EVAL] batch:  260 | acc: 43.75%,  total acc: 71.43%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 71.42%   [EVAL] batch:  262 | acc: 93.75%,  total acc: 71.51%   [EVAL] batch:  263 | acc: 81.25%,  total acc: 71.54%   [EVAL] batch:  264 | acc: 75.00%,  total acc: 71.56%   [EVAL] batch:  265 | acc: 75.00%,  total acc: 71.57%   [EVAL] batch:  266 | acc: 81.25%,  total acc: 71.61%   [EVAL] batch:  267 | acc: 100.00%,  total acc: 71.71%   [EVAL] batch:  268 | acc: 100.00%,  total acc: 71.82%   [EVAL] batch:  269 | acc: 93.75%,  total acc: 71.90%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 72.00%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 72.10%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 72.21%   [EVAL] batch:  273 | acc: 93.75%,  total acc: 72.29%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 72.39%   [EVAL] batch:  275 | acc: 50.00%,  total acc: 72.31%   [EVAL] batch:  276 | acc: 31.25%,  total acc: 72.16%   [EVAL] batch:  277 | acc: 68.75%,  total acc: 72.14%   [EVAL] batch:  278 | acc: 75.00%,  total acc: 72.16%   [EVAL] batch:  279 | acc: 43.75%,  total acc: 72.05%   [EVAL] batch:  280 | acc: 50.00%,  total acc: 71.98%   [EVAL] batch:  281 | acc: 43.75%,  total acc: 71.88%   [EVAL] batch:  282 | acc: 43.75%,  total acc: 71.78%   [EVAL] batch:  283 | acc: 6.25%,  total acc: 71.54%   [EVAL] batch:  284 | acc: 18.75%,  total acc: 71.36%   [EVAL] batch:  285 | acc: 12.50%,  total acc: 71.15%   [EVAL] batch:  286 | acc: 6.25%,  total acc: 70.93%   [EVAL] batch:  287 | acc: 56.25%,  total acc: 70.88%   [EVAL] batch:  288 | acc: 75.00%,  total acc: 70.89%   [EVAL] batch:  289 | acc: 87.50%,  total acc: 70.95%   [EVAL] batch:  290 | acc: 87.50%,  total acc: 71.01%   [EVAL] batch:  291 | acc: 93.75%,  total acc: 71.08%   [EVAL] batch:  292 | acc: 87.50%,  total acc: 71.14%   [EVAL] batch:  293 | acc: 81.25%,  total acc: 71.17%   [EVAL] batch:  294 | acc: 81.25%,  total acc: 71.21%   [EVAL] batch:  295 | acc: 62.50%,  total acc: 71.18%   [EVAL] batch:  296 | acc: 62.50%,  total acc: 71.15%   [EVAL] batch:  297 | acc: 62.50%,  total acc: 71.12%   [EVAL] batch:  298 | acc: 56.25%,  total acc: 71.07%   [EVAL] batch:  299 | acc: 68.75%,  total acc: 71.06%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 71.16%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 71.25%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 71.35%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 71.44%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 71.54%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 71.63%   [EVAL] batch:  306 | acc: 93.75%,  total acc: 71.70%   [EVAL] batch:  307 | acc: 87.50%,  total acc: 71.75%   [EVAL] batch:  308 | acc: 87.50%,  total acc: 71.80%   [EVAL] batch:  309 | acc: 93.75%,  total acc: 71.88%   [EVAL] batch:  310 | acc: 87.50%,  total acc: 71.93%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 72.02%   [EVAL] batch:  312 | acc: 81.25%,  total acc: 72.04%   [EVAL] batch:  313 | acc: 50.00%,  total acc: 71.97%   [EVAL] batch:  314 | acc: 43.75%,  total acc: 71.88%   [EVAL] batch:  315 | acc: 31.25%,  total acc: 71.76%   [EVAL] batch:  316 | acc: 31.25%,  total acc: 71.63%   [EVAL] batch:  317 | acc: 37.50%,  total acc: 71.52%   [EVAL] batch:  318 | acc: 43.75%,  total acc: 71.43%   [EVAL] batch:  319 | acc: 100.00%,  total acc: 71.52%   [EVAL] batch:  320 | acc: 100.00%,  total acc: 71.61%   [EVAL] batch:  321 | acc: 93.75%,  total acc: 71.68%   [EVAL] batch:  322 | acc: 100.00%,  total acc: 71.77%   [EVAL] batch:  323 | acc: 93.75%,  total acc: 71.84%   [EVAL] batch:  324 | acc: 87.50%,  total acc: 71.88%   [EVAL] batch:  325 | acc: 56.25%,  total acc: 71.84%   [EVAL] batch:  326 | acc: 12.50%,  total acc: 71.66%   [EVAL] batch:  327 | acc: 43.75%,  total acc: 71.57%   [EVAL] batch:  328 | acc: 50.00%,  total acc: 71.50%   [EVAL] batch:  329 | acc: 56.25%,  total acc: 71.46%   [EVAL] batch:  330 | acc: 56.25%,  total acc: 71.41%   [EVAL] batch:  331 | acc: 93.75%,  total acc: 71.48%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 71.57%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 71.65%   [EVAL] batch:  334 | acc: 93.75%,  total acc: 71.72%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 71.80%   [EVAL] batch:  336 | acc: 100.00%,  total acc: 71.88%   [EVAL] batch:  337 | acc: 93.75%,  total acc: 71.95%   [EVAL] batch:  338 | acc: 87.50%,  total acc: 71.99%   [EVAL] batch:  339 | acc: 93.75%,  total acc: 72.06%   [EVAL] batch:  340 | acc: 100.00%,  total acc: 72.14%   [EVAL] batch:  341 | acc: 81.25%,  total acc: 72.17%   [EVAL] batch:  342 | acc: 100.00%,  total acc: 72.25%   [EVAL] batch:  343 | acc: 93.75%,  total acc: 72.31%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 72.39%   [EVAL] batch:  345 | acc: 100.00%,  total acc: 72.47%   [EVAL] batch:  346 | acc: 87.50%,  total acc: 72.51%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 72.58%   [EVAL] batch:  348 | acc: 93.75%,  total acc: 72.64%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 72.71%   [EVAL] batch:  350 | acc: 75.00%,  total acc: 72.72%   [EVAL] batch:  351 | acc: 93.75%,  total acc: 72.78%   [EVAL] batch:  352 | acc: 75.00%,  total acc: 72.79%   [EVAL] batch:  353 | acc: 100.00%,  total acc: 72.86%   [EVAL] batch:  354 | acc: 50.00%,  total acc: 72.80%   [EVAL] batch:  355 | acc: 68.75%,  total acc: 72.79%   [EVAL] batch:  356 | acc: 100.00%,  total acc: 72.86%   [EVAL] batch:  357 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:  358 | acc: 100.00%,  total acc: 73.00%   [EVAL] batch:  359 | acc: 100.00%,  total acc: 73.07%   [EVAL] batch:  360 | acc: 93.75%,  total acc: 73.13%   [EVAL] batch:  361 | acc: 87.50%,  total acc: 73.17%   [EVAL] batch:  362 | acc: 87.50%,  total acc: 73.21%   [EVAL] batch:  363 | acc: 81.25%,  total acc: 73.23%   [EVAL] batch:  364 | acc: 50.00%,  total acc: 73.17%   [EVAL] batch:  365 | acc: 50.00%,  total acc: 73.10%   [EVAL] batch:  366 | acc: 62.50%,  total acc: 73.08%   [EVAL] batch:  367 | acc: 56.25%,  total acc: 73.03%   [EVAL] batch:  368 | acc: 37.50%,  total acc: 72.93%   [EVAL] batch:  369 | acc: 43.75%,  total acc: 72.85%   [EVAL] batch:  370 | acc: 68.75%,  total acc: 72.84%   [EVAL] batch:  371 | acc: 50.00%,  total acc: 72.78%   [EVAL] batch:  372 | acc: 81.25%,  total acc: 72.80%   [EVAL] batch:  373 | acc: 87.50%,  total acc: 72.84%   [EVAL] batch:  374 | acc: 68.75%,  total acc: 72.83%   
cur_acc:  ['0.9464', '0.7262', '0.7609', '0.8423', '0.8304', '0.7609']
his_acc:  ['0.9464', '0.8255', '0.7912', '0.7895', '0.7794', '0.7283']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.0500078201293945 1.2317743301391602
CurrentTrain: epoch  0, batch     0 | loss: 8.2817822Losses:  9.723382949829102 1.428454875946045
CurrentTrain: epoch  0, batch     1 | loss: 11.1518383Losses:  9.358404159545898 1.2080917358398438
CurrentTrain: epoch  0, batch     2 | loss: 10.5664959Losses:  9.62886905670166 1.0975086688995361
CurrentTrain: epoch  0, batch     3 | loss: 10.7263775Losses:  9.642108917236328 1.518970251083374
CurrentTrain: epoch  0, batch     4 | loss: 11.1610794Losses:  9.492841720581055 1.2250235080718994
CurrentTrain: epoch  0, batch     5 | loss: 10.7178650Losses:  8.689658164978027 1.3188320398330688
CurrentTrain: epoch  0, batch     6 | loss: 10.0084906Losses:  2.6820168495178223 1.1365793943405151
CurrentTrain: epoch  1, batch     0 | loss: 3.8185964Losses:  2.0921671390533447 1.356268048286438
CurrentTrain: epoch  1, batch     1 | loss: 3.4484353Losses:  2.243682622909546 1.2014843225479126
CurrentTrain: epoch  1, batch     2 | loss: 3.4451671Losses:  2.870278835296631 1.17396080493927
CurrentTrain: epoch  1, batch     3 | loss: 4.0442395Losses:  1.6266558170318604 1.0207593441009521
CurrentTrain: epoch  1, batch     4 | loss: 2.6474152Losses:  3.046980142593384 1.5107131004333496
CurrentTrain: epoch  1, batch     5 | loss: 4.5576935Losses:  2.8355495929718018 1.292240023612976
CurrentTrain: epoch  1, batch     6 | loss: 4.1277895Losses:  2.9113736152648926 1.3180627822875977
CurrentTrain: epoch  2, batch     0 | loss: 4.2294364Losses:  1.505802035331726 1.110902190208435
CurrentTrain: epoch  2, batch     1 | loss: 2.6167042Losses:  2.0212817192077637 1.1100177764892578
CurrentTrain: epoch  2, batch     2 | loss: 3.1312995Losses:  1.9450161457061768 0.9579786062240601
CurrentTrain: epoch  2, batch     3 | loss: 2.9029946Losses:  2.6597681045532227 1.2883750200271606
CurrentTrain: epoch  2, batch     4 | loss: 3.9481430Losses:  2.6011242866516113 1.0685116052627563
CurrentTrain: epoch  2, batch     5 | loss: 3.6696358Losses:  2.2834298610687256 1.2122838497161865
CurrentTrain: epoch  2, batch     6 | loss: 3.4957137Losses:  2.081021785736084 1.1161181926727295
CurrentTrain: epoch  3, batch     0 | loss: 3.1971400Losses:  2.4196362495422363 1.0637388229370117
CurrentTrain: epoch  3, batch     1 | loss: 3.4833751Losses:  1.7671629190444946 1.0089093446731567
CurrentTrain: epoch  3, batch     2 | loss: 2.7760723Losses:  2.576899290084839 1.1169477701187134
CurrentTrain: epoch  3, batch     3 | loss: 3.6938472Losses:  1.7995308637619019 1.014952540397644
CurrentTrain: epoch  3, batch     4 | loss: 2.8144834Losses:  2.0883469581604004 1.16054368019104
CurrentTrain: epoch  3, batch     5 | loss: 3.2488906Losses:  2.0300002098083496 1.2318626642227173
CurrentTrain: epoch  3, batch     6 | loss: 3.2618628Losses:  2.4167823791503906 1.053255319595337
CurrentTrain: epoch  4, batch     0 | loss: 3.4700377Losses:  2.277423143386841 1.112242341041565
CurrentTrain: epoch  4, batch     1 | loss: 3.3896656Losses:  2.2537691593170166 1.023850440979004
CurrentTrain: epoch  4, batch     2 | loss: 3.2776196Losses:  1.8529108762741089 0.7833560705184937
CurrentTrain: epoch  4, batch     3 | loss: 2.6362669Losses:  1.4902492761611938 0.8458154201507568
CurrentTrain: epoch  4, batch     4 | loss: 2.3360648Losses:  2.6881561279296875 1.2447137832641602
CurrentTrain: epoch  4, batch     5 | loss: 3.9328699Losses:  1.0617128610610962 0.6558149456977844
CurrentTrain: epoch  4, batch     6 | loss: 1.7175279Losses:  1.4918127059936523 0.8162325024604797
CurrentTrain: epoch  5, batch     0 | loss: 2.3080451Losses:  2.251612424850464 1.0011279582977295
CurrentTrain: epoch  5, batch     1 | loss: 3.2527404Losses:  1.7595219612121582 0.7810811996459961
CurrentTrain: epoch  5, batch     2 | loss: 2.5406032Losses:  1.8195569515228271 1.0276556015014648
CurrentTrain: epoch  5, batch     3 | loss: 2.8472126Losses:  1.8409948348999023 1.001065969467163
CurrentTrain: epoch  5, batch     4 | loss: 2.8420608Losses:  1.801096796989441 0.6277393698692322
CurrentTrain: epoch  5, batch     5 | loss: 2.4288361Losses:  2.1451575756073 1.039720058441162
CurrentTrain: epoch  5, batch     6 | loss: 3.1848776Losses:  1.8883699178695679 1.0020962953567505
CurrentTrain: epoch  6, batch     0 | loss: 2.8904662Losses:  1.6889674663543701 0.8710877299308777
CurrentTrain: epoch  6, batch     1 | loss: 2.5600553Losses:  1.7785557508468628 0.9900654554367065
CurrentTrain: epoch  6, batch     2 | loss: 2.7686212Losses:  2.0977354049682617 0.8016313910484314
CurrentTrain: epoch  6, batch     3 | loss: 2.8993669Losses:  1.5753588676452637 0.8138571381568909
CurrentTrain: epoch  6, batch     4 | loss: 2.3892159Losses:  1.800034761428833 0.9336901307106018
CurrentTrain: epoch  6, batch     5 | loss: 2.7337248Losses:  1.5703654289245605 0.867600679397583
CurrentTrain: epoch  6, batch     6 | loss: 2.4379661Losses:  1.8689906597137451 1.0263384580612183
CurrentTrain: epoch  7, batch     0 | loss: 2.8953290Losses:  1.3571031093597412 0.8058937191963196
CurrentTrain: epoch  7, batch     1 | loss: 2.1629968Losses:  1.8526983261108398 0.7717141509056091
CurrentTrain: epoch  7, batch     2 | loss: 2.6244125Losses:  2.2654004096984863 0.9328054189682007
CurrentTrain: epoch  7, batch     3 | loss: 3.1982059Losses:  1.4198241233825684 0.8402441740036011
CurrentTrain: epoch  7, batch     4 | loss: 2.2600684Losses:  1.4725797176361084 0.9644595980644226
CurrentTrain: epoch  7, batch     5 | loss: 2.4370394Losses:  1.6475263833999634 0.662634551525116
CurrentTrain: epoch  7, batch     6 | loss: 2.3101609Losses:  1.8085999488830566 1.0331382751464844
CurrentTrain: epoch  8, batch     0 | loss: 2.8417382Losses:  2.0732808113098145 0.8869820237159729
CurrentTrain: epoch  8, batch     1 | loss: 2.9602628Losses:  1.0753095149993896 0.7694849967956543
CurrentTrain: epoch  8, batch     2 | loss: 1.8447945Losses:  1.4691003561019897 0.8452850580215454
CurrentTrain: epoch  8, batch     3 | loss: 2.3143854Losses:  1.3882098197937012 0.8047187328338623
CurrentTrain: epoch  8, batch     4 | loss: 2.1929286Losses:  1.878597378730774 0.867906928062439
CurrentTrain: epoch  8, batch     5 | loss: 2.7465043Losses:  1.6013771295547485 0.5666731595993042
CurrentTrain: epoch  8, batch     6 | loss: 2.1680503Losses:  2.0386791229248047 0.801162838935852
CurrentTrain: epoch  9, batch     0 | loss: 2.8398418Losses:  1.4291186332702637 0.8038667440414429
CurrentTrain: epoch  9, batch     1 | loss: 2.2329855Losses:  1.7338104248046875 0.8279760479927063
CurrentTrain: epoch  9, batch     2 | loss: 2.5617864Losses:  1.5302605628967285 0.6768112778663635
CurrentTrain: epoch  9, batch     3 | loss: 2.2070718Losses:  1.028302788734436 0.7380812168121338
CurrentTrain: epoch  9, batch     4 | loss: 1.7663840Losses:  1.6319255828857422 0.728188693523407
CurrentTrain: epoch  9, batch     5 | loss: 2.3601143Losses:  1.546894907951355 0.7223345041275024
CurrentTrain: epoch  9, batch     6 | loss: 2.2692294
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 40.62%   [EVAL] batch:    2 | acc: 37.50%,  total acc: 39.58%   [EVAL] batch:    3 | acc: 62.50%,  total acc: 45.31%   [EVAL] batch:    4 | acc: 31.25%,  total acc: 42.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 43.75%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 48.21%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 53.91%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 58.33%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 61.25%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 62.50%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 64.58%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 66.35%   [EVAL] batch:   13 | acc: 87.50%,  total acc: 67.86%   [EVAL] batch:   14 | acc: 87.50%,  total acc: 69.17%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 70.70%   [EVAL] batch:   16 | acc: 87.50%,  total acc: 71.69%   [EVAL] batch:   17 | acc: 100.00%,  total acc: 73.26%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 73.03%   [EVAL] batch:   19 | acc: 50.00%,  total acc: 71.88%   [EVAL] batch:   20 | acc: 37.50%,  total acc: 70.24%   [EVAL] batch:   21 | acc: 56.25%,  total acc: 69.60%   [EVAL] batch:   22 | acc: 62.50%,  total acc: 69.29%   [EVAL] batch:   23 | acc: 37.50%,  total acc: 67.97%   [EVAL] batch:   24 | acc: 31.25%,  total acc: 66.50%   [EVAL] batch:   25 | acc: 6.25%,  total acc: 64.18%   [EVAL] batch:   26 | acc: 6.25%,  total acc: 62.04%   [EVAL] batch:   27 | acc: 0.00%,  total acc: 59.82%   [EVAL] batch:   28 | acc: 0.00%,  total acc: 57.76%   [EVAL] batch:   29 | acc: 6.25%,  total acc: 56.04%   [EVAL] batch:   30 | acc: 6.25%,  total acc: 54.44%   [EVAL] batch:   31 | acc: 62.50%,  total acc: 54.69%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 55.87%   [EVAL] batch:   33 | acc: 81.25%,  total acc: 56.62%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 57.68%   [EVAL] batch:   35 | acc: 87.50%,  total acc: 58.51%   [EVAL] batch:   36 | acc: 81.25%,  total acc: 59.12%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 60.03%   [EVAL] batch:   38 | acc: 87.50%,  total acc: 60.74%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 61.72%   [EVAL] batch:   40 | acc: 93.75%,  total acc: 62.50%   [EVAL] batch:   41 | acc: 93.75%,  total acc: 63.24%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 64.10%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 64.91%   [EVAL] batch:   44 | acc: 87.50%,  total acc: 65.42%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 65.90%   [EVAL] batch:   46 | acc: 81.25%,  total acc: 66.22%   [EVAL] batch:   47 | acc: 87.50%,  total acc: 66.67%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 67.22%   [EVAL] batch:   49 | acc: 81.25%,  total acc: 67.50%   [EVAL] batch:   50 | acc: 56.25%,  total acc: 67.28%   [EVAL] batch:   51 | acc: 81.25%,  total acc: 67.55%   [EVAL] batch:   52 | acc: 75.00%,  total acc: 67.69%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 68.06%   [EVAL] batch:   54 | acc: 75.00%,  total acc: 68.18%   [EVAL] batch:   55 | acc: 75.00%,  total acc: 68.30%   [EVAL] batch:   56 | acc: 50.00%,  total acc: 67.98%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 67.89%   [EVAL] batch:   58 | acc: 56.25%,  total acc: 67.69%   [EVAL] batch:   59 | acc: 81.25%,  total acc: 67.92%   [EVAL] batch:   60 | acc: 50.00%,  total acc: 67.62%   [EVAL] batch:   61 | acc: 81.25%,  total acc: 67.84%   [EVAL] batch:   62 | acc: 31.25%,  total acc: 67.26%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 85.00%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 31.25%,  total acc: 77.68%   [EVAL] batch:    7 | acc: 56.25%,  total acc: 75.00%   [EVAL] batch:    8 | acc: 56.25%,  total acc: 72.92%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 70.62%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 67.05%   [EVAL] batch:   11 | acc: 37.50%,  total acc: 64.58%   [EVAL] batch:   12 | acc: 56.25%,  total acc: 63.94%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 67.92%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 69.92%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 71.69%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 74.34%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 74.69%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 75.30%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 75.00%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 75.27%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 75.78%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 76.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 77.16%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 78.01%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 78.79%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 79.31%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 80.00%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 80.65%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 81.82%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 82.17%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 82.14%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 82.47%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 82.94%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 83.39%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 83.81%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 84.22%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 84.60%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 84.67%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 84.88%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 85.23%   [EVAL] batch:   44 | acc: 87.50%,  total acc: 85.28%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 85.46%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 85.51%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 85.42%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 85.71%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 85.75%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 85.78%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 85.94%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 86.08%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 86.11%   [EVAL] batch:   54 | acc: 68.75%,  total acc: 85.80%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 85.83%   [EVAL] batch:   56 | acc: 43.75%,  total acc: 85.09%   [EVAL] batch:   57 | acc: 25.00%,  total acc: 84.05%   [EVAL] batch:   58 | acc: 50.00%,  total acc: 83.47%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 82.92%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 82.27%   [EVAL] batch:   61 | acc: 56.25%,  total acc: 81.85%   [EVAL] batch:   62 | acc: 31.25%,  total acc: 81.05%   [EVAL] batch:   63 | acc: 18.75%,  total acc: 80.08%   [EVAL] batch:   64 | acc: 18.75%,  total acc: 79.13%   [EVAL] batch:   65 | acc: 25.00%,  total acc: 78.31%   [EVAL] batch:   66 | acc: 6.25%,  total acc: 77.24%   [EVAL] batch:   67 | acc: 37.50%,  total acc: 76.65%   [EVAL] batch:   68 | acc: 37.50%,  total acc: 76.09%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 76.43%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 76.76%   [EVAL] batch:   71 | acc: 81.25%,  total acc: 76.82%   [EVAL] batch:   72 | acc: 93.75%,  total acc: 77.05%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 77.11%   [EVAL] batch:   74 | acc: 93.75%,  total acc: 77.33%   [EVAL] batch:   75 | acc: 62.50%,  total acc: 77.14%   [EVAL] batch:   76 | acc: 43.75%,  total acc: 76.70%   [EVAL] batch:   77 | acc: 68.75%,  total acc: 76.60%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 76.58%   [EVAL] batch:   79 | acc: 87.50%,  total acc: 76.72%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 76.70%   [EVAL] batch:   81 | acc: 56.25%,  total acc: 76.45%   [EVAL] batch:   82 | acc: 18.75%,  total acc: 75.75%   [EVAL] batch:   83 | acc: 12.50%,  total acc: 75.00%   [EVAL] batch:   84 | acc: 31.25%,  total acc: 74.49%   [EVAL] batch:   85 | acc: 31.25%,  total acc: 73.98%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 73.49%   [EVAL] batch:   87 | acc: 68.75%,  total acc: 73.44%   [EVAL] batch:   88 | acc: 43.75%,  total acc: 73.10%   [EVAL] batch:   89 | acc: 25.00%,  total acc: 72.57%   [EVAL] batch:   90 | acc: 43.75%,  total acc: 72.25%   [EVAL] batch:   91 | acc: 43.75%,  total acc: 71.94%   [EVAL] batch:   92 | acc: 62.50%,  total acc: 71.84%   [EVAL] batch:   93 | acc: 56.25%,  total acc: 71.68%   [EVAL] batch:   94 | acc: 37.50%,  total acc: 71.32%   [EVAL] batch:   95 | acc: 25.00%,  total acc: 70.83%   [EVAL] batch:   96 | acc: 50.00%,  total acc: 70.62%   [EVAL] batch:   97 | acc: 37.50%,  total acc: 70.28%   [EVAL] batch:   98 | acc: 56.25%,  total acc: 70.14%   [EVAL] batch:   99 | acc: 25.00%,  total acc: 69.69%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 69.55%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 69.49%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 69.36%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 69.29%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 69.29%   [EVAL] batch:  105 | acc: 62.50%,  total acc: 69.22%   [EVAL] batch:  106 | acc: 37.50%,  total acc: 68.93%   [EVAL] batch:  107 | acc: 6.25%,  total acc: 68.34%   [EVAL] batch:  108 | acc: 6.25%,  total acc: 67.78%   [EVAL] batch:  109 | acc: 0.00%,  total acc: 67.16%   [EVAL] batch:  110 | acc: 6.25%,  total acc: 66.61%   [EVAL] batch:  111 | acc: 18.75%,  total acc: 66.18%   [EVAL] batch:  112 | acc: 50.00%,  total acc: 66.04%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 66.34%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 66.63%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 66.92%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 67.20%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 67.48%   [EVAL] batch:  118 | acc: 87.50%,  total acc: 67.65%   [EVAL] batch:  119 | acc: 68.75%,  total acc: 67.66%   [EVAL] batch:  120 | acc: 50.00%,  total acc: 67.51%   [EVAL] batch:  121 | acc: 68.75%,  total acc: 67.52%   [EVAL] batch:  122 | acc: 75.00%,  total acc: 67.58%   [EVAL] batch:  123 | acc: 62.50%,  total acc: 67.54%   [EVAL] batch:  124 | acc: 75.00%,  total acc: 67.60%   [EVAL] batch:  125 | acc: 68.75%,  total acc: 67.61%   [EVAL] batch:  126 | acc: 43.75%,  total acc: 67.42%   [EVAL] batch:  127 | acc: 56.25%,  total acc: 67.33%   [EVAL] batch:  128 | acc: 68.75%,  total acc: 67.34%   [EVAL] batch:  129 | acc: 62.50%,  total acc: 67.31%   [EVAL] batch:  130 | acc: 62.50%,  total acc: 67.27%   [EVAL] batch:  131 | acc: 62.50%,  total acc: 67.23%   [EVAL] batch:  132 | acc: 87.50%,  total acc: 67.39%   [EVAL] batch:  133 | acc: 56.25%,  total acc: 67.30%   [EVAL] batch:  134 | acc: 68.75%,  total acc: 67.31%   [EVAL] batch:  135 | acc: 87.50%,  total acc: 67.46%   [EVAL] batch:  136 | acc: 68.75%,  total acc: 67.47%   [EVAL] batch:  137 | acc: 43.75%,  total acc: 67.30%   [EVAL] batch:  138 | acc: 25.00%,  total acc: 67.00%   [EVAL] batch:  139 | acc: 31.25%,  total acc: 66.74%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 66.45%   [EVAL] batch:  141 | acc: 43.75%,  total acc: 66.29%   [EVAL] batch:  142 | acc: 37.50%,  total acc: 66.08%   [EVAL] batch:  143 | acc: 31.25%,  total acc: 65.84%   [EVAL] batch:  144 | acc: 93.75%,  total acc: 66.03%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 66.27%   [EVAL] batch:  146 | acc: 100.00%,  total acc: 66.50%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 66.72%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 66.95%   [EVAL] batch:  149 | acc: 93.75%,  total acc: 67.12%   [EVAL] batch:  150 | acc: 6.25%,  total acc: 66.72%   [EVAL] batch:  151 | acc: 0.00%,  total acc: 66.28%   [EVAL] batch:  152 | acc: 12.50%,  total acc: 65.93%   [EVAL] batch:  153 | acc: 0.00%,  total acc: 65.50%   [EVAL] batch:  154 | acc: 0.00%,  total acc: 65.08%   [EVAL] batch:  155 | acc: 0.00%,  total acc: 64.66%   [EVAL] batch:  156 | acc: 62.50%,  total acc: 64.65%   [EVAL] batch:  157 | acc: 87.50%,  total acc: 64.79%   [EVAL] batch:  158 | acc: 75.00%,  total acc: 64.86%   [EVAL] batch:  159 | acc: 87.50%,  total acc: 65.00%   [EVAL] batch:  160 | acc: 93.75%,  total acc: 65.18%   [EVAL] batch:  161 | acc: 81.25%,  total acc: 65.28%   [EVAL] batch:  162 | acc: 50.00%,  total acc: 65.18%   [EVAL] batch:  163 | acc: 6.25%,  total acc: 64.82%   [EVAL] batch:  164 | acc: 6.25%,  total acc: 64.47%   [EVAL] batch:  165 | acc: 0.00%,  total acc: 64.08%   [EVAL] batch:  166 | acc: 0.00%,  total acc: 63.70%   [EVAL] batch:  167 | acc: 18.75%,  total acc: 63.43%   [EVAL] batch:  168 | acc: 18.75%,  total acc: 63.17%   [EVAL] batch:  169 | acc: 25.00%,  total acc: 62.94%   [EVAL] batch:  170 | acc: 68.75%,  total acc: 62.98%   [EVAL] batch:  171 | acc: 31.25%,  total acc: 62.79%   [EVAL] batch:  172 | acc: 37.50%,  total acc: 62.64%   [EVAL] batch:  173 | acc: 50.00%,  total acc: 62.57%   [EVAL] batch:  174 | acc: 43.75%,  total acc: 62.46%   [EVAL] batch:  175 | acc: 68.75%,  total acc: 62.50%   [EVAL] batch:  176 | acc: 81.25%,  total acc: 62.61%   [EVAL] batch:  177 | acc: 62.50%,  total acc: 62.61%   [EVAL] batch:  178 | acc: 81.25%,  total acc: 62.71%   [EVAL] batch:  179 | acc: 75.00%,  total acc: 62.78%   [EVAL] batch:  180 | acc: 81.25%,  total acc: 62.88%   [EVAL] batch:  181 | acc: 56.25%,  total acc: 62.84%   [EVAL] batch:  182 | acc: 87.50%,  total acc: 62.98%   [EVAL] batch:  183 | acc: 87.50%,  total acc: 63.11%   [EVAL] batch:  184 | acc: 81.25%,  total acc: 63.21%   [EVAL] batch:  185 | acc: 93.75%,  total acc: 63.37%   [EVAL] batch:  186 | acc: 75.00%,  total acc: 63.44%   [EVAL] batch:  187 | acc: 93.75%,  total acc: 63.60%   [EVAL] batch:  188 | acc: 93.75%,  total acc: 63.76%   [EVAL] batch:  189 | acc: 100.00%,  total acc: 63.95%   [EVAL] batch:  190 | acc: 100.00%,  total acc: 64.14%   [EVAL] batch:  191 | acc: 87.50%,  total acc: 64.26%   [EVAL] batch:  192 | acc: 100.00%,  total acc: 64.44%   [EVAL] batch:  193 | acc: 81.25%,  total acc: 64.53%   [EVAL] batch:  194 | acc: 25.00%,  total acc: 64.33%   [EVAL] batch:  195 | acc: 31.25%,  total acc: 64.16%   [EVAL] batch:  196 | acc: 56.25%,  total acc: 64.12%   [EVAL] batch:  197 | acc: 43.75%,  total acc: 64.02%   [EVAL] batch:  198 | acc: 25.00%,  total acc: 63.82%   [EVAL] batch:  199 | acc: 43.75%,  total acc: 63.72%   [EVAL] batch:  200 | acc: 62.50%,  total acc: 63.71%   [EVAL] batch:  201 | acc: 75.00%,  total acc: 63.77%   [EVAL] batch:  202 | acc: 62.50%,  total acc: 63.76%   [EVAL] batch:  203 | acc: 50.00%,  total acc: 63.69%   [EVAL] batch:  204 | acc: 56.25%,  total acc: 63.66%   [EVAL] batch:  205 | acc: 50.00%,  total acc: 63.59%   [EVAL] batch:  206 | acc: 37.50%,  total acc: 63.47%   [EVAL] batch:  207 | acc: 12.50%,  total acc: 63.22%   [EVAL] batch:  208 | acc: 6.25%,  total acc: 62.95%   [EVAL] batch:  209 | acc: 12.50%,  total acc: 62.71%   [EVAL] batch:  210 | acc: 18.75%,  total acc: 62.50%   [EVAL] batch:  211 | acc: 6.25%,  total acc: 62.23%   [EVAL] batch:  212 | acc: 56.25%,  total acc: 62.21%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 62.38%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 62.56%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 62.73%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 62.90%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 63.07%   [EVAL] batch:  218 | acc: 100.00%,  total acc: 63.24%   [EVAL] batch:  219 | acc: 68.75%,  total acc: 63.27%   [EVAL] batch:  220 | acc: 81.25%,  total acc: 63.35%   [EVAL] batch:  221 | acc: 75.00%,  total acc: 63.40%   [EVAL] batch:  222 | acc: 62.50%,  total acc: 63.40%   [EVAL] batch:  223 | acc: 81.25%,  total acc: 63.48%   [EVAL] batch:  224 | acc: 43.75%,  total acc: 63.39%   [EVAL] batch:  225 | acc: 100.00%,  total acc: 63.55%   [EVAL] batch:  226 | acc: 100.00%,  total acc: 63.71%   [EVAL] batch:  227 | acc: 100.00%,  total acc: 63.87%   [EVAL] batch:  228 | acc: 100.00%,  total acc: 64.03%   [EVAL] batch:  229 | acc: 100.00%,  total acc: 64.18%   [EVAL] batch:  230 | acc: 93.75%,  total acc: 64.31%   [EVAL] batch:  231 | acc: 100.00%,  total acc: 64.47%   [EVAL] batch:  232 | acc: 100.00%,  total acc: 64.62%   [EVAL] batch:  233 | acc: 100.00%,  total acc: 64.77%   [EVAL] batch:  234 | acc: 100.00%,  total acc: 64.92%   [EVAL] batch:  235 | acc: 100.00%,  total acc: 65.07%   [EVAL] batch:  236 | acc: 100.00%,  total acc: 65.22%   [EVAL] batch:  237 | acc: 100.00%,  total acc: 65.36%   [EVAL] batch:  238 | acc: 100.00%,  total acc: 65.51%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 65.62%   [EVAL] batch:  240 | acc: 100.00%,  total acc: 65.77%   [EVAL] batch:  241 | acc: 100.00%,  total acc: 65.91%   [EVAL] batch:  242 | acc: 100.00%,  total acc: 66.05%   [EVAL] batch:  243 | acc: 93.75%,  total acc: 66.16%   [EVAL] batch:  244 | acc: 100.00%,  total acc: 66.30%   [EVAL] batch:  245 | acc: 87.50%,  total acc: 66.39%   [EVAL] batch:  246 | acc: 93.75%,  total acc: 66.50%   [EVAL] batch:  247 | acc: 100.00%,  total acc: 66.63%   [EVAL] batch:  248 | acc: 93.75%,  total acc: 66.74%   [EVAL] batch:  249 | acc: 93.75%,  total acc: 66.85%   [EVAL] batch:  250 | acc: 68.75%,  total acc: 66.86%   [EVAL] batch:  251 | acc: 81.25%,  total acc: 66.91%   [EVAL] batch:  252 | acc: 75.00%,  total acc: 66.95%   [EVAL] batch:  253 | acc: 62.50%,  total acc: 66.93%   [EVAL] batch:  254 | acc: 68.75%,  total acc: 66.94%   [EVAL] batch:  255 | acc: 87.50%,  total acc: 67.02%   [EVAL] batch:  256 | acc: 56.25%,  total acc: 66.97%   [EVAL] batch:  257 | acc: 75.00%,  total acc: 67.01%   [EVAL] batch:  258 | acc: 62.50%,  total acc: 66.99%   [EVAL] batch:  259 | acc: 62.50%,  total acc: 66.97%   [EVAL] batch:  260 | acc: 50.00%,  total acc: 66.91%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 66.91%   [EVAL] batch:  262 | acc: 93.75%,  total acc: 67.02%   [EVAL] batch:  263 | acc: 75.00%,  total acc: 67.05%   [EVAL] batch:  264 | acc: 68.75%,  total acc: 67.05%   [EVAL] batch:  265 | acc: 62.50%,  total acc: 67.03%   [EVAL] batch:  266 | acc: 75.00%,  total acc: 67.06%   [EVAL] batch:  267 | acc: 87.50%,  total acc: 67.14%   [EVAL] batch:  268 | acc: 93.75%,  total acc: 67.24%   [EVAL] batch:  269 | acc: 93.75%,  total acc: 67.34%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 67.46%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 67.58%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 67.70%   [EVAL] batch:  273 | acc: 93.75%,  total acc: 67.79%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 67.91%   [EVAL] batch:  275 | acc: 43.75%,  total acc: 67.82%   [EVAL] batch:  276 | acc: 31.25%,  total acc: 67.69%   [EVAL] batch:  277 | acc: 68.75%,  total acc: 67.69%   [EVAL] batch:  278 | acc: 68.75%,  total acc: 67.70%   [EVAL] batch:  279 | acc: 37.50%,  total acc: 67.59%   [EVAL] batch:  280 | acc: 43.75%,  total acc: 67.50%   [EVAL] batch:  281 | acc: 43.75%,  total acc: 67.42%   [EVAL] batch:  282 | acc: 6.25%,  total acc: 67.20%   [EVAL] batch:  283 | acc: 6.25%,  total acc: 66.99%   [EVAL] batch:  284 | acc: 25.00%,  total acc: 66.84%   [EVAL] batch:  285 | acc: 6.25%,  total acc: 66.63%   [EVAL] batch:  286 | acc: 6.25%,  total acc: 66.42%   [EVAL] batch:  287 | acc: 12.50%,  total acc: 66.23%   [EVAL] batch:  288 | acc: 12.50%,  total acc: 66.05%   [EVAL] batch:  289 | acc: 6.25%,  total acc: 65.84%   [EVAL] batch:  290 | acc: 12.50%,  total acc: 65.66%   [EVAL] batch:  291 | acc: 12.50%,  total acc: 65.48%   [EVAL] batch:  292 | acc: 6.25%,  total acc: 65.27%   [EVAL] batch:  293 | acc: 37.50%,  total acc: 65.18%   [EVAL] batch:  294 | acc: 75.00%,  total acc: 65.21%   [EVAL] batch:  295 | acc: 62.50%,  total acc: 65.20%   [EVAL] batch:  296 | acc: 68.75%,  total acc: 65.21%   [EVAL] batch:  297 | acc: 62.50%,  total acc: 65.21%   [EVAL] batch:  298 | acc: 68.75%,  total acc: 65.22%   [EVAL] batch:  299 | acc: 81.25%,  total acc: 65.27%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 65.39%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 65.50%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 65.61%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 65.73%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 65.84%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 65.95%   [EVAL] batch:  306 | acc: 93.75%,  total acc: 66.04%   [EVAL] batch:  307 | acc: 87.50%,  total acc: 66.11%   [EVAL] batch:  308 | acc: 87.50%,  total acc: 66.18%   [EVAL] batch:  309 | acc: 93.75%,  total acc: 66.27%   [EVAL] batch:  310 | acc: 87.50%,  total acc: 66.34%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 66.45%   [EVAL] batch:  312 | acc: 75.00%,  total acc: 66.47%   [EVAL] batch:  313 | acc: 56.25%,  total acc: 66.44%   [EVAL] batch:  314 | acc: 50.00%,  total acc: 66.39%   [EVAL] batch:  315 | acc: 37.50%,  total acc: 66.30%   [EVAL] batch:  316 | acc: 31.25%,  total acc: 66.19%   [EVAL] batch:  317 | acc: 37.50%,  total acc: 66.10%   [EVAL] batch:  318 | acc: 37.50%,  total acc: 66.01%   [EVAL] batch:  319 | acc: 93.75%,  total acc: 66.09%   [EVAL] batch:  320 | acc: 93.75%,  total acc: 66.18%   [EVAL] batch:  321 | acc: 93.75%,  total acc: 66.27%   [EVAL] batch:  322 | acc: 100.00%,  total acc: 66.37%   [EVAL] batch:  323 | acc: 93.75%,  total acc: 66.45%   [EVAL] batch:  324 | acc: 87.50%,  total acc: 66.52%   [EVAL] batch:  325 | acc: 56.25%,  total acc: 66.49%   [EVAL] batch:  326 | acc: 18.75%,  total acc: 66.34%   [EVAL] batch:  327 | acc: 37.50%,  total acc: 66.25%   [EVAL] batch:  328 | acc: 50.00%,  total acc: 66.20%   [EVAL] batch:  329 | acc: 56.25%,  total acc: 66.17%   [EVAL] batch:  330 | acc: 56.25%,  total acc: 66.14%   [EVAL] batch:  331 | acc: 93.75%,  total acc: 66.23%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 66.33%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 66.43%   [EVAL] batch:  334 | acc: 93.75%,  total acc: 66.51%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 66.61%   [EVAL] batch:  336 | acc: 100.00%,  total acc: 66.71%   [EVAL] batch:  337 | acc: 87.50%,  total acc: 66.77%   [EVAL] batch:  338 | acc: 87.50%,  total acc: 66.83%   [EVAL] batch:  339 | acc: 93.75%,  total acc: 66.91%   [EVAL] batch:  340 | acc: 100.00%,  total acc: 67.01%   [EVAL] batch:  341 | acc: 81.25%,  total acc: 67.05%   [EVAL] batch:  342 | acc: 100.00%,  total acc: 67.15%   [EVAL] batch:  343 | acc: 93.75%,  total acc: 67.22%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 67.32%   [EVAL] batch:  345 | acc: 100.00%,  total acc: 67.41%   [EVAL] batch:  346 | acc: 87.50%,  total acc: 67.47%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 67.55%   [EVAL] batch:  348 | acc: 93.75%,  total acc: 67.62%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 67.71%   [EVAL] batch:  350 | acc: 75.00%,  total acc: 67.74%   [EVAL] batch:  351 | acc: 87.50%,  total acc: 67.79%   [EVAL] batch:  352 | acc: 75.00%,  total acc: 67.81%   [EVAL] batch:  353 | acc: 100.00%,  total acc: 67.90%   [EVAL] batch:  354 | acc: 43.75%,  total acc: 67.83%   [EVAL] batch:  355 | acc: 68.75%,  total acc: 67.84%   [EVAL] batch:  356 | acc: 100.00%,  total acc: 67.93%   [EVAL] batch:  357 | acc: 93.75%,  total acc: 68.00%   [EVAL] batch:  358 | acc: 93.75%,  total acc: 68.07%   [EVAL] batch:  359 | acc: 100.00%,  total acc: 68.16%   [EVAL] batch:  360 | acc: 93.75%,  total acc: 68.23%   [EVAL] batch:  361 | acc: 93.75%,  total acc: 68.30%   [EVAL] batch:  362 | acc: 87.50%,  total acc: 68.35%   [EVAL] batch:  363 | acc: 68.75%,  total acc: 68.36%   [EVAL] batch:  364 | acc: 43.75%,  total acc: 68.29%   [EVAL] batch:  365 | acc: 43.75%,  total acc: 68.22%   [EVAL] batch:  366 | acc: 62.50%,  total acc: 68.21%   [EVAL] batch:  367 | acc: 43.75%,  total acc: 68.14%   [EVAL] batch:  368 | acc: 31.25%,  total acc: 68.04%   [EVAL] batch:  369 | acc: 31.25%,  total acc: 67.94%   [EVAL] batch:  370 | acc: 68.75%,  total acc: 67.94%   [EVAL] batch:  371 | acc: 37.50%,  total acc: 67.86%   [EVAL] batch:  372 | acc: 75.00%,  total acc: 67.88%   [EVAL] batch:  373 | acc: 75.00%,  total acc: 67.90%   [EVAL] batch:  374 | acc: 56.25%,  total acc: 67.87%   [EVAL] batch:  375 | acc: 43.75%,  total acc: 67.80%   [EVAL] batch:  376 | acc: 37.50%,  total acc: 67.72%   [EVAL] batch:  377 | acc: 37.50%,  total acc: 67.64%   [EVAL] batch:  378 | acc: 62.50%,  total acc: 67.63%   [EVAL] batch:  379 | acc: 31.25%,  total acc: 67.53%   [EVAL] batch:  380 | acc: 50.00%,  total acc: 67.49%   [EVAL] batch:  381 | acc: 75.00%,  total acc: 67.51%   [EVAL] batch:  382 | acc: 93.75%,  total acc: 67.58%   [EVAL] batch:  383 | acc: 93.75%,  total acc: 67.64%   [EVAL] batch:  384 | acc: 87.50%,  total acc: 67.69%   [EVAL] batch:  385 | acc: 75.00%,  total acc: 67.71%   [EVAL] batch:  386 | acc: 87.50%,  total acc: 67.76%   [EVAL] batch:  387 | acc: 87.50%,  total acc: 67.82%   [EVAL] batch:  388 | acc: 87.50%,  total acc: 67.87%   [EVAL] batch:  389 | acc: 87.50%,  total acc: 67.92%   [EVAL] batch:  390 | acc: 93.75%,  total acc: 67.98%   [EVAL] batch:  391 | acc: 87.50%,  total acc: 68.03%   [EVAL] batch:  392 | acc: 100.00%,  total acc: 68.11%   [EVAL] batch:  393 | acc: 68.75%,  total acc: 68.12%   [EVAL] batch:  394 | acc: 50.00%,  total acc: 68.07%   [EVAL] batch:  395 | acc: 37.50%,  total acc: 67.99%   [EVAL] batch:  396 | acc: 56.25%,  total acc: 67.96%   [EVAL] batch:  397 | acc: 62.50%,  total acc: 67.95%   [EVAL] batch:  398 | acc: 37.50%,  total acc: 67.87%   [EVAL] batch:  399 | acc: 31.25%,  total acc: 67.78%   [EVAL] batch:  400 | acc: 6.25%,  total acc: 67.63%   [EVAL] batch:  401 | acc: 6.25%,  total acc: 67.48%   [EVAL] batch:  402 | acc: 0.00%,  total acc: 67.31%   [EVAL] batch:  403 | acc: 0.00%,  total acc: 67.14%   [EVAL] batch:  404 | acc: 6.25%,  total acc: 66.99%   [EVAL] batch:  405 | acc: 6.25%,  total acc: 66.84%   [EVAL] batch:  406 | acc: 62.50%,  total acc: 66.83%   [EVAL] batch:  407 | acc: 93.75%,  total acc: 66.90%   [EVAL] batch:  408 | acc: 81.25%,  total acc: 66.93%   [EVAL] batch:  409 | acc: 93.75%,  total acc: 67.00%   [EVAL] batch:  410 | acc: 87.50%,  total acc: 67.05%   [EVAL] batch:  411 | acc: 81.25%,  total acc: 67.08%   [EVAL] batch:  412 | acc: 93.75%,  total acc: 67.15%   [EVAL] batch:  413 | acc: 87.50%,  total acc: 67.20%   [EVAL] batch:  414 | acc: 100.00%,  total acc: 67.27%   [EVAL] batch:  415 | acc: 93.75%,  total acc: 67.34%   [EVAL] batch:  416 | acc: 93.75%,  total acc: 67.40%   [EVAL] batch:  417 | acc: 100.00%,  total acc: 67.48%   [EVAL] batch:  418 | acc: 100.00%,  total acc: 67.56%   [EVAL] batch:  419 | acc: 87.50%,  total acc: 67.60%   [EVAL] batch:  420 | acc: 87.50%,  total acc: 67.65%   [EVAL] batch:  421 | acc: 81.25%,  total acc: 67.68%   [EVAL] batch:  422 | acc: 87.50%,  total acc: 67.73%   [EVAL] batch:  423 | acc: 93.75%,  total acc: 67.79%   [EVAL] batch:  424 | acc: 81.25%,  total acc: 67.82%   [EVAL] batch:  425 | acc: 56.25%,  total acc: 67.80%   [EVAL] batch:  426 | acc: 81.25%,  total acc: 67.83%   [EVAL] batch:  427 | acc: 75.00%,  total acc: 67.84%   [EVAL] batch:  428 | acc: 87.50%,  total acc: 67.89%   [EVAL] batch:  429 | acc: 75.00%,  total acc: 67.91%   [EVAL] batch:  430 | acc: 75.00%,  total acc: 67.92%   [EVAL] batch:  431 | acc: 50.00%,  total acc: 67.88%   [EVAL] batch:  432 | acc: 62.50%,  total acc: 67.87%   [EVAL] batch:  433 | acc: 56.25%,  total acc: 67.84%   [EVAL] batch:  434 | acc: 81.25%,  total acc: 67.87%   [EVAL] batch:  435 | acc: 50.00%,  total acc: 67.83%   [EVAL] batch:  436 | acc: 81.25%,  total acc: 67.86%   [EVAL] batch:  437 | acc: 31.25%,  total acc: 67.78%   
cur_acc:  ['0.9464', '0.7262', '0.7609', '0.8423', '0.8304', '0.7609', '0.6726']
his_acc:  ['0.9464', '0.8255', '0.7912', '0.7895', '0.7794', '0.7283', '0.6778']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0]
Losses:  6.996269226074219 1.2366480827331543
CurrentTrain: epoch  0, batch     0 | loss: 8.2329178Losses:  9.150386810302734 1.0820564031600952
CurrentTrain: epoch  0, batch     1 | loss: 10.2324429Losses:  10.456336975097656 1.0776417255401611
CurrentTrain: epoch  0, batch     2 | loss: 11.5339785Losses:  10.16824722290039 0.9726148247718811
CurrentTrain: epoch  0, batch     3 | loss: 11.1408625Losses:  10.199291229248047 1.1543850898742676
CurrentTrain: epoch  0, batch     4 | loss: 11.3536758Losses:  8.974446296691895 1.1603498458862305
CurrentTrain: epoch  0, batch     5 | loss: 10.1347961Losses:  9.937692642211914 0.8216125965118408
CurrentTrain: epoch  0, batch     6 | loss: 10.7593050Losses:  9.6067533493042 0.877595067024231
CurrentTrain: epoch  0, batch     7 | loss: 10.4843483Losses:  2.2715694904327393 1.1140905618667603
CurrentTrain: epoch  1, batch     0 | loss: 3.3856602Losses:  2.063567638397217 0.8716191053390503
CurrentTrain: epoch  1, batch     1 | loss: 2.9351869Losses:  3.072457790374756 0.9282471537590027
CurrentTrain: epoch  1, batch     2 | loss: 4.0007048Losses:  2.252187728881836 0.7846835255622864
CurrentTrain: epoch  1, batch     3 | loss: 3.0368712Losses:  3.0717012882232666 1.0992836952209473
CurrentTrain: epoch  1, batch     4 | loss: 4.1709852Losses:  1.982801914215088 1.0432124137878418
CurrentTrain: epoch  1, batch     5 | loss: 3.0260143Losses:  2.8506851196289062 1.141608476638794
CurrentTrain: epoch  1, batch     6 | loss: 3.9922936Losses:  1.790938377380371 0.7904460430145264
CurrentTrain: epoch  1, batch     7 | loss: 2.5813844Losses:  2.367499589920044 0.9517600536346436
CurrentTrain: epoch  2, batch     0 | loss: 3.3192596Losses:  1.656968355178833 0.9377166032791138
CurrentTrain: epoch  2, batch     1 | loss: 2.5946851Losses:  1.7016249895095825 0.9716359972953796
CurrentTrain: epoch  2, batch     2 | loss: 2.6732609Losses:  1.9422866106033325 0.8907523155212402
CurrentTrain: epoch  2, batch     3 | loss: 2.8330388Losses:  1.9062352180480957 1.0520778894424438
CurrentTrain: epoch  2, batch     4 | loss: 2.9583130Losses:  2.9084954261779785 0.9950860738754272
CurrentTrain: epoch  2, batch     5 | loss: 3.9035816Losses:  2.4276018142700195 0.8870408535003662
CurrentTrain: epoch  2, batch     6 | loss: 3.3146427Losses:  3.2602105140686035 0.6006892919540405
CurrentTrain: epoch  2, batch     7 | loss: 3.8608999Losses:  2.436683177947998 1.0044864416122437
CurrentTrain: epoch  3, batch     0 | loss: 3.4411697Losses:  1.4638261795043945 0.9294142127037048
CurrentTrain: epoch  3, batch     1 | loss: 2.3932405Losses:  1.8188807964324951 0.7587635517120361
CurrentTrain: epoch  3, batch     2 | loss: 2.5776443Losses:  2.086513042449951 0.8547688126564026
CurrentTrain: epoch  3, batch     3 | loss: 2.9412818Losses:  1.9936785697937012 1.032918930053711
CurrentTrain: epoch  3, batch     4 | loss: 3.0265975Losses:  2.1986119747161865 0.8824529647827148
CurrentTrain: epoch  3, batch     5 | loss: 3.0810649Losses:  2.2652523517608643 1.1525964736938477
CurrentTrain: epoch  3, batch     6 | loss: 3.4178488Losses:  2.810026168823242 0.5929383039474487
CurrentTrain: epoch  3, batch     7 | loss: 3.4029646Losses:  2.215426445007324 0.7292234301567078
CurrentTrain: epoch  4, batch     0 | loss: 2.9446499Losses:  2.8063790798187256 1.0124436616897583
CurrentTrain: epoch  4, batch     1 | loss: 3.8188229Losses:  1.9802017211914062 0.9221075773239136
CurrentTrain: epoch  4, batch     2 | loss: 2.9023094Losses:  1.6557917594909668 0.7470875978469849
CurrentTrain: epoch  4, batch     3 | loss: 2.4028792Losses:  2.003711223602295 0.795601487159729
CurrentTrain: epoch  4, batch     4 | loss: 2.7993126Losses:  1.5699474811553955 0.7198125720024109
CurrentTrain: epoch  4, batch     5 | loss: 2.2897601Losses:  1.8944969177246094 0.9995088577270508
CurrentTrain: epoch  4, batch     6 | loss: 2.8940058Losses:  1.437403917312622 0.3400214910507202
CurrentTrain: epoch  4, batch     7 | loss: 1.7774254Losses:  1.8312182426452637 0.7583504319190979
CurrentTrain: epoch  5, batch     0 | loss: 2.5895686Losses:  3.052762985229492 0.9716105461120605
CurrentTrain: epoch  5, batch     1 | loss: 4.0243735Losses:  1.3335111141204834 0.8059147596359253
CurrentTrain: epoch  5, batch     2 | loss: 2.1394258Losses:  1.4112986326217651 0.9481955766677856
CurrentTrain: epoch  5, batch     3 | loss: 2.3594942Losses:  2.452986717224121 0.7765876054763794
CurrentTrain: epoch  5, batch     4 | loss: 3.2295742Losses:  2.0555598735809326 0.8141196966171265
CurrentTrain: epoch  5, batch     5 | loss: 2.8696795Losses:  1.4100580215454102 0.666399359703064
CurrentTrain: epoch  5, batch     6 | loss: 2.0764575Losses:  0.9241646528244019 0.532402515411377
CurrentTrain: epoch  5, batch     7 | loss: 1.4565672Losses:  1.653375267982483 0.6363164782524109
CurrentTrain: epoch  6, batch     0 | loss: 2.2896917Losses:  1.4682694673538208 0.6592203378677368
CurrentTrain: epoch  6, batch     1 | loss: 2.1274898Losses:  1.644784688949585 0.7636340856552124
CurrentTrain: epoch  6, batch     2 | loss: 2.4084187Losses:  1.774903416633606 0.6970484852790833
CurrentTrain: epoch  6, batch     3 | loss: 2.4719520Losses:  2.040900230407715 0.7751944065093994
CurrentTrain: epoch  6, batch     4 | loss: 2.8160946Losses:  2.0722556114196777 0.7265575528144836
CurrentTrain: epoch  6, batch     5 | loss: 2.7988131Losses:  1.962207317352295 0.8811153173446655
CurrentTrain: epoch  6, batch     6 | loss: 2.8433228Losses:  0.949704110622406 0.4527992010116577
CurrentTrain: epoch  6, batch     7 | loss: 1.4025033Losses:  1.409191608428955 0.657567024230957
CurrentTrain: epoch  7, batch     0 | loss: 2.0667586Losses:  1.7262499332427979 0.8327862024307251
CurrentTrain: epoch  7, batch     1 | loss: 2.5590363Losses:  1.3127760887145996 0.7500802278518677
CurrentTrain: epoch  7, batch     2 | loss: 2.0628562Losses:  1.7363085746765137 0.8316631317138672
CurrentTrain: epoch  7, batch     3 | loss: 2.5679717Losses:  2.424488067626953 0.7994892597198486
CurrentTrain: epoch  7, batch     4 | loss: 3.2239773Losses:  1.7962324619293213 0.6879725456237793
CurrentTrain: epoch  7, batch     5 | loss: 2.4842050Losses:  1.3156158924102783 0.704246997833252
CurrentTrain: epoch  7, batch     6 | loss: 2.0198629Losses:  1.7307435274124146 0.31907689571380615
CurrentTrain: epoch  7, batch     7 | loss: 2.0498204Losses:  1.6300513744354248 0.7775278687477112
CurrentTrain: epoch  8, batch     0 | loss: 2.4075792Losses:  1.1042362451553345 0.7514589428901672
CurrentTrain: epoch  8, batch     1 | loss: 1.8556952Losses:  1.7898709774017334 0.6235635280609131
CurrentTrain: epoch  8, batch     2 | loss: 2.4134345Losses:  1.8780720233917236 0.7362141609191895
CurrentTrain: epoch  8, batch     3 | loss: 2.6142862Losses:  1.0272703170776367 0.5754271745681763
CurrentTrain: epoch  8, batch     4 | loss: 1.6026975Losses:  1.5338726043701172 0.728722333908081
CurrentTrain: epoch  8, batch     5 | loss: 2.2625949Losses:  1.939756989479065 0.8769029378890991
CurrentTrain: epoch  8, batch     6 | loss: 2.8166599Losses:  2.1432178020477295 0.2517063617706299
CurrentTrain: epoch  8, batch     7 | loss: 2.3949242Losses:  0.9739458560943604 0.6630871891975403
CurrentTrain: epoch  9, batch     0 | loss: 1.6370330Losses:  1.4291698932647705 0.5300918817520142
CurrentTrain: epoch  9, batch     1 | loss: 1.9592618Losses:  1.302236557006836 0.5064292550086975
CurrentTrain: epoch  9, batch     2 | loss: 1.8086658Losses:  1.8366174697875977 0.5564689636230469
CurrentTrain: epoch  9, batch     3 | loss: 2.3930864Losses:  1.6085788011550903 0.6565560102462769
CurrentTrain: epoch  9, batch     4 | loss: 2.2651348Losses:  1.875586986541748 0.8474647402763367
CurrentTrain: epoch  9, batch     5 | loss: 2.7230518Losses:  1.6612135171890259 0.650633692741394
CurrentTrain: epoch  9, batch     6 | loss: 2.3118472Losses:  1.4091330766677856 0.2752993106842041
CurrentTrain: epoch  9, batch     7 | loss: 1.6844324
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 81.25%,  total acc: 86.25%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 86.46%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 83.93%   [EVAL] batch:    7 | acc: 75.00%,  total acc: 82.81%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 80.56%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 79.38%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 78.98%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 78.12%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 79.81%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 80.80%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 81.67%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 82.42%   [EVAL] batch:   16 | acc: 87.50%,  total acc: 82.72%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 83.33%   [EVAL] batch:   18 | acc: 81.25%,  total acc: 83.22%   [EVAL] batch:   19 | acc: 31.25%,  total acc: 80.62%   [EVAL] batch:   20 | acc: 50.00%,  total acc: 79.17%   [EVAL] batch:   21 | acc: 43.75%,  total acc: 77.56%   [EVAL] batch:   22 | acc: 56.25%,  total acc: 76.63%   [EVAL] batch:   23 | acc: 31.25%,  total acc: 74.74%   [EVAL] batch:   24 | acc: 25.00%,  total acc: 72.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 73.80%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 74.77%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 75.67%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 76.51%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 77.29%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 78.02%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 78.71%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 79.36%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 79.96%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 80.54%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 81.08%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 81.59%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 82.07%   [EVAL] batch:   38 | acc: 93.75%,  total acc: 82.37%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 82.66%   [EVAL] batch:   40 | acc: 81.25%,  total acc: 82.62%   [EVAL] batch:   41 | acc: 93.75%,  total acc: 82.89%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 83.14%   [EVAL] batch:   43 | acc: 68.75%,  total acc: 82.81%   [EVAL] batch:   44 | acc: 18.75%,  total acc: 81.39%   [EVAL] batch:   45 | acc: 12.50%,  total acc: 79.89%   [EVAL] batch:   46 | acc: 25.00%,  total acc: 78.72%   [EVAL] batch:   47 | acc: 56.25%,  total acc: 78.26%   [EVAL] batch:   48 | acc: 43.75%,  total acc: 77.55%   [EVAL] batch:   49 | acc: 31.25%,  total acc: 76.62%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 76.96%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 77.28%   [EVAL] batch:   52 | acc: 87.50%,  total acc: 77.48%   [EVAL] batch:   53 | acc: 81.25%,  total acc: 77.55%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 77.84%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 78.12%   [EVAL] batch:   56 | acc: 68.75%,  total acc: 77.96%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 77.91%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 78.07%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 77.71%   [EVAL] batch:   60 | acc: 68.75%,  total acc: 77.56%   [EVAL] batch:   61 | acc: 56.25%,  total acc: 77.22%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 76.79%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    6 | acc: 31.25%,  total acc: 76.79%   [EVAL] batch:    7 | acc: 43.75%,  total acc: 72.66%   [EVAL] batch:    8 | acc: 31.25%,  total acc: 68.06%   [EVAL] batch:    9 | acc: 25.00%,  total acc: 63.75%   [EVAL] batch:   10 | acc: 25.00%,  total acc: 60.23%   [EVAL] batch:   11 | acc: 18.75%,  total acc: 56.77%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 56.25%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 58.93%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 61.25%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 63.67%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 65.44%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 67.01%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 68.75%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 69.38%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 70.24%   [EVAL] batch:   21 | acc: 62.50%,  total acc: 69.89%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 70.38%   [EVAL] batch:   23 | acc: 75.00%,  total acc: 70.57%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 71.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 72.36%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 73.38%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 74.33%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 75.00%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 75.83%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 76.61%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 77.34%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 78.03%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 78.49%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 78.57%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 78.99%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 79.56%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 80.10%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 80.61%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 81.09%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 81.55%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 81.70%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 81.98%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 82.10%   [EVAL] batch:   44 | acc: 87.50%,  total acc: 82.22%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 82.20%   [EVAL] batch:   46 | acc: 68.75%,  total acc: 81.91%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 81.90%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 82.27%   [EVAL] batch:   49 | acc: 75.00%,  total acc: 82.12%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 82.23%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 82.45%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 82.67%   [EVAL] batch:   53 | acc: 81.25%,  total acc: 82.64%   [EVAL] batch:   54 | acc: 68.75%,  total acc: 82.39%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 82.48%   [EVAL] batch:   56 | acc: 50.00%,  total acc: 81.91%   [EVAL] batch:   57 | acc: 31.25%,  total acc: 81.03%   [EVAL] batch:   58 | acc: 37.50%,  total acc: 80.30%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 79.79%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 79.20%   [EVAL] batch:   61 | acc: 50.00%,  total acc: 78.73%   [EVAL] batch:   62 | acc: 25.00%,  total acc: 77.88%   [EVAL] batch:   63 | acc: 6.25%,  total acc: 76.76%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 75.58%   [EVAL] batch:   65 | acc: 0.00%,  total acc: 74.43%   [EVAL] batch:   66 | acc: 0.00%,  total acc: 73.32%   [EVAL] batch:   67 | acc: 25.00%,  total acc: 72.61%   [EVAL] batch:   68 | acc: 31.25%,  total acc: 72.01%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 72.41%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 72.80%   [EVAL] batch:   71 | acc: 75.00%,  total acc: 72.83%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 73.20%   [EVAL] batch:   73 | acc: 87.50%,  total acc: 73.40%   [EVAL] batch:   74 | acc: 93.75%,  total acc: 73.67%   [EVAL] batch:   75 | acc: 75.00%,  total acc: 73.68%   [EVAL] batch:   76 | acc: 50.00%,  total acc: 73.38%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 73.40%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 73.42%   [EVAL] batch:   79 | acc: 93.75%,  total acc: 73.67%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 73.69%   [EVAL] batch:   81 | acc: 62.50%,  total acc: 73.55%   [EVAL] batch:   82 | acc: 43.75%,  total acc: 73.19%   [EVAL] batch:   83 | acc: 18.75%,  total acc: 72.54%   [EVAL] batch:   84 | acc: 37.50%,  total acc: 72.13%   [EVAL] batch:   85 | acc: 43.75%,  total acc: 71.80%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 71.34%   [EVAL] batch:   87 | acc: 56.25%,  total acc: 71.16%   [EVAL] batch:   88 | acc: 31.25%,  total acc: 70.72%   [EVAL] batch:   89 | acc: 25.00%,  total acc: 70.21%   [EVAL] batch:   90 | acc: 31.25%,  total acc: 69.78%   [EVAL] batch:   91 | acc: 31.25%,  total acc: 69.36%   [EVAL] batch:   92 | acc: 62.50%,  total acc: 69.29%   [EVAL] batch:   93 | acc: 50.00%,  total acc: 69.08%   [EVAL] batch:   94 | acc: 50.00%,  total acc: 68.88%   [EVAL] batch:   95 | acc: 37.50%,  total acc: 68.55%   [EVAL] batch:   96 | acc: 50.00%,  total acc: 68.36%   [EVAL] batch:   97 | acc: 43.75%,  total acc: 68.11%   [EVAL] batch:   98 | acc: 62.50%,  total acc: 68.06%   [EVAL] batch:   99 | acc: 37.50%,  total acc: 67.75%   [EVAL] batch:  100 | acc: 56.25%,  total acc: 67.64%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 67.59%   [EVAL] batch:  102 | acc: 56.25%,  total acc: 67.48%   [EVAL] batch:  103 | acc: 62.50%,  total acc: 67.43%   [EVAL] batch:  104 | acc: 68.75%,  total acc: 67.44%   [EVAL] batch:  105 | acc: 62.50%,  total acc: 67.39%   [EVAL] batch:  106 | acc: 37.50%,  total acc: 67.11%   [EVAL] batch:  107 | acc: 6.25%,  total acc: 66.55%   [EVAL] batch:  108 | acc: 12.50%,  total acc: 66.06%   [EVAL] batch:  109 | acc: 0.00%,  total acc: 65.45%   [EVAL] batch:  110 | acc: 6.25%,  total acc: 64.92%   [EVAL] batch:  111 | acc: 18.75%,  total acc: 64.51%   [EVAL] batch:  112 | acc: 50.00%,  total acc: 64.38%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 64.69%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 65.00%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 65.30%   [EVAL] batch:  116 | acc: 100.00%,  total acc: 65.60%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 65.89%   [EVAL] batch:  118 | acc: 87.50%,  total acc: 66.07%   [EVAL] batch:  119 | acc: 75.00%,  total acc: 66.15%   [EVAL] batch:  120 | acc: 62.50%,  total acc: 66.12%   [EVAL] batch:  121 | acc: 75.00%,  total acc: 66.19%   [EVAL] batch:  122 | acc: 81.25%,  total acc: 66.31%   [EVAL] batch:  123 | acc: 68.75%,  total acc: 66.33%   [EVAL] batch:  124 | acc: 81.25%,  total acc: 66.45%   [EVAL] batch:  125 | acc: 62.50%,  total acc: 66.42%   [EVAL] batch:  126 | acc: 37.50%,  total acc: 66.19%   [EVAL] batch:  127 | acc: 56.25%,  total acc: 66.11%   [EVAL] batch:  128 | acc: 62.50%,  total acc: 66.09%   [EVAL] batch:  129 | acc: 62.50%,  total acc: 66.06%   [EVAL] batch:  130 | acc: 62.50%,  total acc: 66.03%   [EVAL] batch:  131 | acc: 56.25%,  total acc: 65.96%   [EVAL] batch:  132 | acc: 75.00%,  total acc: 66.02%   [EVAL] batch:  133 | acc: 50.00%,  total acc: 65.90%   [EVAL] batch:  134 | acc: 56.25%,  total acc: 65.83%   [EVAL] batch:  135 | acc: 62.50%,  total acc: 65.81%   [EVAL] batch:  136 | acc: 56.25%,  total acc: 65.74%   [EVAL] batch:  137 | acc: 43.75%,  total acc: 65.58%   [EVAL] batch:  138 | acc: 12.50%,  total acc: 65.20%   [EVAL] batch:  139 | acc: 25.00%,  total acc: 64.91%   [EVAL] batch:  140 | acc: 25.00%,  total acc: 64.63%   [EVAL] batch:  141 | acc: 25.00%,  total acc: 64.35%   [EVAL] batch:  142 | acc: 31.25%,  total acc: 64.12%   [EVAL] batch:  143 | acc: 31.25%,  total acc: 63.89%   [EVAL] batch:  144 | acc: 93.75%,  total acc: 64.09%   [EVAL] batch:  145 | acc: 100.00%,  total acc: 64.34%   [EVAL] batch:  146 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:  147 | acc: 100.00%,  total acc: 64.82%   [EVAL] batch:  148 | acc: 100.00%,  total acc: 65.06%   [EVAL] batch:  149 | acc: 93.75%,  total acc: 65.25%   [EVAL] batch:  150 | acc: 6.25%,  total acc: 64.86%   [EVAL] batch:  151 | acc: 0.00%,  total acc: 64.43%   [EVAL] batch:  152 | acc: 0.00%,  total acc: 64.01%   [EVAL] batch:  153 | acc: 0.00%,  total acc: 63.60%   [EVAL] batch:  154 | acc: 0.00%,  total acc: 63.19%   [EVAL] batch:  155 | acc: 0.00%,  total acc: 62.78%   [EVAL] batch:  156 | acc: 62.50%,  total acc: 62.78%   [EVAL] batch:  157 | acc: 81.25%,  total acc: 62.90%   [EVAL] batch:  158 | acc: 68.75%,  total acc: 62.93%   [EVAL] batch:  159 | acc: 93.75%,  total acc: 63.12%   [EVAL] batch:  160 | acc: 93.75%,  total acc: 63.32%   [EVAL] batch:  161 | acc: 81.25%,  total acc: 63.43%   [EVAL] batch:  162 | acc: 50.00%,  total acc: 63.34%   [EVAL] batch:  163 | acc: 6.25%,  total acc: 63.00%   [EVAL] batch:  164 | acc: 6.25%,  total acc: 62.65%   [EVAL] batch:  165 | acc: 0.00%,  total acc: 62.27%   [EVAL] batch:  166 | acc: 0.00%,  total acc: 61.90%   [EVAL] batch:  167 | acc: 12.50%,  total acc: 61.61%   [EVAL] batch:  168 | acc: 25.00%,  total acc: 61.39%   [EVAL] batch:  169 | acc: 50.00%,  total acc: 61.32%   [EVAL] batch:  170 | acc: 68.75%,  total acc: 61.37%   [EVAL] batch:  171 | acc: 50.00%,  total acc: 61.30%   [EVAL] batch:  172 | acc: 43.75%,  total acc: 61.20%   [EVAL] batch:  173 | acc: 56.25%,  total acc: 61.17%   [EVAL] batch:  174 | acc: 62.50%,  total acc: 61.18%   [EVAL] batch:  175 | acc: 37.50%,  total acc: 61.04%   [EVAL] batch:  176 | acc: 43.75%,  total acc: 60.95%   [EVAL] batch:  177 | acc: 50.00%,  total acc: 60.88%   [EVAL] batch:  178 | acc: 50.00%,  total acc: 60.82%   [EVAL] batch:  179 | acc: 37.50%,  total acc: 60.69%   [EVAL] batch:  180 | acc: 68.75%,  total acc: 60.74%   [EVAL] batch:  181 | acc: 62.50%,  total acc: 60.75%   [EVAL] batch:  182 | acc: 87.50%,  total acc: 60.89%   [EVAL] batch:  183 | acc: 93.75%,  total acc: 61.07%   [EVAL] batch:  184 | acc: 87.50%,  total acc: 61.22%   [EVAL] batch:  185 | acc: 100.00%,  total acc: 61.42%   [EVAL] batch:  186 | acc: 75.00%,  total acc: 61.50%   [EVAL] batch:  187 | acc: 100.00%,  total acc: 61.70%   [EVAL] batch:  188 | acc: 93.75%,  total acc: 61.87%   [EVAL] batch:  189 | acc: 100.00%,  total acc: 62.07%   [EVAL] batch:  190 | acc: 100.00%,  total acc: 62.27%   [EVAL] batch:  191 | acc: 87.50%,  total acc: 62.40%   [EVAL] batch:  192 | acc: 100.00%,  total acc: 62.60%   [EVAL] batch:  193 | acc: 81.25%,  total acc: 62.69%   [EVAL] batch:  194 | acc: 6.25%,  total acc: 62.40%   [EVAL] batch:  195 | acc: 18.75%,  total acc: 62.18%   [EVAL] batch:  196 | acc: 50.00%,  total acc: 62.12%   [EVAL] batch:  197 | acc: 37.50%,  total acc: 61.99%   [EVAL] batch:  198 | acc: 18.75%,  total acc: 61.78%   [EVAL] batch:  199 | acc: 37.50%,  total acc: 61.66%   [EVAL] batch:  200 | acc: 56.25%,  total acc: 61.63%   [EVAL] batch:  201 | acc: 75.00%,  total acc: 61.70%   [EVAL] batch:  202 | acc: 62.50%,  total acc: 61.70%   [EVAL] batch:  203 | acc: 43.75%,  total acc: 61.61%   [EVAL] batch:  204 | acc: 43.75%,  total acc: 61.52%   [EVAL] batch:  205 | acc: 43.75%,  total acc: 61.44%   [EVAL] batch:  206 | acc: 50.00%,  total acc: 61.38%   [EVAL] batch:  207 | acc: 25.00%,  total acc: 61.21%   [EVAL] batch:  208 | acc: 18.75%,  total acc: 61.00%   [EVAL] batch:  209 | acc: 37.50%,  total acc: 60.89%   [EVAL] batch:  210 | acc: 25.00%,  total acc: 60.72%   [EVAL] batch:  211 | acc: 18.75%,  total acc: 60.52%   [EVAL] batch:  212 | acc: 56.25%,  total acc: 60.50%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 60.69%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 60.87%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 61.05%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 61.23%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 61.41%   [EVAL] batch:  218 | acc: 100.00%,  total acc: 61.59%   [EVAL] batch:  219 | acc: 68.75%,  total acc: 61.62%   [EVAL] batch:  220 | acc: 81.25%,  total acc: 61.71%   [EVAL] batch:  221 | acc: 87.50%,  total acc: 61.82%   [EVAL] batch:  222 | acc: 62.50%,  total acc: 61.83%   [EVAL] batch:  223 | acc: 75.00%,  total acc: 61.89%   [EVAL] batch:  224 | acc: 56.25%,  total acc: 61.86%   [EVAL] batch:  225 | acc: 100.00%,  total acc: 62.03%   [EVAL] batch:  226 | acc: 100.00%,  total acc: 62.20%   [EVAL] batch:  227 | acc: 100.00%,  total acc: 62.36%   [EVAL] batch:  228 | acc: 100.00%,  total acc: 62.53%   [EVAL] batch:  229 | acc: 100.00%,  total acc: 62.69%   [EVAL] batch:  230 | acc: 93.75%,  total acc: 62.82%   [EVAL] batch:  231 | acc: 100.00%,  total acc: 62.98%   [EVAL] batch:  232 | acc: 100.00%,  total acc: 63.14%   [EVAL] batch:  233 | acc: 100.00%,  total acc: 63.30%   [EVAL] batch:  234 | acc: 100.00%,  total acc: 63.46%   [EVAL] batch:  235 | acc: 100.00%,  total acc: 63.61%   [EVAL] batch:  236 | acc: 100.00%,  total acc: 63.77%   [EVAL] batch:  237 | acc: 75.00%,  total acc: 63.81%   [EVAL] batch:  238 | acc: 62.50%,  total acc: 63.81%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 63.93%   [EVAL] batch:  240 | acc: 93.75%,  total acc: 64.06%   [EVAL] batch:  241 | acc: 68.75%,  total acc: 64.08%   [EVAL] batch:  242 | acc: 93.75%,  total acc: 64.20%   [EVAL] batch:  243 | acc: 87.50%,  total acc: 64.29%   [EVAL] batch:  244 | acc: 100.00%,  total acc: 64.44%   [EVAL] batch:  245 | acc: 87.50%,  total acc: 64.53%   [EVAL] batch:  246 | acc: 100.00%,  total acc: 64.68%   [EVAL] batch:  247 | acc: 100.00%,  total acc: 64.82%   [EVAL] batch:  248 | acc: 93.75%,  total acc: 64.93%   [EVAL] batch:  249 | acc: 93.75%,  total acc: 65.05%   [EVAL] batch:  250 | acc: 62.50%,  total acc: 65.04%   [EVAL] batch:  251 | acc: 81.25%,  total acc: 65.10%   [EVAL] batch:  252 | acc: 75.00%,  total acc: 65.14%   [EVAL] batch:  253 | acc: 68.75%,  total acc: 65.16%   [EVAL] batch:  254 | acc: 68.75%,  total acc: 65.17%   [EVAL] batch:  255 | acc: 87.50%,  total acc: 65.26%   [EVAL] batch:  256 | acc: 43.75%,  total acc: 65.18%   [EVAL] batch:  257 | acc: 68.75%,  total acc: 65.19%   [EVAL] batch:  258 | acc: 62.50%,  total acc: 65.18%   [EVAL] batch:  259 | acc: 68.75%,  total acc: 65.19%   [EVAL] batch:  260 | acc: 56.25%,  total acc: 65.16%   [EVAL] batch:  261 | acc: 62.50%,  total acc: 65.15%   [EVAL] batch:  262 | acc: 93.75%,  total acc: 65.26%   [EVAL] batch:  263 | acc: 62.50%,  total acc: 65.25%   [EVAL] batch:  264 | acc: 62.50%,  total acc: 65.24%   [EVAL] batch:  265 | acc: 68.75%,  total acc: 65.25%   [EVAL] batch:  266 | acc: 75.00%,  total acc: 65.29%   [EVAL] batch:  267 | acc: 87.50%,  total acc: 65.37%   [EVAL] batch:  268 | acc: 100.00%,  total acc: 65.50%   [EVAL] batch:  269 | acc: 87.50%,  total acc: 65.58%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 65.71%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 65.83%   [EVAL] batch:  272 | acc: 87.50%,  total acc: 65.91%   [EVAL] batch:  273 | acc: 100.00%,  total acc: 66.04%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 66.16%   [EVAL] batch:  275 | acc: 43.75%,  total acc: 66.08%   [EVAL] batch:  276 | acc: 31.25%,  total acc: 65.95%   [EVAL] batch:  277 | acc: 68.75%,  total acc: 65.96%   [EVAL] batch:  278 | acc: 68.75%,  total acc: 65.97%   [EVAL] batch:  279 | acc: 37.50%,  total acc: 65.87%   [EVAL] batch:  280 | acc: 43.75%,  total acc: 65.79%   [EVAL] batch:  281 | acc: 43.75%,  total acc: 65.71%   [EVAL] batch:  282 | acc: 12.50%,  total acc: 65.53%   [EVAL] batch:  283 | acc: 6.25%,  total acc: 65.32%   [EVAL] batch:  284 | acc: 25.00%,  total acc: 65.18%   [EVAL] batch:  285 | acc: 12.50%,  total acc: 64.99%   [EVAL] batch:  286 | acc: 6.25%,  total acc: 64.79%   [EVAL] batch:  287 | acc: 12.50%,  total acc: 64.61%   [EVAL] batch:  288 | acc: 12.50%,  total acc: 64.42%   [EVAL] batch:  289 | acc: 18.75%,  total acc: 64.27%   [EVAL] batch:  290 | acc: 18.75%,  total acc: 64.11%   [EVAL] batch:  291 | acc: 12.50%,  total acc: 63.93%   [EVAL] batch:  292 | acc: 18.75%,  total acc: 63.78%   [EVAL] batch:  293 | acc: 37.50%,  total acc: 63.69%   [EVAL] batch:  294 | acc: 81.25%,  total acc: 63.75%   [EVAL] batch:  295 | acc: 62.50%,  total acc: 63.75%   [EVAL] batch:  296 | acc: 68.75%,  total acc: 63.76%   [EVAL] batch:  297 | acc: 62.50%,  total acc: 63.76%   [EVAL] batch:  298 | acc: 62.50%,  total acc: 63.75%   [EVAL] batch:  299 | acc: 75.00%,  total acc: 63.79%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 63.91%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 64.03%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 64.15%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 64.27%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 64.39%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 64.50%   [EVAL] batch:  306 | acc: 93.75%,  total acc: 64.60%   [EVAL] batch:  307 | acc: 87.50%,  total acc: 64.67%   [EVAL] batch:  308 | acc: 81.25%,  total acc: 64.72%   [EVAL] batch:  309 | acc: 93.75%,  total acc: 64.82%   [EVAL] batch:  310 | acc: 87.50%,  total acc: 64.89%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 65.00%   [EVAL] batch:  312 | acc: 62.50%,  total acc: 65.00%   [EVAL] batch:  313 | acc: 25.00%,  total acc: 64.87%   [EVAL] batch:  314 | acc: 18.75%,  total acc: 64.72%   [EVAL] batch:  315 | acc: 18.75%,  total acc: 64.58%   [EVAL] batch:  316 | acc: 18.75%,  total acc: 64.43%   [EVAL] batch:  317 | acc: 25.00%,  total acc: 64.31%   [EVAL] batch:  318 | acc: 31.25%,  total acc: 64.20%   [EVAL] batch:  319 | acc: 81.25%,  total acc: 64.26%   [EVAL] batch:  320 | acc: 93.75%,  total acc: 64.35%   [EVAL] batch:  321 | acc: 87.50%,  total acc: 64.42%   [EVAL] batch:  322 | acc: 100.00%,  total acc: 64.53%   [EVAL] batch:  323 | acc: 87.50%,  total acc: 64.60%   [EVAL] batch:  324 | acc: 81.25%,  total acc: 64.65%   [EVAL] batch:  325 | acc: 37.50%,  total acc: 64.57%   [EVAL] batch:  326 | acc: 6.25%,  total acc: 64.39%   [EVAL] batch:  327 | acc: 0.00%,  total acc: 64.20%   [EVAL] batch:  328 | acc: 6.25%,  total acc: 64.02%   [EVAL] batch:  329 | acc: 37.50%,  total acc: 63.94%   [EVAL] batch:  330 | acc: 18.75%,  total acc: 63.80%   [EVAL] batch:  331 | acc: 81.25%,  total acc: 63.86%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 63.96%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 64.07%   [EVAL] batch:  334 | acc: 93.75%,  total acc: 64.16%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 64.27%   [EVAL] batch:  336 | acc: 100.00%,  total acc: 64.37%   [EVAL] batch:  337 | acc: 87.50%,  total acc: 64.44%   [EVAL] batch:  338 | acc: 81.25%,  total acc: 64.49%   [EVAL] batch:  339 | acc: 87.50%,  total acc: 64.56%   [EVAL] batch:  340 | acc: 100.00%,  total acc: 64.66%   [EVAL] batch:  341 | acc: 75.00%,  total acc: 64.69%   [EVAL] batch:  342 | acc: 100.00%,  total acc: 64.80%   [EVAL] batch:  343 | acc: 93.75%,  total acc: 64.88%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 64.98%   [EVAL] batch:  345 | acc: 100.00%,  total acc: 65.08%   [EVAL] batch:  346 | acc: 87.50%,  total acc: 65.15%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 65.23%   [EVAL] batch:  348 | acc: 93.75%,  total acc: 65.31%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 65.41%   [EVAL] batch:  350 | acc: 0.00%,  total acc: 65.22%   [EVAL] batch:  351 | acc: 0.00%,  total acc: 65.04%   [EVAL] batch:  352 | acc: 6.25%,  total acc: 64.87%   [EVAL] batch:  353 | acc: 0.00%,  total acc: 64.69%   [EVAL] batch:  354 | acc: 6.25%,  total acc: 64.52%   [EVAL] batch:  355 | acc: 0.00%,  total acc: 64.34%   [EVAL] batch:  356 | acc: 75.00%,  total acc: 64.37%   [EVAL] batch:  357 | acc: 93.75%,  total acc: 64.46%   [EVAL] batch:  358 | acc: 93.75%,  total acc: 64.54%   [EVAL] batch:  359 | acc: 100.00%,  total acc: 64.64%   [EVAL] batch:  360 | acc: 93.75%,  total acc: 64.72%   [EVAL] batch:  361 | acc: 87.50%,  total acc: 64.78%   [EVAL] batch:  362 | acc: 62.50%,  total acc: 64.77%   [EVAL] batch:  363 | acc: 18.75%,  total acc: 64.65%   [EVAL] batch:  364 | acc: 37.50%,  total acc: 64.57%   [EVAL] batch:  365 | acc: 62.50%,  total acc: 64.57%   [EVAL] batch:  366 | acc: 25.00%,  total acc: 64.46%   [EVAL] batch:  367 | acc: 31.25%,  total acc: 64.37%   [EVAL] batch:  368 | acc: 25.00%,  total acc: 64.26%   [EVAL] batch:  369 | acc: 31.25%,  total acc: 64.17%   [EVAL] batch:  370 | acc: 56.25%,  total acc: 64.15%   [EVAL] batch:  371 | acc: 43.75%,  total acc: 64.10%   [EVAL] batch:  372 | acc: 68.75%,  total acc: 64.11%   [EVAL] batch:  373 | acc: 81.25%,  total acc: 64.15%   [EVAL] batch:  374 | acc: 56.25%,  total acc: 64.13%   [EVAL] batch:  375 | acc: 37.50%,  total acc: 64.06%   [EVAL] batch:  376 | acc: 43.75%,  total acc: 64.01%   [EVAL] batch:  377 | acc: 31.25%,  total acc: 63.92%   [EVAL] batch:  378 | acc: 56.25%,  total acc: 63.90%   [EVAL] batch:  379 | acc: 25.00%,  total acc: 63.80%   [EVAL] batch:  380 | acc: 50.00%,  total acc: 63.76%   [EVAL] batch:  381 | acc: 68.75%,  total acc: 63.78%   [EVAL] batch:  382 | acc: 87.50%,  total acc: 63.84%   [EVAL] batch:  383 | acc: 93.75%,  total acc: 63.92%   [EVAL] batch:  384 | acc: 93.75%,  total acc: 63.99%   [EVAL] batch:  385 | acc: 75.00%,  total acc: 64.02%   [EVAL] batch:  386 | acc: 81.25%,  total acc: 64.07%   [EVAL] batch:  387 | acc: 87.50%,  total acc: 64.13%   [EVAL] batch:  388 | acc: 93.75%,  total acc: 64.20%   [EVAL] batch:  389 | acc: 93.75%,  total acc: 64.28%   [EVAL] batch:  390 | acc: 93.75%,  total acc: 64.35%   [EVAL] batch:  391 | acc: 87.50%,  total acc: 64.41%   [EVAL] batch:  392 | acc: 100.00%,  total acc: 64.50%   [EVAL] batch:  393 | acc: 56.25%,  total acc: 64.48%   [EVAL] batch:  394 | acc: 43.75%,  total acc: 64.43%   [EVAL] batch:  395 | acc: 12.50%,  total acc: 64.30%   [EVAL] batch:  396 | acc: 50.00%,  total acc: 64.26%   [EVAL] batch:  397 | acc: 56.25%,  total acc: 64.24%   [EVAL] batch:  398 | acc: 37.50%,  total acc: 64.18%   [EVAL] batch:  399 | acc: 37.50%,  total acc: 64.11%   [EVAL] batch:  400 | acc: 6.25%,  total acc: 63.97%   [EVAL] batch:  401 | acc: 0.00%,  total acc: 63.81%   [EVAL] batch:  402 | acc: 0.00%,  total acc: 63.65%   [EVAL] batch:  403 | acc: 0.00%,  total acc: 63.49%   [EVAL] batch:  404 | acc: 0.00%,  total acc: 63.33%   [EVAL] batch:  405 | acc: 0.00%,  total acc: 63.18%   [EVAL] batch:  406 | acc: 68.75%,  total acc: 63.19%   [EVAL] batch:  407 | acc: 93.75%,  total acc: 63.27%   [EVAL] batch:  408 | acc: 81.25%,  total acc: 63.31%   [EVAL] batch:  409 | acc: 93.75%,  total acc: 63.38%   [EVAL] batch:  410 | acc: 87.50%,  total acc: 63.44%   [EVAL] batch:  411 | acc: 87.50%,  total acc: 63.50%   [EVAL] batch:  412 | acc: 93.75%,  total acc: 63.57%   [EVAL] batch:  413 | acc: 93.75%,  total acc: 63.65%   [EVAL] batch:  414 | acc: 100.00%,  total acc: 63.73%   [EVAL] batch:  415 | acc: 93.75%,  total acc: 63.81%   [EVAL] batch:  416 | acc: 75.00%,  total acc: 63.83%   [EVAL] batch:  417 | acc: 100.00%,  total acc: 63.92%   [EVAL] batch:  418 | acc: 100.00%,  total acc: 64.01%   [EVAL] batch:  419 | acc: 93.75%,  total acc: 64.08%   [EVAL] batch:  420 | acc: 87.50%,  total acc: 64.13%   [EVAL] batch:  421 | acc: 75.00%,  total acc: 64.16%   [EVAL] batch:  422 | acc: 81.25%,  total acc: 64.20%   [EVAL] batch:  423 | acc: 93.75%,  total acc: 64.27%   [EVAL] batch:  424 | acc: 75.00%,  total acc: 64.29%   [EVAL] batch:  425 | acc: 43.75%,  total acc: 64.25%   [EVAL] batch:  426 | acc: 75.00%,  total acc: 64.27%   [EVAL] batch:  427 | acc: 81.25%,  total acc: 64.31%   [EVAL] batch:  428 | acc: 93.75%,  total acc: 64.38%   [EVAL] batch:  429 | acc: 62.50%,  total acc: 64.38%   [EVAL] batch:  430 | acc: 81.25%,  total acc: 64.41%   [EVAL] batch:  431 | acc: 50.00%,  total acc: 64.38%   [EVAL] batch:  432 | acc: 56.25%,  total acc: 64.36%   [EVAL] batch:  433 | acc: 62.50%,  total acc: 64.36%   [EVAL] batch:  434 | acc: 75.00%,  total acc: 64.38%   [EVAL] batch:  435 | acc: 50.00%,  total acc: 64.35%   [EVAL] batch:  436 | acc: 81.25%,  total acc: 64.39%   [EVAL] batch:  437 | acc: 68.75%,  total acc: 64.40%   [EVAL] batch:  438 | acc: 75.00%,  total acc: 64.42%   [EVAL] batch:  439 | acc: 93.75%,  total acc: 64.49%   [EVAL] batch:  440 | acc: 93.75%,  total acc: 64.55%   [EVAL] batch:  441 | acc: 81.25%,  total acc: 64.59%   [EVAL] batch:  442 | acc: 93.75%,  total acc: 64.66%   [EVAL] batch:  443 | acc: 75.00%,  total acc: 64.68%   [EVAL] batch:  444 | acc: 68.75%,  total acc: 64.69%   [EVAL] batch:  445 | acc: 68.75%,  total acc: 64.70%   [EVAL] batch:  446 | acc: 62.50%,  total acc: 64.70%   [EVAL] batch:  447 | acc: 75.00%,  total acc: 64.72%   [EVAL] batch:  448 | acc: 75.00%,  total acc: 64.74%   [EVAL] batch:  449 | acc: 81.25%,  total acc: 64.78%   [EVAL] batch:  450 | acc: 100.00%,  total acc: 64.86%   [EVAL] batch:  451 | acc: 93.75%,  total acc: 64.92%   [EVAL] batch:  452 | acc: 87.50%,  total acc: 64.97%   [EVAL] batch:  453 | acc: 93.75%,  total acc: 65.03%   [EVAL] batch:  454 | acc: 87.50%,  total acc: 65.08%   [EVAL] batch:  455 | acc: 93.75%,  total acc: 65.15%   [EVAL] batch:  456 | acc: 43.75%,  total acc: 65.10%   [EVAL] batch:  457 | acc: 43.75%,  total acc: 65.05%   [EVAL] batch:  458 | acc: 62.50%,  total acc: 65.05%   [EVAL] batch:  459 | acc: 37.50%,  total acc: 64.99%   [EVAL] batch:  460 | acc: 37.50%,  total acc: 64.93%   [EVAL] batch:  461 | acc: 43.75%,  total acc: 64.88%   [EVAL] batch:  462 | acc: 56.25%,  total acc: 64.86%   [EVAL] batch:  463 | acc: 100.00%,  total acc: 64.94%   [EVAL] batch:  464 | acc: 100.00%,  total acc: 65.01%   [EVAL] batch:  465 | acc: 100.00%,  total acc: 65.09%   [EVAL] batch:  466 | acc: 100.00%,  total acc: 65.16%   [EVAL] batch:  467 | acc: 100.00%,  total acc: 65.24%   [EVAL] batch:  468 | acc: 100.00%,  total acc: 65.31%   [EVAL] batch:  469 | acc: 100.00%,  total acc: 65.39%   [EVAL] batch:  470 | acc: 100.00%,  total acc: 65.46%   [EVAL] batch:  471 | acc: 100.00%,  total acc: 65.53%   [EVAL] batch:  472 | acc: 100.00%,  total acc: 65.61%   [EVAL] batch:  473 | acc: 100.00%,  total acc: 65.68%   [EVAL] batch:  474 | acc: 100.00%,  total acc: 65.75%   [EVAL] batch:  475 | acc: 93.75%,  total acc: 65.81%   [EVAL] batch:  476 | acc: 93.75%,  total acc: 65.87%   [EVAL] batch:  477 | acc: 93.75%,  total acc: 65.93%   [EVAL] batch:  478 | acc: 87.50%,  total acc: 65.97%   [EVAL] batch:  479 | acc: 93.75%,  total acc: 66.03%   [EVAL] batch:  480 | acc: 81.25%,  total acc: 66.06%   [EVAL] batch:  481 | acc: 43.75%,  total acc: 66.01%   [EVAL] batch:  482 | acc: 12.50%,  total acc: 65.90%   [EVAL] batch:  483 | acc: 25.00%,  total acc: 65.82%   [EVAL] batch:  484 | acc: 31.25%,  total acc: 65.75%   [EVAL] batch:  485 | acc: 56.25%,  total acc: 65.73%   [EVAL] batch:  486 | acc: 37.50%,  total acc: 65.67%   [EVAL] batch:  487 | acc: 62.50%,  total acc: 65.66%   [EVAL] batch:  488 | acc: 87.50%,  total acc: 65.71%   [EVAL] batch:  489 | acc: 93.75%,  total acc: 65.77%   [EVAL] batch:  490 | acc: 87.50%,  total acc: 65.81%   [EVAL] batch:  491 | acc: 87.50%,  total acc: 65.85%   [EVAL] batch:  492 | acc: 93.75%,  total acc: 65.91%   [EVAL] batch:  493 | acc: 87.50%,  total acc: 65.95%   [EVAL] batch:  494 | acc: 62.50%,  total acc: 65.95%   [EVAL] batch:  495 | acc: 81.25%,  total acc: 65.98%   [EVAL] batch:  496 | acc: 75.00%,  total acc: 66.00%   [EVAL] batch:  497 | acc: 56.25%,  total acc: 65.98%   [EVAL] batch:  498 | acc: 56.25%,  total acc: 65.96%   [EVAL] batch:  499 | acc: 87.50%,  total acc: 66.00%   
cur_acc:  ['0.9464', '0.7262', '0.7609', '0.8423', '0.8304', '0.7609', '0.6726', '0.7679']
his_acc:  ['0.9464', '0.8255', '0.7912', '0.7895', '0.7794', '0.7283', '0.6778', '0.6600']
--------Round  1
seed:  200
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/train.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/valid.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0]
Losses:  11.80009651184082 2.0320608615875244
CurrentTrain: epoch  0, batch     0 | loss: 13.8321571Losses:  12.83187484741211 1.7020825147628784
CurrentTrain: epoch  0, batch     1 | loss: 14.5339575Losses:  13.378859519958496 1.9679834842681885
CurrentTrain: epoch  0, batch     2 | loss: 15.3468428Losses:  13.331903457641602 1.5486576557159424
CurrentTrain: epoch  0, batch     3 | loss: 14.8805609Losses:  13.448766708374023 1.5942790508270264
CurrentTrain: epoch  0, batch     4 | loss: 15.0430460Losses:  12.863714218139648 1.3882880210876465
CurrentTrain: epoch  0, batch     5 | loss: 14.2520027Losses:  13.435091018676758 1.585008144378662
CurrentTrain: epoch  0, batch     6 | loss: 15.0200996Losses:  13.298019409179688 1.7952709197998047
CurrentTrain: epoch  0, batch     7 | loss: 15.0932903Losses:  13.230993270874023 1.6552627086639404
CurrentTrain: epoch  0, batch     8 | loss: 14.8862562Losses:  12.96678638458252 1.6727113723754883
CurrentTrain: epoch  0, batch     9 | loss: 14.6394978Losses:  12.94171142578125 1.5509932041168213
CurrentTrain: epoch  0, batch    10 | loss: 14.4927044Losses:  12.512937545776367 1.5651432275772095
CurrentTrain: epoch  0, batch    11 | loss: 14.0780811Losses:  11.930591583251953 1.3455296754837036
CurrentTrain: epoch  0, batch    12 | loss: 13.2761211Losses:  12.199567794799805 1.4067046642303467
CurrentTrain: epoch  0, batch    13 | loss: 13.6062727Losses:  11.719744682312012 1.4398120641708374
CurrentTrain: epoch  0, batch    14 | loss: 13.1595564Losses:  12.188127517700195 1.8121209144592285
CurrentTrain: epoch  0, batch    15 | loss: 14.0002480Losses:  11.811237335205078 1.7224533557891846
CurrentTrain: epoch  0, batch    16 | loss: 13.5336905Losses:  11.687939643859863 1.3758594989776611
CurrentTrain: epoch  0, batch    17 | loss: 13.0637989Losses:  11.957721710205078 1.5569233894348145
CurrentTrain: epoch  0, batch    18 | loss: 13.5146446Losses:  11.670044898986816 1.6647332906723022
CurrentTrain: epoch  0, batch    19 | loss: 13.3347778Losses:  11.516008377075195 1.6172289848327637
CurrentTrain: epoch  0, batch    20 | loss: 13.1332378Losses:  11.425788879394531 1.4822404384613037
CurrentTrain: epoch  0, batch    21 | loss: 12.9080296Losses:  10.914588928222656 1.2432827949523926
CurrentTrain: epoch  0, batch    22 | loss: 12.1578712Losses:  11.151966094970703 1.2915475368499756
CurrentTrain: epoch  0, batch    23 | loss: 12.4435139Losses:  10.909682273864746 1.139878749847412
CurrentTrain: epoch  0, batch    24 | loss: 12.0495605Losses:  11.032238960266113 1.377902865409851
CurrentTrain: epoch  0, batch    25 | loss: 12.4101419Losses:  10.93326187133789 1.3395648002624512
CurrentTrain: epoch  0, batch    26 | loss: 12.2728271Losses:  10.15753173828125 1.2862868309020996
CurrentTrain: epoch  0, batch    27 | loss: 11.4438190Losses:  10.671048164367676 1.206681489944458
CurrentTrain: epoch  0, batch    28 | loss: 11.8777294Losses:  10.006887435913086 1.445456862449646
CurrentTrain: epoch  0, batch    29 | loss: 11.4523439Losses:  10.029827117919922 1.1475543975830078
CurrentTrain: epoch  0, batch    30 | loss: 11.1773815Losses:  9.774235725402832 1.1309376955032349
CurrentTrain: epoch  0, batch    31 | loss: 10.9051733Losses:  10.133752822875977 1.3332569599151611
CurrentTrain: epoch  0, batch    32 | loss: 11.4670095Losses:  10.017253875732422 1.4235765933990479
CurrentTrain: epoch  0, batch    33 | loss: 11.4408302Losses:  9.913862228393555 1.0547140836715698
CurrentTrain: epoch  0, batch    34 | loss: 10.9685764Losses:  9.535163879394531 1.1248060464859009
CurrentTrain: epoch  0, batch    35 | loss: 10.6599703Losses:  9.29391098022461 1.1656043529510498
CurrentTrain: epoch  0, batch    36 | loss: 10.4595156Losses:  9.680208206176758 1.2641983032226562
CurrentTrain: epoch  0, batch    37 | loss: 10.9444065Losses:  9.813671112060547 1.1278505325317383
CurrentTrain: epoch  0, batch    38 | loss: 10.9415216Losses:  8.847047805786133 1.1456289291381836
CurrentTrain: epoch  0, batch    39 | loss: 9.9926767Losses:  8.578371047973633 0.9201753735542297
CurrentTrain: epoch  0, batch    40 | loss: 9.4985466Losses:  8.854568481445312 1.0341432094573975
CurrentTrain: epoch  0, batch    41 | loss: 9.8887119Losses:  8.17757797241211 1.0100207328796387
CurrentTrain: epoch  0, batch    42 | loss: 9.1875992Losses:  8.444289207458496 1.0988048315048218
CurrentTrain: epoch  0, batch    43 | loss: 9.5430937Losses:  8.432069778442383 1.0472676753997803
CurrentTrain: epoch  0, batch    44 | loss: 9.4793377Losses:  8.70500373840332 1.1440507173538208
CurrentTrain: epoch  0, batch    45 | loss: 9.8490543Losses:  8.19975471496582 1.0847069025039673
CurrentTrain: epoch  0, batch    46 | loss: 9.2844620Losses:  8.160804748535156 1.049302577972412
CurrentTrain: epoch  0, batch    47 | loss: 9.2101078Losses:  7.687814712524414 0.9054933786392212
CurrentTrain: epoch  0, batch    48 | loss: 8.5933084Losses:  7.690745830535889 0.8388671875
CurrentTrain: epoch  0, batch    49 | loss: 8.5296135Losses:  7.454989433288574 1.03340482711792
CurrentTrain: epoch  0, batch    50 | loss: 8.4883938Losses:  7.599617958068848 0.9572756886482239
CurrentTrain: epoch  0, batch    51 | loss: 8.5568933Losses:  7.538597583770752 0.9700849652290344
CurrentTrain: epoch  0, batch    52 | loss: 8.5086823Losses:  7.112765312194824 0.9161005020141602
CurrentTrain: epoch  0, batch    53 | loss: 8.0288658Losses:  7.195306777954102 1.0502959489822388
CurrentTrain: epoch  0, batch    54 | loss: 8.2456026Losses:  7.091432571411133 1.2635514736175537
CurrentTrain: epoch  0, batch    55 | loss: 8.3549843Losses:  6.85324764251709 0.7356294393539429
CurrentTrain: epoch  0, batch    56 | loss: 7.5888772Losses:  6.953138828277588 1.0716170072555542
CurrentTrain: epoch  0, batch    57 | loss: 8.0247555Losses:  7.663155555725098 0.9441080093383789
CurrentTrain: epoch  0, batch    58 | loss: 8.6072636Losses:  6.459559440612793 0.9126016497612
CurrentTrain: epoch  0, batch    59 | loss: 7.3721609Losses:  6.384497165679932 0.7490364909172058
CurrentTrain: epoch  0, batch    60 | loss: 7.1335335Losses:  6.363658905029297 0.8164695501327515
CurrentTrain: epoch  0, batch    61 | loss: 7.1801286Losses:  6.201291084289551 0.6683823466300964
CurrentTrain: epoch  0, batch    62 | loss: 6.8696733Losses:  5.534139633178711 0.6644335985183716
CurrentTrain: epoch  1, batch     0 | loss: 6.1985731Losses:  6.3583879470825195 0.86238694190979
CurrentTrain: epoch  1, batch     1 | loss: 7.2207747Losses:  6.413450241088867 0.6464425325393677
CurrentTrain: epoch  1, batch     2 | loss: 7.0598927Losses:  6.519118309020996 0.9999678134918213
CurrentTrain: epoch  1, batch     3 | loss: 7.5190859Losses:  6.229782581329346 0.7473679780960083
CurrentTrain: epoch  1, batch     4 | loss: 6.9771504Losses:  5.688599109649658 0.8823567032814026
CurrentTrain: epoch  1, batch     5 | loss: 6.5709558Losses:  6.001835823059082 0.7573257684707642
CurrentTrain: epoch  1, batch     6 | loss: 6.7591615Losses:  5.845501899719238 0.5613322854042053
CurrentTrain: epoch  1, batch     7 | loss: 6.4068341Losses:  5.869089603424072 0.7060728073120117
CurrentTrain: epoch  1, batch     8 | loss: 6.5751624Losses:  5.932615280151367 0.8247545957565308
CurrentTrain: epoch  1, batch     9 | loss: 6.7573700Losses:  5.85860538482666 0.737109899520874
CurrentTrain: epoch  1, batch    10 | loss: 6.5957155Losses:  6.002370834350586 0.7392991781234741
CurrentTrain: epoch  1, batch    11 | loss: 6.7416701Losses:  5.806249618530273 0.7079862356185913
CurrentTrain: epoch  1, batch    12 | loss: 6.5142360Losses:  5.933310508728027 0.725171685218811
CurrentTrain: epoch  1, batch    13 | loss: 6.6584821Losses:  5.546945571899414 0.7795549035072327
CurrentTrain: epoch  1, batch    14 | loss: 6.3265004Losses:  5.576165199279785 0.6960104703903198
CurrentTrain: epoch  1, batch    15 | loss: 6.2721758Losses:  5.461379051208496 0.567488431930542
CurrentTrain: epoch  1, batch    16 | loss: 6.0288677Losses:  5.249294281005859 0.588309645652771
CurrentTrain: epoch  1, batch    17 | loss: 5.8376040Losses:  6.111238956451416 0.6579629778862
CurrentTrain: epoch  1, batch    18 | loss: 6.7692018Losses:  5.507960319519043 0.5692108869552612
CurrentTrain: epoch  1, batch    19 | loss: 6.0771713Losses:  5.538747787475586 0.6188070774078369
CurrentTrain: epoch  1, batch    20 | loss: 6.1575546Losses:  5.32352352142334 0.6280567646026611
CurrentTrain: epoch  1, batch    21 | loss: 5.9515800Losses:  5.248481750488281 0.4908600151538849
CurrentTrain: epoch  1, batch    22 | loss: 5.7393417Losses:  5.399270057678223 0.7270164489746094
CurrentTrain: epoch  1, batch    23 | loss: 6.1262865Losses:  5.837935447692871 0.652190089225769
CurrentTrain: epoch  1, batch    24 | loss: 6.4901257Losses:  5.350656032562256 0.5930113792419434
CurrentTrain: epoch  1, batch    25 | loss: 5.9436674Losses:  5.7649455070495605 0.4763837456703186
CurrentTrain: epoch  1, batch    26 | loss: 6.2413292Losses:  5.514109134674072 0.5642205476760864
CurrentTrain: epoch  1, batch    27 | loss: 6.0783296Losses:  5.639052391052246 0.756114661693573
CurrentTrain: epoch  1, batch    28 | loss: 6.3951669Losses:  5.449583053588867 0.634499192237854
CurrentTrain: epoch  1, batch    29 | loss: 6.0840821Losses:  5.26494026184082 0.3684886693954468
CurrentTrain: epoch  1, batch    30 | loss: 5.6334291Losses:  5.816068649291992 0.9247078895568848
CurrentTrain: epoch  1, batch    31 | loss: 6.7407765Losses:  5.197066307067871 0.6153672337532043
CurrentTrain: epoch  1, batch    32 | loss: 5.8124337Losses:  5.479647636413574 0.4865383803844452
CurrentTrain: epoch  1, batch    33 | loss: 5.9661860Losses:  5.227306365966797 0.455562949180603
CurrentTrain: epoch  1, batch    34 | loss: 5.6828694Losses:  5.417566299438477 0.48787224292755127
CurrentTrain: epoch  1, batch    35 | loss: 5.9054384Losses:  5.560833930969238 0.5902894735336304
CurrentTrain: epoch  1, batch    36 | loss: 6.1511235Losses:  5.298832893371582 0.5106581449508667
CurrentTrain: epoch  1, batch    37 | loss: 5.8094912Losses:  5.399114608764648 0.5188590288162231
CurrentTrain: epoch  1, batch    38 | loss: 5.9179735Losses:  5.961477279663086 0.4854937195777893
CurrentTrain: epoch  1, batch    39 | loss: 6.4469709Losses:  4.904862880706787 0.4029918909072876
CurrentTrain: epoch  1, batch    40 | loss: 5.3078547Losses:  5.3631591796875 0.4929419755935669
CurrentTrain: epoch  1, batch    41 | loss: 5.8561010Losses:  5.503767967224121 0.6118131875991821
CurrentTrain: epoch  1, batch    42 | loss: 6.1155810Losses:  5.307707786560059 0.7436596751213074
CurrentTrain: epoch  1, batch    43 | loss: 6.0513673Losses:  4.781718730926514 0.29982277750968933
CurrentTrain: epoch  1, batch    44 | loss: 5.0815415Losses:  5.191779136657715 0.4235756993293762
CurrentTrain: epoch  1, batch    45 | loss: 5.6153550Losses:  5.2906293869018555 0.6387335658073425
CurrentTrain: epoch  1, batch    46 | loss: 5.9293628Losses:  5.762081146240234 0.7486244440078735
CurrentTrain: epoch  1, batch    47 | loss: 6.5107055Losses:  5.504538536071777 0.5877867937088013
CurrentTrain: epoch  1, batch    48 | loss: 6.0923252Losses:  5.612231254577637 0.6526710987091064
CurrentTrain: epoch  1, batch    49 | loss: 6.2649021Losses:  5.1310882568359375 0.6016770601272583
CurrentTrain: epoch  1, batch    50 | loss: 5.7327652Losses:  5.340947151184082 0.5439732074737549
CurrentTrain: epoch  1, batch    51 | loss: 5.8849201Losses:  4.903257369995117 0.5144420862197876
CurrentTrain: epoch  1, batch    52 | loss: 5.4176993Losses:  4.928074836730957 0.4553617835044861
CurrentTrain: epoch  1, batch    53 | loss: 5.3834367Losses:  5.218116760253906 0.46573835611343384
CurrentTrain: epoch  1, batch    54 | loss: 5.6838551Losses:  4.8240203857421875 0.3401215672492981
CurrentTrain: epoch  1, batch    55 | loss: 5.1641421Losses:  4.876213073730469 0.5111220479011536
CurrentTrain: epoch  1, batch    56 | loss: 5.3873353Losses:  5.240062236785889 0.4849591851234436
CurrentTrain: epoch  1, batch    57 | loss: 5.7250214Losses:  4.964669227600098 0.48321816325187683
CurrentTrain: epoch  1, batch    58 | loss: 5.4478874Losses:  5.056077003479004 0.356842041015625
CurrentTrain: epoch  1, batch    59 | loss: 5.4129190Losses:  4.741570949554443 0.48883822560310364
CurrentTrain: epoch  1, batch    60 | loss: 5.2304091Losses:  5.250283241271973 0.5701415538787842
CurrentTrain: epoch  1, batch    61 | loss: 5.8204250Losses:  5.353189945220947 0.4400041997432709
CurrentTrain: epoch  1, batch    62 | loss: 5.7931943Losses:  4.737171649932861 0.35021036863327026
CurrentTrain: epoch  2, batch     0 | loss: 5.0873818Losses:  4.575272560119629 0.3265097737312317
CurrentTrain: epoch  2, batch     1 | loss: 4.9017825Losses:  5.07634162902832 0.6060791015625
CurrentTrain: epoch  2, batch     2 | loss: 5.6824207Losses:  5.521233558654785 0.4111126661300659
CurrentTrain: epoch  2, batch     3 | loss: 5.9323463Losses:  4.981045722961426 0.34082069993019104
CurrentTrain: epoch  2, batch     4 | loss: 5.3218665Losses:  4.909448623657227 0.33650439977645874
CurrentTrain: epoch  2, batch     5 | loss: 5.2459531Losses:  4.791532039642334 0.42636358737945557
CurrentTrain: epoch  2, batch     6 | loss: 5.2178955Losses:  4.642085075378418 0.40993720293045044
CurrentTrain: epoch  2, batch     7 | loss: 5.0520225Losses:  4.870570659637451 0.3976367712020874
CurrentTrain: epoch  2, batch     8 | loss: 5.2682076Losses:  5.288673400878906 0.43246811628341675
CurrentTrain: epoch  2, batch     9 | loss: 5.7211413Losses:  4.7563252449035645 0.39475512504577637
CurrentTrain: epoch  2, batch    10 | loss: 5.1510801Losses:  4.942058563232422 0.39107686281204224
CurrentTrain: epoch  2, batch    11 | loss: 5.3331356Losses:  4.720191955566406 0.34905168414115906
CurrentTrain: epoch  2, batch    12 | loss: 5.0692434Losses:  5.1063032150268555 0.4082820415496826
CurrentTrain: epoch  2, batch    13 | loss: 5.5145855Losses:  4.9161248207092285 0.3680643141269684
CurrentTrain: epoch  2, batch    14 | loss: 5.2841892Losses:  4.76500129699707 0.3495205044746399
CurrentTrain: epoch  2, batch    15 | loss: 5.1145220Losses:  4.673957824707031 0.3748742341995239
CurrentTrain: epoch  2, batch    16 | loss: 5.0488319Losses:  4.917499542236328 0.24580232799053192
CurrentTrain: epoch  2, batch    17 | loss: 5.1633019Losses:  4.997312545776367 0.4340389370918274
CurrentTrain: epoch  2, batch    18 | loss: 5.4313517Losses:  4.829888343811035 0.47141289710998535
CurrentTrain: epoch  2, batch    19 | loss: 5.3013010Losses:  4.6151123046875 0.31828707456588745
CurrentTrain: epoch  2, batch    20 | loss: 4.9333992Losses:  4.444511890411377 0.3208182454109192
CurrentTrain: epoch  2, batch    21 | loss: 4.7653303Losses:  4.5673723220825195 0.3318203389644623
CurrentTrain: epoch  2, batch    22 | loss: 4.8991928Losses:  4.441127777099609 0.2930431067943573
CurrentTrain: epoch  2, batch    23 | loss: 4.7341709Losses:  4.818533897399902 0.3711055517196655
CurrentTrain: epoch  2, batch    24 | loss: 5.1896396Losses:  4.616671562194824 0.31432318687438965
CurrentTrain: epoch  2, batch    25 | loss: 4.9309950Losses:  5.082901954650879 0.570002555847168
CurrentTrain: epoch  2, batch    26 | loss: 5.6529045Losses:  4.693648338317871 0.3580661416053772
CurrentTrain: epoch  2, batch    27 | loss: 5.0517144Losses:  4.591117858886719 0.3990177512168884
CurrentTrain: epoch  2, batch    28 | loss: 4.9901357Losses:  4.882705211639404 0.5309782028198242
CurrentTrain: epoch  2, batch    29 | loss: 5.4136834Losses:  4.715104579925537 0.39678406715393066
CurrentTrain: epoch  2, batch    30 | loss: 5.1118889Losses:  4.722538471221924 0.4068784713745117
CurrentTrain: epoch  2, batch    31 | loss: 5.1294169Losses:  4.532562255859375 0.29372403025627136
CurrentTrain: epoch  2, batch    32 | loss: 4.8262863Losses:  4.4358015060424805 0.254504919052124
CurrentTrain: epoch  2, batch    33 | loss: 4.6903067Losses:  4.702531814575195 0.34258073568344116
CurrentTrain: epoch  2, batch    34 | loss: 5.0451126Losses:  4.8943305015563965 0.33654630184173584
CurrentTrain: epoch  2, batch    35 | loss: 5.2308769Losses:  4.441972732543945 0.3284839689731598
CurrentTrain: epoch  2, batch    36 | loss: 4.7704568Losses:  4.895289421081543 0.31884682178497314
CurrentTrain: epoch  2, batch    37 | loss: 5.2141361Losses:  4.705904960632324 0.34200918674468994
CurrentTrain: epoch  2, batch    38 | loss: 5.0479140Losses:  4.573485374450684 0.37719541788101196
CurrentTrain: epoch  2, batch    39 | loss: 4.9506807Losses:  4.9696245193481445 0.4633907377719879
CurrentTrain: epoch  2, batch    40 | loss: 5.4330153Losses:  4.959109306335449 0.4134218692779541
CurrentTrain: epoch  2, batch    41 | loss: 5.3725309Losses:  4.687147617340088 0.33112648129463196
CurrentTrain: epoch  2, batch    42 | loss: 5.0182743Losses:  4.674918174743652 0.33926424384117126
CurrentTrain: epoch  2, batch    43 | loss: 5.0141826Losses:  4.357226371765137 0.23296378552913666
CurrentTrain: epoch  2, batch    44 | loss: 4.5901899Losses:  4.395926475524902 0.27954575419425964
CurrentTrain: epoch  2, batch    45 | loss: 4.6754723Losses:  4.472528457641602 0.27255094051361084
CurrentTrain: epoch  2, batch    46 | loss: 4.7450795Losses:  4.3982391357421875 0.27425092458724976
CurrentTrain: epoch  2, batch    47 | loss: 4.6724901Losses:  4.480990886688232 0.280758798122406
CurrentTrain: epoch  2, batch    48 | loss: 4.7617497Losses:  4.4749555587768555 0.20204350352287292
CurrentTrain: epoch  2, batch    49 | loss: 4.6769991Losses:  4.82185697555542 0.47747206687927246
CurrentTrain: epoch  2, batch    50 | loss: 5.2993288Losses:  4.546123504638672 0.20866045355796814
CurrentTrain: epoch  2, batch    51 | loss: 4.7547841Losses:  4.888917922973633 0.39871057868003845
CurrentTrain: epoch  2, batch    52 | loss: 5.2876287Losses:  4.388835906982422 0.33764612674713135
CurrentTrain: epoch  2, batch    53 | loss: 4.7264819Losses:  4.447933673858643 0.27578604221343994
CurrentTrain: epoch  2, batch    54 | loss: 4.7237196Losses:  4.3365020751953125 0.19200024008750916
CurrentTrain: epoch  2, batch    55 | loss: 4.5285025Losses:  4.7471160888671875 0.3250170946121216
CurrentTrain: epoch  2, batch    56 | loss: 5.0721331Losses:  4.444359302520752 0.24476468563079834
CurrentTrain: epoch  2, batch    57 | loss: 4.6891241Losses:  4.483516693115234 0.3246925473213196
CurrentTrain: epoch  2, batch    58 | loss: 4.8082094Losses:  4.1952924728393555 0.18585175275802612
CurrentTrain: epoch  2, batch    59 | loss: 4.3811440Losses:  4.386784553527832 0.25392240285873413
CurrentTrain: epoch  2, batch    60 | loss: 4.6407070Losses:  4.646201133728027 0.3836679756641388
CurrentTrain: epoch  2, batch    61 | loss: 5.0298691Losses:  4.792436122894287 0.24750736355781555
CurrentTrain: epoch  2, batch    62 | loss: 5.0399437Losses:  4.605404853820801 0.27094268798828125
CurrentTrain: epoch  3, batch     0 | loss: 4.8763475Losses:  4.287166595458984 0.18654939532279968
CurrentTrain: epoch  3, batch     1 | loss: 4.4737158Losses:  4.230738639831543 0.17382141947746277
CurrentTrain: epoch  3, batch     2 | loss: 4.4045601Losses:  4.499067783355713 0.20976963639259338
CurrentTrain: epoch  3, batch     3 | loss: 4.7088375Losses:  4.4921088218688965 0.3289449214935303
CurrentTrain: epoch  3, batch     4 | loss: 4.8210535Losses:  4.54588508605957 0.25844207406044006
CurrentTrain: epoch  3, batch     5 | loss: 4.8043270Losses:  4.277154445648193 0.22826190292835236
CurrentTrain: epoch  3, batch     6 | loss: 4.5054164Losses:  4.513711929321289 0.22662019729614258
CurrentTrain: epoch  3, batch     7 | loss: 4.7403321Losses:  4.660507678985596 0.21500715613365173
CurrentTrain: epoch  3, batch     8 | loss: 4.8755150Losses:  4.493958473205566 0.20321035385131836
CurrentTrain: epoch  3, batch     9 | loss: 4.6971688Losses:  4.291073322296143 0.28588348627090454
CurrentTrain: epoch  3, batch    10 | loss: 4.5769567Losses:  4.596409797668457 0.2964510917663574
CurrentTrain: epoch  3, batch    11 | loss: 4.8928609Losses:  4.506311893463135 0.3246873617172241
CurrentTrain: epoch  3, batch    12 | loss: 4.8309994Losses:  4.254663467407227 0.2484251707792282
CurrentTrain: epoch  3, batch    13 | loss: 4.5030885Losses:  4.319314002990723 0.21256574988365173
CurrentTrain: epoch  3, batch    14 | loss: 4.5318799Losses:  4.2408833503723145 0.18353740870952606
CurrentTrain: epoch  3, batch    15 | loss: 4.4244208Losses:  4.264374256134033 0.22668525576591492
CurrentTrain: epoch  3, batch    16 | loss: 4.4910593Losses:  4.30409049987793 0.16199661791324615
CurrentTrain: epoch  3, batch    17 | loss: 4.4660873Losses:  4.357219696044922 0.1989293098449707
CurrentTrain: epoch  3, batch    18 | loss: 4.5561490Losses:  4.249715805053711 0.24221494793891907
CurrentTrain: epoch  3, batch    19 | loss: 4.4919310Losses:  4.301186561584473 0.24874547123908997
CurrentTrain: epoch  3, batch    20 | loss: 4.5499320Losses:  4.4263105392456055 0.18870654702186584
CurrentTrain: epoch  3, batch    21 | loss: 4.6150169Losses:  4.230617046356201 0.20917311310768127
CurrentTrain: epoch  3, batch    22 | loss: 4.4397902Losses:  4.302044868469238 0.2272321581840515
CurrentTrain: epoch  3, batch    23 | loss: 4.5292768Losses:  4.267832279205322 0.2398214340209961
CurrentTrain: epoch  3, batch    24 | loss: 4.5076537Losses:  4.149169445037842 0.19473843276500702
CurrentTrain: epoch  3, batch    25 | loss: 4.3439078Losses:  4.24177360534668 0.18105703592300415
CurrentTrain: epoch  3, batch    26 | loss: 4.4228306Losses:  4.7888712882995605 0.3391808867454529
CurrentTrain: epoch  3, batch    27 | loss: 5.1280522Losses:  4.11149787902832 0.1595683991909027
CurrentTrain: epoch  3, batch    28 | loss: 4.2710662Losses:  4.302364349365234 0.21884965896606445
CurrentTrain: epoch  3, batch    29 | loss: 4.5212140Losses:  4.598084449768066 0.3010876774787903
CurrentTrain: epoch  3, batch    30 | loss: 4.8991723Losses:  4.167110443115234 0.17986205220222473
CurrentTrain: epoch  3, batch    31 | loss: 4.3469725Losses:  4.228235244750977 0.17208953201770782
CurrentTrain: epoch  3, batch    32 | loss: 4.4003248Losses:  4.568100929260254 0.21038644015789032
CurrentTrain: epoch  3, batch    33 | loss: 4.7784872Losses:  4.318565368652344 0.16315895318984985
CurrentTrain: epoch  3, batch    34 | loss: 4.4817243Losses:  4.452310562133789 0.19089755415916443
CurrentTrain: epoch  3, batch    35 | loss: 4.6432080Losses:  4.291162490844727 0.1440773606300354
CurrentTrain: epoch  3, batch    36 | loss: 4.4352398Losses:  4.137738227844238 0.181142657995224
CurrentTrain: epoch  3, batch    37 | loss: 4.3188810Losses:  4.144103050231934 0.1765798181295395
CurrentTrain: epoch  3, batch    38 | loss: 4.3206830Losses:  4.228224754333496 0.23966477811336517
CurrentTrain: epoch  3, batch    39 | loss: 4.4678893Losses:  4.24436092376709 0.21964457631111145
CurrentTrain: epoch  3, batch    40 | loss: 4.4640055Losses:  4.3187150955200195 0.21153393387794495
CurrentTrain: epoch  3, batch    41 | loss: 4.5302491Losses:  4.062442779541016 0.16818279027938843
CurrentTrain: epoch  3, batch    42 | loss: 4.2306256Losses:  4.127542018890381 0.15553396940231323
CurrentTrain: epoch  3, batch    43 | loss: 4.2830758Losses:  4.235808372497559 0.23911824822425842
CurrentTrain: epoch  3, batch    44 | loss: 4.4749265Losses:  4.19622278213501 0.21360260248184204
CurrentTrain: epoch  3, batch    45 | loss: 4.4098253Losses:  4.257589340209961 0.22450454533100128
CurrentTrain: epoch  3, batch    46 | loss: 4.4820938Losses:  4.558943271636963 0.3944835066795349
CurrentTrain: epoch  3, batch    47 | loss: 4.9534268Losses:  4.106854438781738 0.17705954611301422
CurrentTrain: epoch  3, batch    48 | loss: 4.2839141Losses:  4.174713134765625 0.15452703833580017
CurrentTrain: epoch  3, batch    49 | loss: 4.3292403Losses:  4.257503032684326 0.21456004679203033
CurrentTrain: epoch  3, batch    50 | loss: 4.4720631Losses:  4.1390380859375 0.15462633967399597
CurrentTrain: epoch  3, batch    51 | loss: 4.2936645Losses:  4.270261764526367 0.19473180174827576
CurrentTrain: epoch  3, batch    52 | loss: 4.4649935Losses:  4.151059150695801 0.16964960098266602
CurrentTrain: epoch  3, batch    53 | loss: 4.3207088Losses:  4.266360759735107 0.14816740155220032
CurrentTrain: epoch  3, batch    54 | loss: 4.4145284Losses:  4.148435592651367 0.15633311867713928
CurrentTrain: epoch  3, batch    55 | loss: 4.3047686Losses:  4.164534568786621 0.10960306972265244
CurrentTrain: epoch  3, batch    56 | loss: 4.2741375Losses:  4.2082319259643555 0.23422248661518097
CurrentTrain: epoch  3, batch    57 | loss: 4.4424543Losses:  4.118189811706543 0.19568182528018951
CurrentTrain: epoch  3, batch    58 | loss: 4.3138719Losses:  4.426611423492432 0.18820977210998535
CurrentTrain: epoch  3, batch    59 | loss: 4.6148214Losses:  4.898822784423828 0.3352508544921875
CurrentTrain: epoch  3, batch    60 | loss: 5.2340736Losses:  4.108473777770996 0.14457052946090698
CurrentTrain: epoch  3, batch    61 | loss: 4.2530441Losses:  4.178215980529785 0.12926889955997467
CurrentTrain: epoch  3, batch    62 | loss: 4.3074851Losses:  4.070840358734131 0.13242977857589722
CurrentTrain: epoch  4, batch     0 | loss: 4.2032700Losses:  4.131160736083984 0.1367788165807724
CurrentTrain: epoch  4, batch     1 | loss: 4.2679396Losses:  4.118050575256348 0.12976886332035065
CurrentTrain: epoch  4, batch     2 | loss: 4.2478194Losses:  4.816007614135742 0.2898402214050293
CurrentTrain: epoch  4, batch     3 | loss: 5.1058478Losses:  4.11883544921875 0.1769936978816986
CurrentTrain: epoch  4, batch     4 | loss: 4.2958293Losses:  4.425063133239746 0.20290783047676086
CurrentTrain: epoch  4, batch     5 | loss: 4.6279712Losses:  4.324575901031494 0.17988872528076172
CurrentTrain: epoch  4, batch     6 | loss: 4.5044646Losses:  4.0755510330200195 0.1309155821800232
CurrentTrain: epoch  4, batch     7 | loss: 4.2064667Losses:  4.280373573303223 0.18496762216091156
CurrentTrain: epoch  4, batch     8 | loss: 4.4653411Losses:  4.353568077087402 0.14686474204063416
CurrentTrain: epoch  4, batch     9 | loss: 4.5004330Losses:  4.21504545211792 0.19684740900993347
CurrentTrain: epoch  4, batch    10 | loss: 4.4118929Losses:  4.189202308654785 0.162904292345047
CurrentTrain: epoch  4, batch    11 | loss: 4.3521066Losses:  4.099465847015381 0.16115397214889526
CurrentTrain: epoch  4, batch    12 | loss: 4.2606196Losses:  4.178889274597168 0.17858555912971497
CurrentTrain: epoch  4, batch    13 | loss: 4.3574748Losses:  4.120545864105225 0.19573143124580383
CurrentTrain: epoch  4, batch    14 | loss: 4.3162775Losses:  4.095934867858887 0.13712580502033234
CurrentTrain: epoch  4, batch    15 | loss: 4.2330608Losses:  4.253600597381592 0.12826642394065857
CurrentTrain: epoch  4, batch    16 | loss: 4.3818669Losses:  4.2523674964904785 0.15368390083312988
CurrentTrain: epoch  4, batch    17 | loss: 4.4060516Losses:  4.014376640319824 0.1285053789615631
CurrentTrain: epoch  4, batch    18 | loss: 4.1428819Losses:  4.074499130249023 0.1362748146057129
CurrentTrain: epoch  4, batch    19 | loss: 4.2107739Losses:  4.21003532409668 0.15058565139770508
CurrentTrain: epoch  4, batch    20 | loss: 4.3606210Losses:  4.120260238647461 0.16374574601650238
CurrentTrain: epoch  4, batch    21 | loss: 4.2840061Losses:  4.097925662994385 0.16748952865600586
CurrentTrain: epoch  4, batch    22 | loss: 4.2654152Losses:  4.180840015411377 0.12513422966003418
CurrentTrain: epoch  4, batch    23 | loss: 4.3059740Losses:  4.034547805786133 0.17187203466892242
CurrentTrain: epoch  4, batch    24 | loss: 4.2064199Losses:  4.048460483551025 0.11126403510570526
CurrentTrain: epoch  4, batch    25 | loss: 4.1597247Losses:  4.555447578430176 0.27601850032806396
CurrentTrain: epoch  4, batch    26 | loss: 4.8314662Losses:  4.14424467086792 0.13035668432712555
CurrentTrain: epoch  4, batch    27 | loss: 4.2746015Losses:  4.3146796226501465 0.1341758370399475
CurrentTrain: epoch  4, batch    28 | loss: 4.4488554Losses:  4.2798051834106445 0.1601833999156952
CurrentTrain: epoch  4, batch    29 | loss: 4.4399886Losses:  4.1193013191223145 0.15147030353546143
CurrentTrain: epoch  4, batch    30 | loss: 4.2707715Losses:  4.282648086547852 0.17500877380371094
CurrentTrain: epoch  4, batch    31 | loss: 4.4576569Losses:  4.198518753051758 0.1600465625524521
CurrentTrain: epoch  4, batch    32 | loss: 4.3585653Losses:  4.143851280212402 0.18346017599105835
CurrentTrain: epoch  4, batch    33 | loss: 4.3273115Losses:  4.134503364562988 0.13824686408042908
CurrentTrain: epoch  4, batch    34 | loss: 4.2727504Losses:  4.082033157348633 0.1636035293340683
CurrentTrain: epoch  4, batch    35 | loss: 4.2456365Losses:  4.088237762451172 0.08975173532962799
CurrentTrain: epoch  4, batch    36 | loss: 4.1779895Losses:  4.034584045410156 0.11165677011013031
CurrentTrain: epoch  4, batch    37 | loss: 4.1462407Losses:  4.137053966522217 0.16368937492370605
CurrentTrain: epoch  4, batch    38 | loss: 4.3007431Losses:  4.205921649932861 0.1434181034564972
CurrentTrain: epoch  4, batch    39 | loss: 4.3493400Losses:  4.357111930847168 0.1919512152671814
CurrentTrain: epoch  4, batch    40 | loss: 4.5490632Losses:  4.0836501121521 0.08899049460887909
CurrentTrain: epoch  4, batch    41 | loss: 4.1726408Losses:  4.087656021118164 0.11551906168460846
CurrentTrain: epoch  4, batch    42 | loss: 4.2031751Losses:  4.180393218994141 0.16990439593791962
CurrentTrain: epoch  4, batch    43 | loss: 4.3502975Losses:  4.227596282958984 0.13822683691978455
CurrentTrain: epoch  4, batch    44 | loss: 4.3658233Losses:  4.0703535079956055 0.1669272780418396
CurrentTrain: epoch  4, batch    45 | loss: 4.2372808Losses:  4.074139595031738 0.16151148080825806
CurrentTrain: epoch  4, batch    46 | loss: 4.2356510Losses:  4.055741310119629 0.16509124636650085
CurrentTrain: epoch  4, batch    47 | loss: 4.2208323Losses:  4.012063026428223 0.13601645827293396
CurrentTrain: epoch  4, batch    48 | loss: 4.1480794Losses:  4.0348100662231445 0.11302107572555542
CurrentTrain: epoch  4, batch    49 | loss: 4.1478310Losses:  4.120502948760986 0.1246713250875473
CurrentTrain: epoch  4, batch    50 | loss: 4.2451744Losses:  4.136660575866699 0.15432478487491608
CurrentTrain: epoch  4, batch    51 | loss: 4.2909856Losses:  4.185962677001953 0.17624157667160034
CurrentTrain: epoch  4, batch    52 | loss: 4.3622041Losses:  4.174952507019043 0.10438549518585205
CurrentTrain: epoch  4, batch    53 | loss: 4.2793379Losses:  4.079236030578613 0.13461369276046753
CurrentTrain: epoch  4, batch    54 | loss: 4.2138495Losses:  4.118078708648682 0.15789809823036194
CurrentTrain: epoch  4, batch    55 | loss: 4.2759767Losses:  4.009548664093018 0.13909831643104553
CurrentTrain: epoch  4, batch    56 | loss: 4.1486468Losses:  4.0934600830078125 0.11023712903261185
CurrentTrain: epoch  4, batch    57 | loss: 4.2036972Losses:  4.082026481628418 0.1094948947429657
CurrentTrain: epoch  4, batch    58 | loss: 4.1915212Losses:  3.9970028400421143 0.10775503516197205
CurrentTrain: epoch  4, batch    59 | loss: 4.1047578Losses:  4.0544352531433105 0.15098489820957184
CurrentTrain: epoch  4, batch    60 | loss: 4.2054200Losses:  4.035175323486328 0.1546526402235031
CurrentTrain: epoch  4, batch    61 | loss: 4.1898279Losses:  4.619253158569336 0.34888172149658203
CurrentTrain: epoch  4, batch    62 | loss: 4.9681349Losses:  4.042291164398193 0.1028178408741951
CurrentTrain: epoch  5, batch     0 | loss: 4.1451092Losses:  4.658703804016113 0.2420574128627777
CurrentTrain: epoch  5, batch     1 | loss: 4.9007611Losses:  4.262432098388672 0.11191032826900482
CurrentTrain: epoch  5, batch     2 | loss: 4.3743424Losses:  3.951228380203247 0.12533435225486755
CurrentTrain: epoch  5, batch     3 | loss: 4.0765629Losses:  3.9503707885742188 0.12720927596092224
CurrentTrain: epoch  5, batch     4 | loss: 4.0775800Losses:  4.131021022796631 0.19365045428276062
CurrentTrain: epoch  5, batch     5 | loss: 4.3246713Losses:  4.018341064453125 0.13137754797935486
CurrentTrain: epoch  5, batch     6 | loss: 4.1497188Losses:  4.099693298339844 0.1769847869873047
CurrentTrain: epoch  5, batch     7 | loss: 4.2766781Losses:  4.042849540710449 0.15531134605407715
CurrentTrain: epoch  5, batch     8 | loss: 4.1981611Losses:  4.169071674346924 0.1129598543047905
CurrentTrain: epoch  5, batch     9 | loss: 4.2820315Losses:  4.027026176452637 0.10206391662359238
CurrentTrain: epoch  5, batch    10 | loss: 4.1290903Losses:  4.054806709289551 0.14869514107704163
CurrentTrain: epoch  5, batch    11 | loss: 4.2035017Losses:  4.00438117980957 0.15197385847568512
CurrentTrain: epoch  5, batch    12 | loss: 4.1563549Losses:  4.113940238952637 0.14745497703552246
CurrentTrain: epoch  5, batch    13 | loss: 4.2613955Losses:  4.0190629959106445 0.154184490442276
CurrentTrain: epoch  5, batch    14 | loss: 4.1732473Losses:  4.116063117980957 0.16534657776355743
CurrentTrain: epoch  5, batch    15 | loss: 4.2814097Losses:  4.046924591064453 0.16918930411338806
CurrentTrain: epoch  5, batch    16 | loss: 4.2161140Losses:  4.114773750305176 0.13081808388233185
CurrentTrain: epoch  5, batch    17 | loss: 4.2455916Losses:  4.05772066116333 0.08678959310054779
CurrentTrain: epoch  5, batch    18 | loss: 4.1445103Losses:  4.00034761428833 0.11300409585237503
CurrentTrain: epoch  5, batch    19 | loss: 4.1133518Losses:  4.044677257537842 0.13618820905685425
CurrentTrain: epoch  5, batch    20 | loss: 4.1808653Losses:  4.024538040161133 0.11939524114131927
CurrentTrain: epoch  5, batch    21 | loss: 4.1439333Losses:  4.130266189575195 0.113447405397892
CurrentTrain: epoch  5, batch    22 | loss: 4.2437134Losses:  4.059916973114014 0.12508973479270935
CurrentTrain: epoch  5, batch    23 | loss: 4.1850066Losses:  4.039057731628418 0.13310794532299042
CurrentTrain: epoch  5, batch    24 | loss: 4.1721659Losses:  4.092536926269531 0.1274988353252411
CurrentTrain: epoch  5, batch    25 | loss: 4.2200356Losses:  4.037618637084961 0.14839015901088715
CurrentTrain: epoch  5, batch    26 | loss: 4.1860089Losses:  3.991464614868164 0.11104965955018997
CurrentTrain: epoch  5, batch    27 | loss: 4.1025143Losses:  4.0589599609375 0.10018882155418396
CurrentTrain: epoch  5, batch    28 | loss: 4.1591487Losses:  4.0263519287109375 0.10497888922691345
CurrentTrain: epoch  5, batch    29 | loss: 4.1313310Losses:  4.130913734436035 0.12931737303733826
CurrentTrain: epoch  5, batch    30 | loss: 4.2602310Losses:  4.0622358322143555 0.13451257348060608
CurrentTrain: epoch  5, batch    31 | loss: 4.1967483Losses:  4.052844047546387 0.1045500785112381
CurrentTrain: epoch  5, batch    32 | loss: 4.1573939Losses:  4.035907745361328 0.10107867419719696
CurrentTrain: epoch  5, batch    33 | loss: 4.1369863Losses:  3.9661049842834473 0.11284331977367401
CurrentTrain: epoch  5, batch    34 | loss: 4.0789485Losses:  4.0367560386657715 0.13396380841732025
CurrentTrain: epoch  5, batch    35 | loss: 4.1707196Losses:  4.085973739624023 0.16981583833694458
CurrentTrain: epoch  5, batch    36 | loss: 4.2557898Losses:  3.9716014862060547 0.10862436890602112
CurrentTrain: epoch  5, batch    37 | loss: 4.0802259Losses:  4.108811378479004 0.12640683352947235
CurrentTrain: epoch  5, batch    38 | loss: 4.2352180Losses:  4.01893424987793 0.09580472856760025
CurrentTrain: epoch  5, batch    39 | loss: 4.1147389Losses:  4.024635314941406 0.1256190836429596
CurrentTrain: epoch  5, batch    40 | loss: 4.1502542Losses:  3.9913227558135986 0.12873081862926483
CurrentTrain: epoch  5, batch    41 | loss: 4.1200538Losses:  4.040195465087891 0.1502046287059784
CurrentTrain: epoch  5, batch    42 | loss: 4.1904001Losses:  3.9657301902770996 0.09892752021551132
CurrentTrain: epoch  5, batch    43 | loss: 4.0646577Losses:  4.003878593444824 0.11251237988471985
CurrentTrain: epoch  5, batch    44 | loss: 4.1163912Losses:  4.06620454788208 0.10050777345895767
CurrentTrain: epoch  5, batch    45 | loss: 4.1667123Losses:  4.009645462036133 0.10048706829547882
CurrentTrain: epoch  5, batch    46 | loss: 4.1101327Losses:  4.0399861335754395 0.11218277364969254
CurrentTrain: epoch  5, batch    47 | loss: 4.1521688Losses:  3.983654022216797 0.1015276312828064
CurrentTrain: epoch  5, batch    48 | loss: 4.0851817Losses:  4.033949851989746 0.14406563341617584
CurrentTrain: epoch  5, batch    49 | loss: 4.1780157Losses:  4.2745771408081055 0.24238377809524536
CurrentTrain: epoch  5, batch    50 | loss: 4.5169611Losses:  3.974911689758301 0.0897127240896225
CurrentTrain: epoch  5, batch    51 | loss: 4.0646243Losses:  4.07297420501709 0.09636132419109344
CurrentTrain: epoch  5, batch    52 | loss: 4.1693354Losses:  4.145927429199219 0.09853899478912354
CurrentTrain: epoch  5, batch    53 | loss: 4.2444663Losses:  3.977031707763672 0.10630305111408234
CurrentTrain: epoch  5, batch    54 | loss: 4.0833349Losses:  4.020256519317627 0.10929596424102783
CurrentTrain: epoch  5, batch    55 | loss: 4.1295524Losses:  3.9850716590881348 0.12816789746284485
CurrentTrain: epoch  5, batch    56 | loss: 4.1132398Losses:  4.0234150886535645 0.09849458932876587
CurrentTrain: epoch  5, batch    57 | loss: 4.1219096Losses:  4.079562664031982 0.12284596264362335
CurrentTrain: epoch  5, batch    58 | loss: 4.2024088Losses:  4.044309139251709 0.13727670907974243
CurrentTrain: epoch  5, batch    59 | loss: 4.1815858Losses:  3.9916298389434814 0.11723410338163376
CurrentTrain: epoch  5, batch    60 | loss: 4.1088638Losses:  3.972537040710449 0.08711674064397812
CurrentTrain: epoch  5, batch    61 | loss: 4.0596538Losses:  3.990168809890747 0.058173760771751404
CurrentTrain: epoch  5, batch    62 | loss: 4.0483427Losses:  4.003887176513672 0.10224540531635284
CurrentTrain: epoch  6, batch     0 | loss: 4.1061325Losses:  3.99507212638855 0.06334561854600906
CurrentTrain: epoch  6, batch     1 | loss: 4.0584178Losses:  3.97135853767395 0.11316892504692078
CurrentTrain: epoch  6, batch     2 | loss: 4.0845275Losses:  4.033614158630371 0.1058538407087326
CurrentTrain: epoch  6, batch     3 | loss: 4.1394682Losses:  3.9715700149536133 0.10603021830320358
CurrentTrain: epoch  6, batch     4 | loss: 4.0776000Losses:  3.992471218109131 0.10770367085933685
CurrentTrain: epoch  6, batch     5 | loss: 4.1001749Losses:  4.047174453735352 0.0940237045288086
CurrentTrain: epoch  6, batch     6 | loss: 4.1411982Losses:  3.99035382270813 0.11040076613426208
CurrentTrain: epoch  6, batch     7 | loss: 4.1007547Losses:  3.984915256500244 0.09881775081157684
CurrentTrain: epoch  6, batch     8 | loss: 4.0837331Losses:  4.047456741333008 0.11268678307533264
CurrentTrain: epoch  6, batch     9 | loss: 4.1601434Losses:  3.9855194091796875 0.12181852757930756
CurrentTrain: epoch  6, batch    10 | loss: 4.1073380Losses:  4.08895206451416 0.11715354025363922
CurrentTrain: epoch  6, batch    11 | loss: 4.2061057Losses:  4.141889572143555 0.12702566385269165
CurrentTrain: epoch  6, batch    12 | loss: 4.2689152Losses:  3.9342823028564453 0.10259923338890076
CurrentTrain: epoch  6, batch    13 | loss: 4.0368814Losses:  3.9635024070739746 0.12368020415306091
CurrentTrain: epoch  6, batch    14 | loss: 4.0871825Losses:  3.9858546257019043 0.08994875848293304
CurrentTrain: epoch  6, batch    15 | loss: 4.0758033Losses:  3.980846405029297 0.11025238037109375
CurrentTrain: epoch  6, batch    16 | loss: 4.0910988Losses:  3.982572317123413 0.11443044990301132
CurrentTrain: epoch  6, batch    17 | loss: 4.0970030Losses:  3.9910988807678223 0.0753232091665268
CurrentTrain: epoch  6, batch    18 | loss: 4.0664220Losses:  3.992114543914795 0.10103112459182739
CurrentTrain: epoch  6, batch    19 | loss: 4.0931458Losses:  3.959747314453125 0.09056126326322556
CurrentTrain: epoch  6, batch    20 | loss: 4.0503087Losses:  3.986340045928955 0.11967570334672928
CurrentTrain: epoch  6, batch    21 | loss: 4.1060157Losses:  3.961190700531006 0.1256415694952011
CurrentTrain: epoch  6, batch    22 | loss: 4.0868320Losses:  3.983635663986206 0.08736267685890198
CurrentTrain: epoch  6, batch    23 | loss: 4.0709982Losses:  3.936948776245117 0.09143973141908646
CurrentTrain: epoch  6, batch    24 | loss: 4.0283885Losses:  4.011672019958496 0.09121406078338623
CurrentTrain: epoch  6, batch    25 | loss: 4.1028862Losses:  4.017305374145508 0.12063208222389221
CurrentTrain: epoch  6, batch    26 | loss: 4.1379375Losses:  3.905552864074707 0.06977489590644836
CurrentTrain: epoch  6, batch    27 | loss: 3.9753277Losses:  4.032068729400635 0.13245293498039246
CurrentTrain: epoch  6, batch    28 | loss: 4.1645217Losses:  3.979247570037842 0.06312433630228043
CurrentTrain: epoch  6, batch    29 | loss: 4.0423717Losses:  3.9712493419647217 0.09910539537668228
CurrentTrain: epoch  6, batch    30 | loss: 4.0703549Losses:  3.959239959716797 0.10599535703659058
CurrentTrain: epoch  6, batch    31 | loss: 4.0652351Losses:  3.9871490001678467 0.08079873770475388
CurrentTrain: epoch  6, batch    32 | loss: 4.0679479Losses:  3.964773654937744 0.08356818556785583
CurrentTrain: epoch  6, batch    33 | loss: 4.0483418Losses:  3.9767141342163086 0.09968417137861252
CurrentTrain: epoch  6, batch    34 | loss: 4.0763984Losses:  4.102895259857178 0.13400904834270477
CurrentTrain: epoch  6, batch    35 | loss: 4.2369041Losses:  3.9694249629974365 0.09762735664844513
CurrentTrain: epoch  6, batch    36 | loss: 4.0670524Losses:  3.968629837036133 0.0846831351518631
CurrentTrain: epoch  6, batch    37 | loss: 4.0533128Losses:  3.93966007232666 0.10701178014278412
CurrentTrain: epoch  6, batch    38 | loss: 4.0466719Losses:  3.9959893226623535 0.11789826303720474
CurrentTrain: epoch  6, batch    39 | loss: 4.1138878Losses:  3.956796646118164 0.09662202000617981
CurrentTrain: epoch  6, batch    40 | loss: 4.0534186Losses:  3.9564099311828613 0.1054697036743164
CurrentTrain: epoch  6, batch    41 | loss: 4.0618796Losses:  3.978269100189209 0.11225512623786926
CurrentTrain: epoch  6, batch    42 | loss: 4.0905242Losses:  3.983790874481201 0.11211243271827698
CurrentTrain: epoch  6, batch    43 | loss: 4.0959034Losses:  3.9644927978515625 0.08060543984174728
CurrentTrain: epoch  6, batch    44 | loss: 4.0450983Losses:  3.993272304534912 0.08746857941150665
CurrentTrain: epoch  6, batch    45 | loss: 4.0807409Losses:  3.9524123668670654 0.11973349750041962
CurrentTrain: epoch  6, batch    46 | loss: 4.0721459Losses:  3.9684510231018066 0.07726079225540161
CurrentTrain: epoch  6, batch    47 | loss: 4.0457120Losses:  3.9793026447296143 0.10257522761821747
CurrentTrain: epoch  6, batch    48 | loss: 4.0818777Losses:  3.935645818710327 0.09454609453678131
CurrentTrain: epoch  6, batch    49 | loss: 4.0301919Losses:  4.007550239562988 0.059401530772447586
CurrentTrain: epoch  6, batch    50 | loss: 4.0669518Losses:  3.924086093902588 0.0878358781337738
CurrentTrain: epoch  6, batch    51 | loss: 4.0119219Losses:  3.9550185203552246 0.08404742181301117
CurrentTrain: epoch  6, batch    52 | loss: 4.0390658Losses:  3.958332061767578 0.08446633815765381
CurrentTrain: epoch  6, batch    53 | loss: 4.0427985Losses:  3.9702653884887695 0.09234798699617386
CurrentTrain: epoch  6, batch    54 | loss: 4.0626135Losses:  3.935532569885254 0.09852667897939682
CurrentTrain: epoch  6, batch    55 | loss: 4.0340590Losses:  3.957371711730957 0.09844011813402176
CurrentTrain: epoch  6, batch    56 | loss: 4.0558119Losses:  4.0012617111206055 0.08273203670978546
CurrentTrain: epoch  6, batch    57 | loss: 4.0839939Losses:  3.964344024658203 0.08257782459259033
CurrentTrain: epoch  6, batch    58 | loss: 4.0469217Losses:  3.979764938354492 0.07190965116024017
CurrentTrain: epoch  6, batch    59 | loss: 4.0516744Losses:  3.9689457416534424 0.08667302131652832
CurrentTrain: epoch  6, batch    60 | loss: 4.0556188Losses:  3.9636576175689697 0.10640875995159149
CurrentTrain: epoch  6, batch    61 | loss: 4.0700665Losses:  3.964334487915039 0.057855281978845596
CurrentTrain: epoch  6, batch    62 | loss: 4.0221896Losses:  3.9818568229675293 0.10176153481006622
CurrentTrain: epoch  7, batch     0 | loss: 4.0836182Losses:  3.9092791080474854 0.08764145523309708
CurrentTrain: epoch  7, batch     1 | loss: 3.9969206Losses:  3.9693856239318848 0.07383273541927338
CurrentTrain: epoch  7, batch     2 | loss: 4.0432181Losses:  3.983891010284424 0.09561974555253983
CurrentTrain: epoch  7, batch     3 | loss: 4.0795107Losses:  3.9840216636657715 0.09830756485462189
CurrentTrain: epoch  7, batch     4 | loss: 4.0823293Losses:  3.9753406047821045 0.0950460433959961
CurrentTrain: epoch  7, batch     5 | loss: 4.0703869Losses:  3.9654831886291504 0.08207739144563675
CurrentTrain: epoch  7, batch     6 | loss: 4.0475607Losses:  3.968348503112793 0.09538285434246063
CurrentTrain: epoch  7, batch     7 | loss: 4.0637312Losses:  3.9888756275177 0.103753462433815
CurrentTrain: epoch  7, batch     8 | loss: 4.0926290Losses:  3.973175048828125 0.07575158029794693
CurrentTrain: epoch  7, batch     9 | loss: 4.0489268Losses:  3.981100559234619 0.09564733505249023
CurrentTrain: epoch  7, batch    10 | loss: 4.0767479Losses:  3.9200594425201416 0.08176618069410324
CurrentTrain: epoch  7, batch    11 | loss: 4.0018258Losses:  3.930950164794922 0.09075155109167099
CurrentTrain: epoch  7, batch    12 | loss: 4.0217018Losses:  3.9608154296875 0.09527631103992462
CurrentTrain: epoch  7, batch    13 | loss: 4.0560918Losses:  3.947073459625244 0.07132234424352646
CurrentTrain: epoch  7, batch    14 | loss: 4.0183959Losses:  3.988980293273926 0.09305156767368317
CurrentTrain: epoch  7, batch    15 | loss: 4.0820317Losses:  3.9521708488464355 0.08188530802726746
CurrentTrain: epoch  7, batch    16 | loss: 4.0340562Losses:  4.008028030395508 0.10645179450511932
CurrentTrain: epoch  7, batch    17 | loss: 4.1144800Losses:  3.970460891723633 0.0895199403166771
CurrentTrain: epoch  7, batch    18 | loss: 4.0599809Losses:  3.9697933197021484 0.1024036854505539
CurrentTrain: epoch  7, batch    19 | loss: 4.0721970Losses:  3.9443421363830566 0.07508352398872375
CurrentTrain: epoch  7, batch    20 | loss: 4.0194259Losses:  3.9784581661224365 0.07963445782661438
CurrentTrain: epoch  7, batch    21 | loss: 4.0580926Losses:  3.937655210494995 0.1008366048336029
CurrentTrain: epoch  7, batch    22 | loss: 4.0384917Losses:  4.008389472961426 0.08435270190238953
CurrentTrain: epoch  7, batch    23 | loss: 4.0927420Losses:  3.9662530422210693 0.06257133185863495
CurrentTrain: epoch  7, batch    24 | loss: 4.0288243Losses:  3.989129066467285 0.07079970836639404
CurrentTrain: epoch  7, batch    25 | loss: 4.0599289Losses:  3.939401149749756 0.07152076065540314
CurrentTrain: epoch  7, batch    26 | loss: 4.0109220Losses:  3.9819211959838867 0.10143744945526123
CurrentTrain: epoch  7, batch    27 | loss: 4.0833588Losses:  3.945305109024048 0.0852472186088562
CurrentTrain: epoch  7, batch    28 | loss: 4.0305524Losses:  3.9690895080566406 0.09871108084917068
CurrentTrain: epoch  7, batch    29 | loss: 4.0678005Losses:  3.974660873413086 0.08235539495944977
CurrentTrain: epoch  7, batch    30 | loss: 4.0570164Losses:  3.925611734390259 0.08947694301605225
CurrentTrain: epoch  7, batch    31 | loss: 4.0150886Losses:  3.974308490753174 0.08010973781347275
CurrentTrain: epoch  7, batch    32 | loss: 4.0544181Losses:  3.9602749347686768 0.07143422216176987
CurrentTrain: epoch  7, batch    33 | loss: 4.0317092Losses:  4.005929946899414 0.08546328544616699
CurrentTrain: epoch  7, batch    34 | loss: 4.0913935Losses:  3.964031219482422 0.10838164389133453
CurrentTrain: epoch  7, batch    35 | loss: 4.0724130Losses:  3.9531090259552 0.08480483293533325
CurrentTrain: epoch  7, batch    36 | loss: 4.0379138Losses:  4.0300211906433105 0.08336260169744492
CurrentTrain: epoch  7, batch    37 | loss: 4.1133838Losses:  3.9678635597229004 0.0947219580411911
CurrentTrain: epoch  7, batch    38 | loss: 4.0625854Losses:  3.9629178047180176 0.08134393393993378
CurrentTrain: epoch  7, batch    39 | loss: 4.0442619Losses:  3.951295852661133 0.08758280426263809
CurrentTrain: epoch  7, batch    40 | loss: 4.0388784Losses:  3.942795991897583 0.06585481762886047
CurrentTrain: epoch  7, batch    41 | loss: 4.0086508Losses:  3.9635679721832275 0.07526672631502151
CurrentTrain: epoch  7, batch    42 | loss: 4.0388346Losses:  3.943948745727539 0.09393060952425003
CurrentTrain: epoch  7, batch    43 | loss: 4.0378795Losses:  3.974146604537964 0.0717487707734108
CurrentTrain: epoch  7, batch    44 | loss: 4.0458956Losses:  3.9247264862060547 0.08001397550106049
CurrentTrain: epoch  7, batch    45 | loss: 4.0047402Losses:  3.9384605884552 0.07780706882476807
CurrentTrain: epoch  7, batch    46 | loss: 4.0162678Losses:  3.9573724269866943 0.0660475492477417
CurrentTrain: epoch  7, batch    47 | loss: 4.0234199Losses:  4.000970840454102 0.05158475041389465
CurrentTrain: epoch  7, batch    48 | loss: 4.0525556Losses:  3.9634690284729004 0.0820140689611435
CurrentTrain: epoch  7, batch    49 | loss: 4.0454831Losses:  3.980527400970459 0.08142559975385666
CurrentTrain: epoch  7, batch    50 | loss: 4.0619531Losses:  3.929530382156372 0.054081905633211136
CurrentTrain: epoch  7, batch    51 | loss: 3.9836123Losses:  3.9551949501037598 0.07201121002435684
CurrentTrain: epoch  7, batch    52 | loss: 4.0272059Losses:  3.9037506580352783 0.07593394815921783
CurrentTrain: epoch  7, batch    53 | loss: 3.9796846Losses:  3.9535951614379883 0.09659069776535034
CurrentTrain: epoch  7, batch    54 | loss: 4.0501857Losses:  3.946538209915161 0.08384254574775696
CurrentTrain: epoch  7, batch    55 | loss: 4.0303807Losses:  3.942786693572998 0.08539369702339172
CurrentTrain: epoch  7, batch    56 | loss: 4.0281806Losses:  3.9686713218688965 0.08234280347824097
CurrentTrain: epoch  7, batch    57 | loss: 4.0510139Losses:  3.930525779724121 0.07418088614940643
CurrentTrain: epoch  7, batch    58 | loss: 4.0047069Losses:  3.9928016662597656 0.06249875947833061
CurrentTrain: epoch  7, batch    59 | loss: 4.0553002Losses:  3.94759464263916 0.08654989302158356
CurrentTrain: epoch  7, batch    60 | loss: 4.0341444Losses:  3.8851141929626465 0.06544721126556396
CurrentTrain: epoch  7, batch    61 | loss: 3.9505615Losses:  3.9431214332580566 0.05601213872432709
CurrentTrain: epoch  7, batch    62 | loss: 3.9991336Losses:  3.9597179889678955 0.07056372612714767
CurrentTrain: epoch  8, batch     0 | loss: 4.0302815Losses:  3.9377293586730957 0.0689188688993454
CurrentTrain: epoch  8, batch     1 | loss: 4.0066481Losses:  3.92368221282959 0.07763965427875519
CurrentTrain: epoch  8, batch     2 | loss: 4.0013218Losses:  3.9969749450683594 0.04718667268753052
CurrentTrain: epoch  8, batch     3 | loss: 4.0441618Losses:  3.9261314868927 0.05833028256893158
CurrentTrain: epoch  8, batch     4 | loss: 3.9844618Losses:  3.9695165157318115 0.06109368056058884
CurrentTrain: epoch  8, batch     5 | loss: 4.0306101Losses:  3.9812562465667725 0.116300567984581
CurrentTrain: epoch  8, batch     6 | loss: 4.0975566Losses:  3.9681344032287598 0.07550126314163208
CurrentTrain: epoch  8, batch     7 | loss: 4.0436358Losses:  3.9294629096984863 0.06889735162258148
CurrentTrain: epoch  8, batch     8 | loss: 3.9983602Losses:  3.9201858043670654 0.05690339580178261
CurrentTrain: epoch  8, batch     9 | loss: 3.9770892Losses:  3.9352095127105713 0.08131568133831024
CurrentTrain: epoch  8, batch    10 | loss: 4.0165253Losses:  4.033063888549805 0.07663074880838394
CurrentTrain: epoch  8, batch    11 | loss: 4.1096945Losses:  3.973390579223633 0.05486289784312248
CurrentTrain: epoch  8, batch    12 | loss: 4.0282536Losses:  3.926285743713379 0.09082266688346863
CurrentTrain: epoch  8, batch    13 | loss: 4.0171084Losses:  3.990964651107788 0.09842149913311005
CurrentTrain: epoch  8, batch    14 | loss: 4.0893860Losses:  3.9671239852905273 0.06573363393545151
CurrentTrain: epoch  8, batch    15 | loss: 4.0328574Losses:  3.9690165519714355 0.09002701938152313
CurrentTrain: epoch  8, batch    16 | loss: 4.0590434Losses:  3.9305543899536133 0.07922931015491486
CurrentTrain: epoch  8, batch    17 | loss: 4.0097837Losses:  3.9310555458068848 0.09014482796192169
CurrentTrain: epoch  8, batch    18 | loss: 4.0212002Losses:  3.928837776184082 0.07478243112564087
CurrentTrain: epoch  8, batch    19 | loss: 4.0036201Losses:  3.945512294769287 0.05504082888364792
CurrentTrain: epoch  8, batch    20 | loss: 4.0005531Losses:  3.9899346828460693 0.07547855377197266
CurrentTrain: epoch  8, batch    21 | loss: 4.0654135Losses:  3.9470036029815674 0.07383744418621063
CurrentTrain: epoch  8, batch    22 | loss: 4.0208411Losses:  3.9494242668151855 0.08652451634407043
CurrentTrain: epoch  8, batch    23 | loss: 4.0359488Losses:  3.941793918609619 0.05883949249982834
CurrentTrain: epoch  8, batch    24 | loss: 4.0006332Losses:  3.973595142364502 0.06288705766201019
CurrentTrain: epoch  8, batch    25 | loss: 4.0364823Losses:  3.9243435859680176 0.06878635287284851
CurrentTrain: epoch  8, batch    26 | loss: 3.9931300Losses:  3.9446754455566406 0.07880321145057678
CurrentTrain: epoch  8, batch    27 | loss: 4.0234785Losses:  3.9376325607299805 0.09368915855884552
CurrentTrain: epoch  8, batch    28 | loss: 4.0313215Losses:  3.9161758422851562 0.06442298740148544
CurrentTrain: epoch  8, batch    29 | loss: 3.9805989Losses:  3.9434051513671875 0.0645594596862793
CurrentTrain: epoch  8, batch    30 | loss: 4.0079646Losses:  3.9304771423339844 0.07053490728139877
CurrentTrain: epoch  8, batch    31 | loss: 4.0010118Losses:  3.9499239921569824 0.06947939842939377
CurrentTrain: epoch  8, batch    32 | loss: 4.0194035Losses:  3.9572410583496094 0.0702865868806839
CurrentTrain: epoch  8, batch    33 | loss: 4.0275278Losses:  3.9213078022003174 0.0752926766872406
CurrentTrain: epoch  8, batch    34 | loss: 3.9966004Losses:  3.952393054962158 0.09314824640750885
CurrentTrain: epoch  8, batch    35 | loss: 4.0455413Losses:  3.9925718307495117 0.07994221150875092
CurrentTrain: epoch  8, batch    36 | loss: 4.0725141Losses:  3.9758872985839844 0.07047976553440094
CurrentTrain: epoch  8, batch    37 | loss: 4.0463672Losses:  3.9294116497039795 0.08517797291278839
CurrentTrain: epoch  8, batch    38 | loss: 4.0145898Losses:  3.9829657077789307 0.07390390336513519
CurrentTrain: epoch  8, batch    39 | loss: 4.0568695Losses:  3.9605345726013184 0.04842612147331238
CurrentTrain: epoch  8, batch    40 | loss: 4.0089607Losses:  3.985341787338257 0.08806505799293518
CurrentTrain: epoch  8, batch    41 | loss: 4.0734067Losses:  3.958125591278076 0.08252215385437012
CurrentTrain: epoch  8, batch    42 | loss: 4.0406475Losses:  3.936877727508545 0.0625830888748169
CurrentTrain: epoch  8, batch    43 | loss: 3.9994607Losses:  3.9752707481384277 0.07782638072967529
CurrentTrain: epoch  8, batch    44 | loss: 4.0530972Losses:  3.9371864795684814 0.06479024142026901
CurrentTrain: epoch  8, batch    45 | loss: 4.0019765Losses:  3.947801351547241 0.05521757900714874
CurrentTrain: epoch  8, batch    46 | loss: 4.0030189Losses:  3.949434280395508 0.08347311615943909
CurrentTrain: epoch  8, batch    47 | loss: 4.0329075Losses:  3.894022226333618 0.056048423051834106
CurrentTrain: epoch  8, batch    48 | loss: 3.9500706Losses:  3.900345802307129 0.06926576048135757
CurrentTrain: epoch  8, batch    49 | loss: 3.9696116Losses:  3.9087343215942383 0.05558847263455391
CurrentTrain: epoch  8, batch    50 | loss: 3.9643228Losses:  3.891542434692383 0.06202350929379463
CurrentTrain: epoch  8, batch    51 | loss: 3.9535658Losses:  3.9295990467071533 0.06220530718564987
CurrentTrain: epoch  8, batch    52 | loss: 3.9918044Losses:  3.9344048500061035 0.07103578001260757
CurrentTrain: epoch  8, batch    53 | loss: 4.0054407Losses:  3.9651482105255127 0.05588102340698242
CurrentTrain: epoch  8, batch    54 | loss: 4.0210295Losses:  3.9948582649230957 0.07627830654382706
CurrentTrain: epoch  8, batch    55 | loss: 4.0711365Losses:  3.961884021759033 0.07619781792163849
CurrentTrain: epoch  8, batch    56 | loss: 4.0380816Losses:  3.9253673553466797 0.06796594709157944
CurrentTrain: epoch  8, batch    57 | loss: 3.9933333Losses:  3.935563087463379 0.0733298510313034
CurrentTrain: epoch  8, batch    58 | loss: 4.0088930Losses:  3.934386730194092 0.06879056245088577
CurrentTrain: epoch  8, batch    59 | loss: 4.0031772Losses:  3.9661359786987305 0.05831145495176315
CurrentTrain: epoch  8, batch    60 | loss: 4.0244474Losses:  3.9174399375915527 0.09400288760662079
CurrentTrain: epoch  8, batch    61 | loss: 4.0114427Losses:  3.9282946586608887 0.044185712933540344
CurrentTrain: epoch  8, batch    62 | loss: 3.9724803Losses:  3.867539405822754 0.03868303447961807
CurrentTrain: epoch  9, batch     0 | loss: 3.9062223Losses:  3.930492401123047 0.06205177307128906
CurrentTrain: epoch  9, batch     1 | loss: 3.9925442Losses:  3.940192699432373 0.06347693502902985
CurrentTrain: epoch  9, batch     2 | loss: 4.0036697Losses:  3.9637699127197266 0.07552340626716614
CurrentTrain: epoch  9, batch     3 | loss: 4.0392933Losses:  3.9587759971618652 0.06592042744159698
CurrentTrain: epoch  9, batch     4 | loss: 4.0246964Losses:  3.955223560333252 0.05783078819513321
CurrentTrain: epoch  9, batch     5 | loss: 4.0130544Losses:  3.9117932319641113 0.06913895905017853
CurrentTrain: epoch  9, batch     6 | loss: 3.9809322Losses:  3.978713274002075 0.07036255300045013
CurrentTrain: epoch  9, batch     7 | loss: 4.0490756Losses:  3.930426597595215 0.0609109029173851
CurrentTrain: epoch  9, batch     8 | loss: 3.9913375Losses:  3.969362258911133 0.07045124471187592
CurrentTrain: epoch  9, batch     9 | loss: 4.0398135Losses:  3.944589376449585 0.0685727596282959
CurrentTrain: epoch  9, batch    10 | loss: 4.0131621Losses:  3.946141004562378 0.06583984941244125
CurrentTrain: epoch  9, batch    11 | loss: 4.0119810Losses:  3.9461216926574707 0.0632539689540863
CurrentTrain: epoch  9, batch    12 | loss: 4.0093756Losses:  3.881978988647461 0.04152800142765045
CurrentTrain: epoch  9, batch    13 | loss: 3.9235070Losses:  3.938298225402832 0.03665771335363388
CurrentTrain: epoch  9, batch    14 | loss: 3.9749560Losses:  3.950613021850586 0.06552290916442871
CurrentTrain: epoch  9, batch    15 | loss: 4.0161362Losses:  3.953824043273926 0.07616519182920456
CurrentTrain: epoch  9, batch    16 | loss: 4.0299892Losses:  3.9340038299560547 0.06289694458246231
CurrentTrain: epoch  9, batch    17 | loss: 3.9969008Losses:  3.932438850402832 0.07035453617572784
CurrentTrain: epoch  9, batch    18 | loss: 4.0027933Losses:  3.971430778503418 0.07638613879680634
CurrentTrain: epoch  9, batch    19 | loss: 4.0478168Losses:  3.9739675521850586 0.07243721187114716
CurrentTrain: epoch  9, batch    20 | loss: 4.0464048Losses:  3.9630820751190186 0.04055345058441162
CurrentTrain: epoch  9, batch    21 | loss: 4.0036354Losses:  3.942870616912842 0.08260199427604675
CurrentTrain: epoch  9, batch    22 | loss: 4.0254726Losses:  3.960087776184082 0.05682292580604553
CurrentTrain: epoch  9, batch    23 | loss: 4.0169106Losses:  3.930842399597168 0.061886951327323914
CurrentTrain: epoch  9, batch    24 | loss: 3.9927294Losses:  3.9786856174468994 0.0544712133705616
CurrentTrain: epoch  9, batch    25 | loss: 4.0331569Losses:  3.9492135047912598 0.053001612424850464
CurrentTrain: epoch  9, batch    26 | loss: 4.0022149Losses:  3.925239324569702 0.05925433337688446
CurrentTrain: epoch  9, batch    27 | loss: 3.9844937Losses:  3.891652822494507 0.0551682747900486
CurrentTrain: epoch  9, batch    28 | loss: 3.9468212Losses:  3.9368581771850586 0.07138171792030334
CurrentTrain: epoch  9, batch    29 | loss: 4.0082397Losses:  3.9528894424438477 0.07830055803060532
CurrentTrain: epoch  9, batch    30 | loss: 4.0311899Losses:  3.94199800491333 0.06880180537700653
CurrentTrain: epoch  9, batch    31 | loss: 4.0107999Losses:  3.9528889656066895 0.043706297874450684
CurrentTrain: epoch  9, batch    32 | loss: 3.9965954Losses:  3.958400249481201 0.08161865919828415
CurrentTrain: epoch  9, batch    33 | loss: 4.0400190Losses:  3.9386720657348633 0.06523396819829941
CurrentTrain: epoch  9, batch    34 | loss: 4.0039062Losses:  3.9129528999328613 0.08127385377883911
CurrentTrain: epoch  9, batch    35 | loss: 3.9942267Losses:  3.958587884902954 0.04327470064163208
CurrentTrain: epoch  9, batch    36 | loss: 4.0018625Losses:  3.941513776779175 0.050215959548950195
CurrentTrain: epoch  9, batch    37 | loss: 3.9917297Losses:  3.9484424591064453 0.07711979746818542
CurrentTrain: epoch  9, batch    38 | loss: 4.0255623Losses:  3.9282803535461426 0.07073818892240524
CurrentTrain: epoch  9, batch    39 | loss: 3.9990184Losses:  3.8997039794921875 0.05256049335002899
CurrentTrain: epoch  9, batch    40 | loss: 3.9522645Losses:  3.9550864696502686 0.05917308107018471
CurrentTrain: epoch  9, batch    41 | loss: 4.0142593Losses:  3.9744441509246826 0.05061909928917885
CurrentTrain: epoch  9, batch    42 | loss: 4.0250630Losses:  3.950758218765259 0.06876936554908752
CurrentTrain: epoch  9, batch    43 | loss: 4.0195274Losses:  3.9744362831115723 0.06069265305995941
CurrentTrain: epoch  9, batch    44 | loss: 4.0351291Losses:  3.9379465579986572 0.07148227095603943
CurrentTrain: epoch  9, batch    45 | loss: 4.0094290Losses:  3.9002599716186523 0.0661393254995346
CurrentTrain: epoch  9, batch    46 | loss: 3.9663992Losses:  3.932234764099121 0.07767851650714874
CurrentTrain: epoch  9, batch    47 | loss: 4.0099134Losses:  3.934858560562134 0.06469756364822388
CurrentTrain: epoch  9, batch    48 | loss: 3.9995561Losses:  3.9291582107543945 0.06730391085147858
CurrentTrain: epoch  9, batch    49 | loss: 3.9964621Losses:  3.937688112258911 0.058751143515110016
CurrentTrain: epoch  9, batch    50 | loss: 3.9964392Losses:  3.9542007446289062 0.07631418108940125
CurrentTrain: epoch  9, batch    51 | loss: 4.0305147Losses:  3.936152935028076 0.06412100046873093
CurrentTrain: epoch  9, batch    52 | loss: 4.0002737Losses:  3.9328112602233887 0.07473879307508469
CurrentTrain: epoch  9, batch    53 | loss: 4.0075502Losses:  3.943861722946167 0.06774073839187622
CurrentTrain: epoch  9, batch    54 | loss: 4.0116024Losses:  3.946981430053711 0.06264971196651459
CurrentTrain: epoch  9, batch    55 | loss: 4.0096312Losses:  3.9325921535491943 0.056449130177497864
CurrentTrain: epoch  9, batch    56 | loss: 3.9890413Losses:  3.963742733001709 0.06958095729351044
CurrentTrain: epoch  9, batch    57 | loss: 4.0333238Losses:  3.9559175968170166 0.05951222777366638
CurrentTrain: epoch  9, batch    58 | loss: 4.0154300Losses:  3.965977668762207 0.07393760234117508
CurrentTrain: epoch  9, batch    59 | loss: 4.0399151Losses:  3.9553518295288086 0.07726365327835083
CurrentTrain: epoch  9, batch    60 | loss: 4.0326157Losses:  3.9910755157470703 0.045378804206848145
CurrentTrain: epoch  9, batch    61 | loss: 4.0364542Losses:  3.916782855987549 0.06239817664027214
CurrentTrain: epoch  9, batch    62 | loss: 3.9791811
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 85.94%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 88.75%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 88.64%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 89.90%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 90.18%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 90.42%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 91.02%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 91.54%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 92.11%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 92.50%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 92.56%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 92.33%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 92.66%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 92.97%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 92.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 93.03%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 93.06%   [EVAL] batch:   27 | acc: 87.50%,  total acc: 92.86%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 92.89%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 93.12%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 93.35%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 93.55%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 93.93%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 93.93%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 94.10%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 94.26%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 94.24%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 94.39%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 94.53%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 94.66%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 94.79%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 94.77%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 94.89%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 95.00%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 95.11%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 95.08%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 95.05%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 95.15%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 95.25%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 95.22%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 95.07%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 95.05%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 95.14%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 95.00%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 94.98%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 95.07%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 95.15%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 95.23%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 95.21%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 95.29%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 95.26%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 94.54%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 85.94%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 88.75%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 88.64%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 89.90%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 90.18%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 90.42%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 91.02%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 91.54%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 92.11%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 92.50%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 92.56%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 92.33%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 92.66%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 92.97%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 92.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 93.03%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 93.06%   [EVAL] batch:   27 | acc: 87.50%,  total acc: 92.86%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 92.89%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 93.12%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 93.35%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 93.55%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 93.93%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 93.93%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 94.10%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 94.26%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 94.24%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 94.39%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 94.53%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 94.66%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 94.79%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 94.77%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 94.89%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 95.00%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 95.11%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 95.08%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 95.05%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 95.15%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 95.25%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 95.22%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 95.07%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 95.05%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 95.14%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 95.00%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 94.98%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 95.07%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 95.15%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 95.23%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 95.21%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 95.29%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 95.26%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 94.54%   
cur_acc:  ['0.9454']
his_acc:  ['0.9454']
Clustering into  4  clusters
Clusters:  [0 3 0 0 2 2 1 0 0 0 0 0 0 1 1 0 0 0 0 0]
Losses:  8.316219329833984 1.7793034315109253
CurrentTrain: epoch  0, batch     0 | loss: 10.0955229Losses:  10.262914657592773 1.92087721824646
CurrentTrain: epoch  0, batch     1 | loss: 12.1837921Losses:  9.672406196594238 1.9226288795471191
CurrentTrain: epoch  0, batch     2 | loss: 11.5950356Losses:  7.672083854675293 1.897653341293335
CurrentTrain: epoch  0, batch     3 | loss: 9.5697374Losses:  4.261497497558594 1.4514483213424683
CurrentTrain: epoch  1, batch     0 | loss: 5.7129459Losses:  3.9087295532226562 1.8521287441253662
CurrentTrain: epoch  1, batch     1 | loss: 5.7608585Losses:  4.076720237731934 1.3722491264343262
CurrentTrain: epoch  1, batch     2 | loss: 5.4489694Losses:  4.34471321105957 1.576514720916748
CurrentTrain: epoch  1, batch     3 | loss: 5.9212279Losses:  3.4478743076324463 1.373591423034668
CurrentTrain: epoch  2, batch     0 | loss: 4.8214655Losses:  4.283422470092773 1.7248945236206055
CurrentTrain: epoch  2, batch     1 | loss: 6.0083170Losses:  3.5794248580932617 1.59453547000885
CurrentTrain: epoch  2, batch     2 | loss: 5.1739602Losses:  3.108001232147217 1.644347071647644
CurrentTrain: epoch  2, batch     3 | loss: 4.7523484Losses:  3.667206287384033 1.5562589168548584
CurrentTrain: epoch  3, batch     0 | loss: 5.2234650Losses:  3.142669677734375 1.4589340686798096
CurrentTrain: epoch  3, batch     1 | loss: 4.6016035Losses:  3.329590320587158 1.5503826141357422
CurrentTrain: epoch  3, batch     2 | loss: 4.8799729Losses:  2.9805426597595215 1.1317145824432373
CurrentTrain: epoch  3, batch     3 | loss: 4.1122570Losses:  2.996971607208252 1.328481674194336
CurrentTrain: epoch  4, batch     0 | loss: 4.3254533Losses:  3.09380841255188 1.3923537731170654
CurrentTrain: epoch  4, batch     1 | loss: 4.4861622Losses:  3.017174243927002 1.3979284763336182
CurrentTrain: epoch  4, batch     2 | loss: 4.4151030Losses:  3.488107204437256 1.1680173873901367
CurrentTrain: epoch  4, batch     3 | loss: 4.6561246Losses:  2.70736026763916 1.5316553115844727
CurrentTrain: epoch  5, batch     0 | loss: 4.2390156Losses:  3.2621350288391113 1.3963239192962646
CurrentTrain: epoch  5, batch     1 | loss: 4.6584587Losses:  2.5951459407806396 1.0980749130249023
CurrentTrain: epoch  5, batch     2 | loss: 3.6932209Losses:  3.1049728393554688 1.176622986793518
CurrentTrain: epoch  5, batch     3 | loss: 4.2815957Losses:  3.413438320159912 1.3467580080032349
CurrentTrain: epoch  6, batch     0 | loss: 4.7601962Losses:  2.9650511741638184 1.299440622329712
CurrentTrain: epoch  6, batch     1 | loss: 4.2644920Losses:  2.326198101043701 1.0243217945098877
CurrentTrain: epoch  6, batch     2 | loss: 3.3505199Losses:  2.165281057357788 0.9392287135124207
CurrentTrain: epoch  6, batch     3 | loss: 3.1045098Losses:  2.5201587677001953 1.3203662633895874
CurrentTrain: epoch  7, batch     0 | loss: 3.8405252Losses:  2.553563117980957 1.1039674282073975
CurrentTrain: epoch  7, batch     1 | loss: 3.6575305Losses:  2.851743459701538 1.2212588787078857
CurrentTrain: epoch  7, batch     2 | loss: 4.0730023Losses:  2.588252544403076 0.9989781379699707
CurrentTrain: epoch  7, batch     3 | loss: 3.5872307Losses:  2.9763617515563965 1.1488027572631836
CurrentTrain: epoch  8, batch     0 | loss: 4.1251645Losses:  2.3608145713806152 0.9755900502204895
CurrentTrain: epoch  8, batch     1 | loss: 3.3364046Losses:  2.3571157455444336 1.0852766036987305
CurrentTrain: epoch  8, batch     2 | loss: 3.4423923Losses:  2.1925506591796875 0.9438892602920532
CurrentTrain: epoch  8, batch     3 | loss: 3.1364398Losses:  2.317397117614746 0.8915860652923584
CurrentTrain: epoch  9, batch     0 | loss: 3.2089832Losses:  2.6068620681762695 1.0365504026412964
CurrentTrain: epoch  9, batch     1 | loss: 3.6434126Losses:  2.5388247966766357 0.9699013233184814
CurrentTrain: epoch  9, batch     2 | loss: 3.5087261Losses:  1.7934993505477905 0.9039177894592285
CurrentTrain: epoch  9, batch     3 | loss: 2.6974173
[EVAL] batch:    0 | acc: 18.75%,  total acc: 18.75%   [EVAL] batch:    1 | acc: 31.25%,  total acc: 25.00%   [EVAL] batch:    2 | acc: 31.25%,  total acc: 27.08%   [EVAL] batch:    3 | acc: 31.25%,  total acc: 28.12%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 32.50%   [EVAL] batch:    5 | acc: 37.50%,  total acc: 33.33%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 41.07%   [EVAL] batch:    7 | acc: 81.25%,  total acc: 46.09%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 52.08%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 56.88%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 60.23%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 61.98%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 64.42%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 66.52%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 68.75%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 70.70%   [EVAL] batch:   16 | acc: 87.50%,  total acc: 71.69%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   18 | acc: 81.25%,  total acc: 73.36%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 72.81%   [EVAL] batch:   20 | acc: 56.25%,  total acc: 72.02%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 72.44%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 72.55%   [EVAL] batch:   23 | acc: 31.25%,  total acc: 70.83%   [EVAL] batch:   24 | acc: 75.00%,  total acc: 71.00%   [EVAL] batch:   25 | acc: 6.25%,  total acc: 68.51%   [EVAL] batch:   26 | acc: 0.00%,  total acc: 65.97%   [EVAL] batch:   27 | acc: 0.00%,  total acc: 63.62%   [EVAL] batch:   28 | acc: 0.00%,  total acc: 61.42%   [EVAL] batch:   29 | acc: 6.25%,  total acc: 59.58%   [EVAL] batch:   30 | acc: 0.00%,  total acc: 57.66%   [EVAL] batch:   31 | acc: 56.25%,  total acc: 57.62%   [EVAL] batch:   32 | acc: 81.25%,  total acc: 58.33%   [EVAL] batch:   33 | acc: 75.00%,  total acc: 58.82%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 60.00%   [EVAL] batch:   35 | acc: 81.25%,  total acc: 60.59%   [EVAL] batch:   36 | acc: 75.00%,  total acc: 60.98%   [EVAL] batch:   37 | acc: 75.00%,  total acc: 61.35%   [EVAL] batch:   38 | acc: 81.25%,  total acc: 61.86%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 62.81%   [EVAL] batch:   40 | acc: 93.75%,  total acc: 63.57%   [EVAL] batch:   41 | acc: 75.00%,  total acc: 63.84%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 64.53%   [EVAL] batch:   43 | acc: 93.75%,  total acc: 65.20%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 65.97%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 66.44%   [EVAL] batch:   46 | acc: 81.25%,  total acc: 66.76%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 67.06%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 67.47%   [EVAL] batch:   49 | acc: 81.25%,  total acc: 67.75%   [EVAL] batch:   50 | acc: 56.25%,  total acc: 67.52%   [EVAL] batch:   51 | acc: 81.25%,  total acc: 67.79%   [EVAL] batch:   52 | acc: 81.25%,  total acc: 68.04%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 68.40%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 68.64%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 68.86%   [EVAL] batch:   56 | acc: 50.00%,  total acc: 68.53%   [EVAL] batch:   57 | acc: 43.75%,  total acc: 68.10%   [EVAL] batch:   58 | acc: 43.75%,  total acc: 67.69%   [EVAL] batch:   59 | acc: 68.75%,  total acc: 67.71%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 67.32%   [EVAL] batch:   61 | acc: 75.00%,  total acc: 67.44%   [EVAL] batch:   62 | acc: 25.00%,  total acc: 66.77%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 85.00%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 85.16%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 85.62%   [EVAL] batch:   10 | acc: 68.75%,  total acc: 84.09%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 83.85%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 84.62%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 85.27%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 85.83%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 86.72%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 87.85%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 88.49%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 89.06%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 89.29%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 88.92%   [EVAL] batch:   22 | acc: 93.75%,  total acc: 89.13%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 89.06%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 89.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 89.42%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 89.58%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 89.73%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 89.87%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 90.21%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 90.52%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 90.82%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 91.10%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 91.36%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 91.43%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 91.89%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 92.11%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 92.31%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 92.50%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 92.68%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 92.86%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 93.02%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 93.18%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 93.19%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 93.34%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 93.22%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 93.23%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 93.37%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 93.50%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 93.38%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 93.39%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 93.40%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 93.29%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 93.18%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 92.97%   [EVAL] batch:   56 | acc: 93.75%,  total acc: 92.98%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 93.00%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 93.11%   [EVAL] batch:   59 | acc: 100.00%,  total acc: 93.23%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 93.34%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 93.35%   [EVAL] batch:   62 | acc: 62.50%,  total acc: 92.86%   [EVAL] batch:   63 | acc: 25.00%,  total acc: 91.80%   [EVAL] batch:   64 | acc: 25.00%,  total acc: 90.77%   [EVAL] batch:   65 | acc: 18.75%,  total acc: 89.68%   [EVAL] batch:   66 | acc: 62.50%,  total acc: 89.27%   [EVAL] batch:   67 | acc: 37.50%,  total acc: 88.51%   [EVAL] batch:   68 | acc: 56.25%,  total acc: 88.04%   [EVAL] batch:   69 | acc: 87.50%,  total acc: 88.04%   [EVAL] batch:   70 | acc: 93.75%,  total acc: 88.12%   [EVAL] batch:   71 | acc: 100.00%,  total acc: 88.28%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 88.44%   [EVAL] batch:   73 | acc: 87.50%,  total acc: 88.43%   [EVAL] batch:   74 | acc: 81.25%,  total acc: 88.33%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 88.49%   [EVAL] batch:   76 | acc: 93.75%,  total acc: 88.56%   [EVAL] batch:   77 | acc: 100.00%,  total acc: 88.70%   [EVAL] batch:   78 | acc: 93.75%,  total acc: 88.77%   [EVAL] batch:   79 | acc: 93.75%,  total acc: 88.83%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 88.89%   [EVAL] batch:   81 | acc: 56.25%,  total acc: 88.49%   [EVAL] batch:   82 | acc: 62.50%,  total acc: 88.18%   [EVAL] batch:   83 | acc: 68.75%,  total acc: 87.95%   [EVAL] batch:   84 | acc: 81.25%,  total acc: 87.87%   [EVAL] batch:   85 | acc: 56.25%,  total acc: 87.50%   [EVAL] batch:   86 | acc: 50.00%,  total acc: 87.07%   [EVAL] batch:   87 | acc: 43.75%,  total acc: 86.58%   [EVAL] batch:   88 | acc: 0.00%,  total acc: 85.60%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 84.65%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 83.72%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 82.81%   [EVAL] batch:   92 | acc: 6.25%,  total acc: 81.99%   [EVAL] batch:   93 | acc: 12.50%,  total acc: 81.25%   [EVAL] batch:   94 | acc: 75.00%,  total acc: 81.18%   [EVAL] batch:   95 | acc: 93.75%,  total acc: 81.32%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 81.31%   [EVAL] batch:   97 | acc: 93.75%,  total acc: 81.44%   [EVAL] batch:   98 | acc: 81.25%,  total acc: 81.44%   [EVAL] batch:   99 | acc: 68.75%,  total acc: 81.31%   [EVAL] batch:  100 | acc: 75.00%,  total acc: 81.25%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 81.37%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 81.49%   [EVAL] batch:  103 | acc: 87.50%,  total acc: 81.55%   [EVAL] batch:  104 | acc: 81.25%,  total acc: 81.55%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 81.72%   [EVAL] batch:  106 | acc: 93.75%,  total acc: 81.83%   [EVAL] batch:  107 | acc: 93.75%,  total acc: 81.94%   [EVAL] batch:  108 | acc: 81.25%,  total acc: 81.94%   [EVAL] batch:  109 | acc: 93.75%,  total acc: 82.05%   [EVAL] batch:  110 | acc: 75.00%,  total acc: 81.98%   [EVAL] batch:  111 | acc: 93.75%,  total acc: 82.09%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 81.86%   [EVAL] batch:  113 | acc: 68.75%,  total acc: 81.74%   [EVAL] batch:  114 | acc: 81.25%,  total acc: 81.74%   [EVAL] batch:  115 | acc: 93.75%,  total acc: 81.84%   [EVAL] batch:  116 | acc: 75.00%,  total acc: 81.78%   [EVAL] batch:  117 | acc: 87.50%,  total acc: 81.83%   [EVAL] batch:  118 | acc: 62.50%,  total acc: 81.67%   [EVAL] batch:  119 | acc: 37.50%,  total acc: 81.30%   [EVAL] batch:  120 | acc: 56.25%,  total acc: 81.10%   [EVAL] batch:  121 | acc: 56.25%,  total acc: 80.89%   [EVAL] batch:  122 | acc: 50.00%,  total acc: 80.64%   [EVAL] batch:  123 | acc: 62.50%,  total acc: 80.49%   [EVAL] batch:  124 | acc: 62.50%,  total acc: 80.35%   
cur_acc:  ['0.9454', '0.6677']
his_acc:  ['0.9454', '0.8035']
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.928795337677002 1.4237406253814697
CurrentTrain: epoch  0, batch     0 | loss: 9.3525362Losses:  9.643566131591797 1.314920425415039
CurrentTrain: epoch  0, batch     1 | loss: 10.9584866Losses:  10.249765396118164 1.2493717670440674
CurrentTrain: epoch  0, batch     2 | loss: 11.4991369Losses:  10.334318161010742 1.589227318763733
CurrentTrain: epoch  0, batch     3 | loss: 11.9235458Losses:  6.124852657318115 1.0895607471466064
CurrentTrain: epoch  0, batch     4 | loss: 7.2144136Losses:  3.5951242446899414 1.6065655946731567
CurrentTrain: epoch  1, batch     0 | loss: 5.2016897Losses:  3.403261661529541 1.2063729763031006
CurrentTrain: epoch  1, batch     1 | loss: 4.6096344Losses:  3.7646594047546387 1.3990569114685059
CurrentTrain: epoch  1, batch     2 | loss: 5.1637163Losses:  2.6161751747131348 1.1791598796844482
CurrentTrain: epoch  1, batch     3 | loss: 3.7953351Losses:  3.9671266078948975 0.9910385012626648
CurrentTrain: epoch  1, batch     4 | loss: 4.9581652Losses:  2.8215456008911133 1.1170518398284912
CurrentTrain: epoch  2, batch     0 | loss: 3.9385974Losses:  2.723344326019287 1.2009096145629883
CurrentTrain: epoch  2, batch     1 | loss: 3.9242539Losses:  3.2845067977905273 1.12388277053833
CurrentTrain: epoch  2, batch     2 | loss: 4.4083896Losses:  3.4695165157318115 1.0866916179656982
CurrentTrain: epoch  2, batch     3 | loss: 4.5562081Losses:  2.97436785697937 0.7265839576721191
CurrentTrain: epoch  2, batch     4 | loss: 3.7009518Losses:  2.8023266792297363 1.3785920143127441
CurrentTrain: epoch  3, batch     0 | loss: 4.1809187Losses:  2.49410343170166 1.1849173307418823
CurrentTrain: epoch  3, batch     1 | loss: 3.6790209Losses:  2.631117105484009 1.1465803384780884
CurrentTrain: epoch  3, batch     2 | loss: 3.7776976Losses:  3.4041035175323486 1.1508699655532837
CurrentTrain: epoch  3, batch     3 | loss: 4.5549736Losses:  2.821547508239746 0.6135086417198181
CurrentTrain: epoch  3, batch     4 | loss: 3.4350562Losses:  2.407588481903076 0.9414292573928833
CurrentTrain: epoch  4, batch     0 | loss: 3.3490176Losses:  2.8237669467926025 1.2080837488174438
CurrentTrain: epoch  4, batch     1 | loss: 4.0318508Losses:  2.5297303199768066 0.8406416773796082
CurrentTrain: epoch  4, batch     2 | loss: 3.3703721Losses:  2.890805244445801 1.1530499458312988
CurrentTrain: epoch  4, batch     3 | loss: 4.0438552Losses:  3.0303733348846436 0.6010197997093201
CurrentTrain: epoch  4, batch     4 | loss: 3.6313932Losses:  2.367060661315918 0.985550045967102
CurrentTrain: epoch  5, batch     0 | loss: 3.3526106Losses:  2.313932180404663 0.8592309951782227
CurrentTrain: epoch  5, batch     1 | loss: 3.1731632Losses:  2.944242477416992 1.017319679260254
CurrentTrain: epoch  5, batch     2 | loss: 3.9615622Losses:  2.7370481491088867 0.9809852838516235
CurrentTrain: epoch  5, batch     3 | loss: 3.7180333Losses:  1.6800329685211182 0.7187251448631287
CurrentTrain: epoch  5, batch     4 | loss: 2.3987582Losses:  2.2723159790039062 0.8795986175537109
CurrentTrain: epoch  6, batch     0 | loss: 3.1519146Losses:  2.5012688636779785 0.9588155746459961
CurrentTrain: epoch  6, batch     1 | loss: 3.4600844Losses:  2.3559813499450684 0.9505138397216797
CurrentTrain: epoch  6, batch     2 | loss: 3.3064952Losses:  2.0357890129089355 1.0095834732055664
CurrentTrain: epoch  6, batch     3 | loss: 3.0453725Losses:  2.8035101890563965 0.3782428205013275
CurrentTrain: epoch  6, batch     4 | loss: 3.1817529Losses:  2.190159320831299 0.7878617644309998
CurrentTrain: epoch  7, batch     0 | loss: 2.9780211Losses:  1.8950248956680298 1.0353946685791016
CurrentTrain: epoch  7, batch     1 | loss: 2.9304194Losses:  3.2235631942749023 0.9351346492767334
CurrentTrain: epoch  7, batch     2 | loss: 4.1586981Losses:  2.299999237060547 0.9532545804977417
CurrentTrain: epoch  7, batch     3 | loss: 3.2532539Losses:  1.6244004964828491 0.2883080244064331
CurrentTrain: epoch  7, batch     4 | loss: 1.9127085Losses:  2.006810188293457 0.8173438906669617
CurrentTrain: epoch  8, batch     0 | loss: 2.8241541Losses:  2.2092747688293457 0.8976359367370605
CurrentTrain: epoch  8, batch     1 | loss: 3.1069107Losses:  2.3167762756347656 0.8808208107948303
CurrentTrain: epoch  8, batch     2 | loss: 3.1975970Losses:  2.1579551696777344 1.0446662902832031
CurrentTrain: epoch  8, batch     3 | loss: 3.2026215Losses:  2.4000844955444336 0.5222427248954773
CurrentTrain: epoch  8, batch     4 | loss: 2.9223273Losses:  2.1632256507873535 0.714681088924408
CurrentTrain: epoch  9, batch     0 | loss: 2.8779068Losses:  1.6440227031707764 0.7470055818557739
CurrentTrain: epoch  9, batch     1 | loss: 2.3910284Losses:  2.004305601119995 0.846308708190918
CurrentTrain: epoch  9, batch     2 | loss: 2.8506143Losses:  2.535202980041504 0.7722290754318237
CurrentTrain: epoch  9, batch     3 | loss: 3.3074322Losses:  1.86428964138031 0.5245760679244995
CurrentTrain: epoch  9, batch     4 | loss: 2.3888657
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 95.83%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 95.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 95.83%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 96.43%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 96.09%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 95.14%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 92.50%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 91.48%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:   12 | acc: 81.25%,  total acc: 90.87%   [EVAL] batch:   13 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 89.58%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 89.84%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 88.97%   [EVAL] batch:   17 | acc: 87.50%,  total acc: 88.89%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 89.47%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 88.75%   [EVAL] batch:   20 | acc: 81.25%,  total acc: 88.39%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 88.64%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 88.32%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 88.54%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 88.50%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 87.98%   [EVAL] batch:   26 | acc: 81.25%,  total acc: 87.73%   [EVAL] batch:   27 | acc: 62.50%,  total acc: 86.83%   [EVAL] batch:   28 | acc: 81.25%,  total acc: 86.64%   [EVAL] batch:   29 | acc: 56.25%,  total acc: 85.62%   [EVAL] batch:   30 | acc: 43.75%,  total acc: 84.27%   [EVAL] batch:   31 | acc: 43.75%,  total acc: 83.01%   [EVAL] batch:   32 | acc: 31.25%,  total acc: 81.44%   [EVAL] batch:   33 | acc: 50.00%,  total acc: 80.51%   [EVAL] batch:   34 | acc: 37.50%,  total acc: 79.29%   [EVAL] batch:   35 | acc: 50.00%,  total acc: 78.47%   [EVAL] batch:   36 | acc: 43.75%,  total acc: 77.53%   [EVAL] batch:   37 | acc: 43.75%,  total acc: 76.64%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 76.60%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 76.56%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 76.22%   [EVAL] batch:   41 | acc: 56.25%,  total acc: 75.74%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 76.02%   [EVAL] batch:   43 | acc: 62.50%,  total acc: 75.71%   [EVAL] batch:   44 | acc: 31.25%,  total acc: 74.72%   [EVAL] batch:   45 | acc: 31.25%,  total acc: 73.78%   [EVAL] batch:   46 | acc: 37.50%,  total acc: 73.01%   [EVAL] batch:   47 | acc: 43.75%,  total acc: 72.40%   [EVAL] batch:   48 | acc: 25.00%,  total acc: 71.43%   [EVAL] batch:   49 | acc: 37.50%,  total acc: 70.75%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 71.32%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 71.88%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 72.41%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 72.92%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 73.30%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 73.77%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 74.01%   [EVAL] batch:   57 | acc: 87.50%,  total acc: 74.25%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 74.58%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 74.90%   [EVAL] batch:   60 | acc: 93.75%,  total acc: 75.20%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 75.50%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 75.10%   
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 90.18%   [EVAL] batch:    7 | acc: 81.25%,  total acc: 89.06%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 88.19%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 88.12%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 87.50%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 87.95%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 88.33%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 89.06%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 89.71%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 89.93%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 90.46%   [EVAL] batch:   19 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 90.77%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 90.34%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 90.22%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 90.10%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 90.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 90.38%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 90.51%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 90.95%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 91.25%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 91.53%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 91.80%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 92.05%   [EVAL] batch:   33 | acc: 68.75%,  total acc: 91.36%   [EVAL] batch:   34 | acc: 75.00%,  total acc: 90.89%   [EVAL] batch:   35 | acc: 87.50%,  total acc: 90.80%   [EVAL] batch:   36 | acc: 87.50%,  total acc: 90.71%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 90.79%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 91.03%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 91.25%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 91.46%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 91.72%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 91.90%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 91.94%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 92.12%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 92.02%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 92.06%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 92.22%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 92.38%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 92.28%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 92.31%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 92.45%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 92.36%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 92.27%   [EVAL] batch:   55 | acc: 75.00%,  total acc: 91.96%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 91.89%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 91.59%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 91.74%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 91.77%   [EVAL] batch:   60 | acc: 87.50%,  total acc: 91.70%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 91.63%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 90.97%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 89.55%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 88.17%   [EVAL] batch:   65 | acc: 12.50%,  total acc: 87.03%   [EVAL] batch:   66 | acc: 12.50%,  total acc: 85.91%   [EVAL] batch:   67 | acc: 12.50%,  total acc: 84.83%   [EVAL] batch:   68 | acc: 37.50%,  total acc: 84.15%   [EVAL] batch:   69 | acc: 62.50%,  total acc: 83.84%   [EVAL] batch:   70 | acc: 87.50%,  total acc: 83.89%   [EVAL] batch:   71 | acc: 87.50%,  total acc: 83.94%   [EVAL] batch:   72 | acc: 93.75%,  total acc: 84.08%   [EVAL] batch:   73 | acc: 62.50%,  total acc: 83.78%   [EVAL] batch:   74 | acc: 68.75%,  total acc: 83.58%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 83.80%   [EVAL] batch:   76 | acc: 93.75%,  total acc: 83.93%   [EVAL] batch:   77 | acc: 100.00%,  total acc: 84.13%   [EVAL] batch:   78 | acc: 87.50%,  total acc: 84.18%   [EVAL] batch:   79 | acc: 93.75%,  total acc: 84.30%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 84.41%   [EVAL] batch:   81 | acc: 31.25%,  total acc: 83.77%   [EVAL] batch:   82 | acc: 18.75%,  total acc: 82.98%   [EVAL] batch:   83 | acc: 6.25%,  total acc: 82.07%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 81.25%   [EVAL] batch:   85 | acc: 12.50%,  total acc: 80.45%   [EVAL] batch:   86 | acc: 6.25%,  total acc: 79.60%   [EVAL] batch:   87 | acc: 31.25%,  total acc: 79.05%   [EVAL] batch:   88 | acc: 0.00%,  total acc: 78.16%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 77.29%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 76.44%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 75.61%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 74.80%   [EVAL] batch:   93 | acc: 12.50%,  total acc: 74.14%   [EVAL] batch:   94 | acc: 93.75%,  total acc: 74.34%   [EVAL] batch:   95 | acc: 93.75%,  total acc: 74.54%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 74.61%   [EVAL] batch:   97 | acc: 87.50%,  total acc: 74.74%   [EVAL] batch:   98 | acc: 75.00%,  total acc: 74.75%   [EVAL] batch:   99 | acc: 75.00%,  total acc: 74.75%   [EVAL] batch:  100 | acc: 93.75%,  total acc: 74.94%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 75.12%   [EVAL] batch:  102 | acc: 100.00%,  total acc: 75.36%   [EVAL] batch:  103 | acc: 87.50%,  total acc: 75.48%   [EVAL] batch:  104 | acc: 87.50%,  total acc: 75.60%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 75.83%   [EVAL] batch:  106 | acc: 100.00%,  total acc: 76.05%   [EVAL] batch:  107 | acc: 93.75%,  total acc: 76.22%   [EVAL] batch:  108 | acc: 81.25%,  total acc: 76.26%   [EVAL] batch:  109 | acc: 100.00%,  total acc: 76.48%   [EVAL] batch:  110 | acc: 81.25%,  total acc: 76.52%   [EVAL] batch:  111 | acc: 93.75%,  total acc: 76.67%   [EVAL] batch:  112 | acc: 62.50%,  total acc: 76.55%   [EVAL] batch:  113 | acc: 62.50%,  total acc: 76.43%   [EVAL] batch:  114 | acc: 87.50%,  total acc: 76.52%   [EVAL] batch:  115 | acc: 87.50%,  total acc: 76.62%   [EVAL] batch:  116 | acc: 75.00%,  total acc: 76.60%   [EVAL] batch:  117 | acc: 87.50%,  total acc: 76.69%   [EVAL] batch:  118 | acc: 75.00%,  total acc: 76.68%   [EVAL] batch:  119 | acc: 37.50%,  total acc: 76.35%   [EVAL] batch:  120 | acc: 43.75%,  total acc: 76.08%   [EVAL] batch:  121 | acc: 43.75%,  total acc: 75.82%   [EVAL] batch:  122 | acc: 43.75%,  total acc: 75.56%   [EVAL] batch:  123 | acc: 62.50%,  total acc: 75.45%   [EVAL] batch:  124 | acc: 68.75%,  total acc: 75.40%   [EVAL] batch:  125 | acc: 93.75%,  total acc: 75.55%   [EVAL] batch:  126 | acc: 93.75%,  total acc: 75.69%   [EVAL] batch:  127 | acc: 100.00%,  total acc: 75.88%   [EVAL] batch:  128 | acc: 93.75%,  total acc: 76.02%   [EVAL] batch:  129 | acc: 93.75%,  total acc: 76.15%   [EVAL] batch:  130 | acc: 100.00%,  total acc: 76.34%   [EVAL] batch:  131 | acc: 100.00%,  total acc: 76.52%   [EVAL] batch:  132 | acc: 93.75%,  total acc: 76.64%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 76.73%   [EVAL] batch:  134 | acc: 68.75%,  total acc: 76.67%   [EVAL] batch:  135 | acc: 81.25%,  total acc: 76.70%   [EVAL] batch:  136 | acc: 93.75%,  total acc: 76.82%   [EVAL] batch:  137 | acc: 81.25%,  total acc: 76.86%   [EVAL] batch:  138 | acc: 87.50%,  total acc: 76.93%   [EVAL] batch:  139 | acc: 75.00%,  total acc: 76.92%   [EVAL] batch:  140 | acc: 93.75%,  total acc: 77.04%   [EVAL] batch:  141 | acc: 75.00%,  total acc: 77.02%   [EVAL] batch:  142 | acc: 87.50%,  total acc: 77.10%   [EVAL] batch:  143 | acc: 100.00%,  total acc: 77.26%   [EVAL] batch:  144 | acc: 75.00%,  total acc: 77.24%   [EVAL] batch:  145 | acc: 81.25%,  total acc: 77.27%   [EVAL] batch:  146 | acc: 93.75%,  total acc: 77.38%   [EVAL] batch:  147 | acc: 81.25%,  total acc: 77.41%   [EVAL] batch:  148 | acc: 93.75%,  total acc: 77.52%   [EVAL] batch:  149 | acc: 87.50%,  total acc: 77.58%   [EVAL] batch:  150 | acc: 75.00%,  total acc: 77.57%   [EVAL] batch:  151 | acc: 81.25%,  total acc: 77.59%   [EVAL] batch:  152 | acc: 62.50%,  total acc: 77.49%   [EVAL] batch:  153 | acc: 81.25%,  total acc: 77.52%   [EVAL] batch:  154 | acc: 56.25%,  total acc: 77.38%   [EVAL] batch:  155 | acc: 43.75%,  total acc: 77.16%   [EVAL] batch:  156 | acc: 43.75%,  total acc: 76.95%   [EVAL] batch:  157 | acc: 31.25%,  total acc: 76.66%   [EVAL] batch:  158 | acc: 50.00%,  total acc: 76.49%   [EVAL] batch:  159 | acc: 37.50%,  total acc: 76.25%   [EVAL] batch:  160 | acc: 50.00%,  total acc: 76.09%   [EVAL] batch:  161 | acc: 43.75%,  total acc: 75.89%   [EVAL] batch:  162 | acc: 43.75%,  total acc: 75.69%   [EVAL] batch:  163 | acc: 75.00%,  total acc: 75.69%   [EVAL] batch:  164 | acc: 75.00%,  total acc: 75.68%   [EVAL] batch:  165 | acc: 62.50%,  total acc: 75.60%   [EVAL] batch:  166 | acc: 56.25%,  total acc: 75.49%   [EVAL] batch:  167 | acc: 87.50%,  total acc: 75.56%   [EVAL] batch:  168 | acc: 62.50%,  total acc: 75.48%   [EVAL] batch:  169 | acc: 31.25%,  total acc: 75.22%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 74.96%   [EVAL] batch:  171 | acc: 37.50%,  total acc: 74.75%   [EVAL] batch:  172 | acc: 43.75%,  total acc: 74.57%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 74.28%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 74.07%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 74.22%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 74.36%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 74.51%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 74.65%   [EVAL] batch:  179 | acc: 93.75%,  total acc: 74.76%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 74.90%   [EVAL] batch:  181 | acc: 87.50%,  total acc: 74.97%   [EVAL] batch:  182 | acc: 87.50%,  total acc: 75.03%   [EVAL] batch:  183 | acc: 93.75%,  total acc: 75.14%   [EVAL] batch:  184 | acc: 93.75%,  total acc: 75.24%   [EVAL] batch:  185 | acc: 93.75%,  total acc: 75.34%   [EVAL] batch:  186 | acc: 93.75%,  total acc: 75.43%   [EVAL] batch:  187 | acc: 50.00%,  total acc: 75.30%   
cur_acc:  ['0.9454', '0.6677', '0.7510']
his_acc:  ['0.9454', '0.8035', '0.7530']
Clustering into  5  clusters
Clusters:  [0 3 0 0 4 4 1 0 0 0 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0 1 0 4 0 1 0 0 0 0 0 0 2
 1 0 1]
Losses:  7.434642314910889 1.635833501815796
CurrentTrain: epoch  0, batch     0 | loss: 9.0704756Losses:  10.175945281982422 1.4026832580566406
CurrentTrain: epoch  0, batch     1 | loss: 11.5786285Losses:  9.335365295410156 1.458809494972229
CurrentTrain: epoch  0, batch     2 | loss: 10.7941751Losses:  8.856575012207031 1.578259825706482
CurrentTrain: epoch  0, batch     3 | loss: 10.4348345Losses:  9.486148834228516 1.548467993736267
CurrentTrain: epoch  0, batch     4 | loss: 11.0346165Losses:  3.7106685638427734 1.3795291185379028
CurrentTrain: epoch  1, batch     0 | loss: 5.0901976Losses:  3.4324889183044434 1.3995451927185059
CurrentTrain: epoch  1, batch     1 | loss: 4.8320341Losses:  3.005688428878784 1.3868242502212524
CurrentTrain: epoch  1, batch     2 | loss: 4.3925128Losses:  2.673320770263672 1.4283753633499146
CurrentTrain: epoch  1, batch     3 | loss: 4.1016960Losses:  3.6456120014190674 1.018907070159912
CurrentTrain: epoch  1, batch     4 | loss: 4.6645193Losses:  2.797788619995117 1.1371166706085205
CurrentTrain: epoch  2, batch     0 | loss: 3.9349053Losses:  4.64969539642334 1.3495657444000244
CurrentTrain: epoch  2, batch     1 | loss: 5.9992609Losses:  2.4282987117767334 1.3015875816345215
CurrentTrain: epoch  2, batch     2 | loss: 3.7298863Losses:  2.8053345680236816 1.296691656112671
CurrentTrain: epoch  2, batch     3 | loss: 4.1020260Losses:  2.390817403793335 0.9487204551696777
CurrentTrain: epoch  2, batch     4 | loss: 3.3395379Losses:  2.5284104347229004 1.2738741636276245
CurrentTrain: epoch  3, batch     0 | loss: 3.8022847Losses:  4.144286155700684 1.1494698524475098
CurrentTrain: epoch  3, batch     1 | loss: 5.2937560Losses:  2.2826499938964844 1.0585354566574097
CurrentTrain: epoch  3, batch     2 | loss: 3.3411856Losses:  1.8183685541152954 1.0438108444213867
CurrentTrain: epoch  3, batch     3 | loss: 2.8621793Losses:  3.5957279205322266 0.9752253293991089
CurrentTrain: epoch  3, batch     4 | loss: 4.5709534Losses:  3.2904605865478516 1.1599016189575195
CurrentTrain: epoch  4, batch     0 | loss: 4.4503622Losses:  2.725525379180908 0.8925212621688843
CurrentTrain: epoch  4, batch     1 | loss: 3.6180468Losses:  2.2314138412475586 1.0738530158996582
CurrentTrain: epoch  4, batch     2 | loss: 3.3052669Losses:  2.9894580841064453 1.1603220701217651
CurrentTrain: epoch  4, batch     3 | loss: 4.1497803Losses:  2.3455207347869873 0.8578618764877319
CurrentTrain: epoch  4, batch     4 | loss: 3.2033825Losses:  2.6243081092834473 0.9959901571273804
CurrentTrain: epoch  5, batch     0 | loss: 3.6202984Losses:  2.734645366668701 1.0637199878692627
CurrentTrain: epoch  5, batch     1 | loss: 3.7983654Losses:  2.084070920944214 0.6948431730270386
CurrentTrain: epoch  5, batch     2 | loss: 2.7789140Losses:  3.1578307151794434 0.9866203665733337
CurrentTrain: epoch  5, batch     3 | loss: 4.1444511Losses:  2.523838996887207 1.1859829425811768
CurrentTrain: epoch  5, batch     4 | loss: 3.7098219Losses:  2.2857155799865723 0.7409685850143433
CurrentTrain: epoch  6, batch     0 | loss: 3.0266843Losses:  2.5820651054382324 1.0557479858398438
CurrentTrain: epoch  6, batch     1 | loss: 3.6378131Losses:  2.755997657775879 0.8507763147354126
CurrentTrain: epoch  6, batch     2 | loss: 3.6067739Losses:  2.803281784057617 0.8290329575538635
CurrentTrain: epoch  6, batch     3 | loss: 3.6323147Losses:  2.1398489475250244 0.8363983035087585
CurrentTrain: epoch  6, batch     4 | loss: 2.9762473Losses:  1.8950278759002686 0.8962960839271545
CurrentTrain: epoch  7, batch     0 | loss: 2.7913239Losses:  2.8393187522888184 0.9157755970954895
CurrentTrain: epoch  7, batch     1 | loss: 3.7550943Losses:  2.079679489135742 0.9433265328407288
CurrentTrain: epoch  7, batch     2 | loss: 3.0230060Losses:  2.681307315826416 0.873512864112854
CurrentTrain: epoch  7, batch     3 | loss: 3.5548201Losses:  2.5082859992980957 0.929093599319458
CurrentTrain: epoch  7, batch     4 | loss: 3.4373796Losses:  2.187455177307129 0.9229569435119629
CurrentTrain: epoch  8, batch     0 | loss: 3.1104121Losses:  1.7661160230636597 0.795764684677124
CurrentTrain: epoch  8, batch     1 | loss: 2.5618806Losses:  1.9523820877075195 0.8134208917617798
CurrentTrain: epoch  8, batch     2 | loss: 2.7658029Losses:  2.6462793350219727 0.7843835353851318
CurrentTrain: epoch  8, batch     3 | loss: 3.4306629Losses:  2.7171764373779297 0.6918580532073975
CurrentTrain: epoch  8, batch     4 | loss: 3.4090345Losses:  2.0338892936706543 0.7727473974227905
CurrentTrain: epoch  9, batch     0 | loss: 2.8066368Losses:  2.4350056648254395 0.9389225840568542
CurrentTrain: epoch  9, batch     1 | loss: 3.3739283Losses:  1.7072094678878784 0.8503957986831665
CurrentTrain: epoch  9, batch     2 | loss: 2.5576053Losses:  2.4402852058410645 0.7471295595169067
CurrentTrain: epoch  9, batch     3 | loss: 3.1874146Losses:  2.1499412059783936 0.8675342798233032
CurrentTrain: epoch  9, batch     4 | loss: 3.0174756
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 75.00%,  total acc: 79.17%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 71.88%   [EVAL] batch:    4 | acc: 68.75%,  total acc: 71.25%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 71.88%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 72.32%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 74.22%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 72.92%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 72.50%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 73.30%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 73.96%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 75.96%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 77.23%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 78.33%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 79.30%   [EVAL] batch:   16 | acc: 87.50%,  total acc: 79.78%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 80.56%   [EVAL] batch:   18 | acc: 87.50%,  total acc: 80.92%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 80.31%   [EVAL] batch:   20 | acc: 56.25%,  total acc: 79.17%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 79.26%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 79.08%   [EVAL] batch:   23 | acc: 68.75%,  total acc: 78.65%   [EVAL] batch:   24 | acc: 62.50%,  total acc: 78.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 78.85%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 79.63%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 80.13%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 80.82%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 81.46%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 82.06%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 82.42%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 82.95%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 83.46%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 83.93%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 84.80%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 85.20%   [EVAL] batch:   38 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 85.62%   [EVAL] batch:   40 | acc: 81.25%,  total acc: 85.52%   [EVAL] batch:   41 | acc: 93.75%,  total acc: 85.71%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 85.90%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 85.94%   [EVAL] batch:   44 | acc: 56.25%,  total acc: 85.28%   [EVAL] batch:   45 | acc: 37.50%,  total acc: 84.24%   [EVAL] batch:   46 | acc: 31.25%,  total acc: 83.11%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 82.81%   [EVAL] batch:   48 | acc: 43.75%,  total acc: 82.02%   [EVAL] batch:   49 | acc: 62.50%,  total acc: 81.62%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 81.86%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 82.09%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 82.31%   [EVAL] batch:   53 | acc: 81.25%,  total acc: 82.29%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 82.50%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 82.70%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 82.24%   [EVAL] batch:   57 | acc: 56.25%,  total acc: 81.79%   [EVAL] batch:   58 | acc: 75.00%,  total acc: 81.67%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 81.15%   [EVAL] batch:   60 | acc: 68.75%,  total acc: 80.94%   [EVAL] batch:   61 | acc: 43.75%,  total acc: 80.34%   [EVAL] batch:   62 | acc: 43.75%,  total acc: 79.76%   
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 92.71%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 89.29%   [EVAL] batch:    7 | acc: 81.25%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 87.50%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 86.25%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 85.23%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 85.58%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 86.16%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 86.67%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 87.87%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 88.19%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 88.82%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 89.38%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 89.29%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 88.92%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 88.86%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 88.80%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 88.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 89.18%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 89.96%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 90.30%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 90.93%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 91.21%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 91.48%   [EVAL] batch:   33 | acc: 81.25%,  total acc: 91.18%   [EVAL] batch:   34 | acc: 75.00%,  total acc: 90.71%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 90.80%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 90.88%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 91.12%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 91.35%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 91.56%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 91.77%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 91.96%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 92.01%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 91.90%   [EVAL] batch:   44 | acc: 87.50%,  total acc: 91.81%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 91.85%   [EVAL] batch:   46 | acc: 75.00%,  total acc: 91.49%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 91.28%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 91.45%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 91.50%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 91.42%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 91.47%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 91.63%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 91.55%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 91.48%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 91.29%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 91.01%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 90.62%   [EVAL] batch:   58 | acc: 81.25%,  total acc: 90.47%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 90.52%   [EVAL] batch:   60 | acc: 81.25%,  total acc: 90.37%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 90.32%   [EVAL] batch:   62 | acc: 43.75%,  total acc: 89.58%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 88.18%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 86.83%   [EVAL] batch:   65 | acc: 12.50%,  total acc: 85.70%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 84.70%   [EVAL] batch:   67 | acc: 12.50%,  total acc: 83.64%   [EVAL] batch:   68 | acc: 37.50%,  total acc: 82.97%   [EVAL] batch:   69 | acc: 62.50%,  total acc: 82.68%   [EVAL] batch:   70 | acc: 87.50%,  total acc: 82.75%   [EVAL] batch:   71 | acc: 87.50%,  total acc: 82.81%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 82.88%   [EVAL] batch:   73 | acc: 62.50%,  total acc: 82.60%   [EVAL] batch:   74 | acc: 68.75%,  total acc: 82.42%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 82.65%   [EVAL] batch:   76 | acc: 81.25%,  total acc: 82.63%   [EVAL] batch:   77 | acc: 100.00%,  total acc: 82.85%   [EVAL] batch:   78 | acc: 87.50%,  total acc: 82.91%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 83.12%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 83.26%   [EVAL] batch:   81 | acc: 31.25%,  total acc: 82.62%   [EVAL] batch:   82 | acc: 18.75%,  total acc: 81.85%   [EVAL] batch:   83 | acc: 6.25%,  total acc: 80.95%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 80.15%   [EVAL] batch:   85 | acc: 12.50%,  total acc: 79.36%   [EVAL] batch:   86 | acc: 0.00%,  total acc: 78.45%   [EVAL] batch:   87 | acc: 18.75%,  total acc: 77.77%   [EVAL] batch:   88 | acc: 6.25%,  total acc: 76.97%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 76.11%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 75.27%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 74.46%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 73.66%   [EVAL] batch:   93 | acc: 18.75%,  total acc: 73.07%   [EVAL] batch:   94 | acc: 87.50%,  total acc: 73.22%   [EVAL] batch:   95 | acc: 87.50%,  total acc: 73.37%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 73.45%   [EVAL] batch:   97 | acc: 100.00%,  total acc: 73.72%   [EVAL] batch:   98 | acc: 87.50%,  total acc: 73.86%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 73.94%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 74.07%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 74.26%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 74.45%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 74.70%   [EVAL] batch:  104 | acc: 93.75%,  total acc: 74.88%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 75.12%   [EVAL] batch:  106 | acc: 100.00%,  total acc: 75.35%   [EVAL] batch:  107 | acc: 93.75%,  total acc: 75.52%   [EVAL] batch:  108 | acc: 81.25%,  total acc: 75.57%   [EVAL] batch:  109 | acc: 93.75%,  total acc: 75.74%   [EVAL] batch:  110 | acc: 81.25%,  total acc: 75.79%   [EVAL] batch:  111 | acc: 87.50%,  total acc: 75.89%   [EVAL] batch:  112 | acc: 56.25%,  total acc: 75.72%   [EVAL] batch:  113 | acc: 62.50%,  total acc: 75.60%   [EVAL] batch:  114 | acc: 75.00%,  total acc: 75.60%   [EVAL] batch:  115 | acc: 93.75%,  total acc: 75.75%   [EVAL] batch:  116 | acc: 68.75%,  total acc: 75.69%   [EVAL] batch:  117 | acc: 87.50%,  total acc: 75.79%   [EVAL] batch:  118 | acc: 62.50%,  total acc: 75.68%   [EVAL] batch:  119 | acc: 37.50%,  total acc: 75.36%   [EVAL] batch:  120 | acc: 50.00%,  total acc: 75.15%   [EVAL] batch:  121 | acc: 50.00%,  total acc: 74.95%   [EVAL] batch:  122 | acc: 43.75%,  total acc: 74.70%   [EVAL] batch:  123 | acc: 56.25%,  total acc: 74.55%   [EVAL] batch:  124 | acc: 56.25%,  total acc: 74.40%   [EVAL] batch:  125 | acc: 25.00%,  total acc: 74.01%   [EVAL] batch:  126 | acc: 31.25%,  total acc: 73.67%   [EVAL] batch:  127 | acc: 25.00%,  total acc: 73.29%   [EVAL] batch:  128 | acc: 6.25%,  total acc: 72.77%   [EVAL] batch:  129 | acc: 37.50%,  total acc: 72.50%   [EVAL] batch:  130 | acc: 25.00%,  total acc: 72.14%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 72.21%   [EVAL] batch:  132 | acc: 93.75%,  total acc: 72.37%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 72.48%   [EVAL] batch:  134 | acc: 68.75%,  total acc: 72.45%   [EVAL] batch:  135 | acc: 87.50%,  total acc: 72.56%   [EVAL] batch:  136 | acc: 93.75%,  total acc: 72.72%   [EVAL] batch:  137 | acc: 87.50%,  total acc: 72.83%   [EVAL] batch:  138 | acc: 81.25%,  total acc: 72.89%   [EVAL] batch:  139 | acc: 81.25%,  total acc: 72.95%   [EVAL] batch:  140 | acc: 93.75%,  total acc: 73.09%   [EVAL] batch:  141 | acc: 81.25%,  total acc: 73.15%   [EVAL] batch:  142 | acc: 93.75%,  total acc: 73.30%   [EVAL] batch:  143 | acc: 100.00%,  total acc: 73.48%   [EVAL] batch:  144 | acc: 75.00%,  total acc: 73.49%   [EVAL] batch:  145 | acc: 75.00%,  total acc: 73.50%   [EVAL] batch:  146 | acc: 68.75%,  total acc: 73.47%   [EVAL] batch:  147 | acc: 81.25%,  total acc: 73.52%   [EVAL] batch:  148 | acc: 81.25%,  total acc: 73.57%   [EVAL] batch:  149 | acc: 75.00%,  total acc: 73.58%   [EVAL] batch:  150 | acc: 68.75%,  total acc: 73.55%   [EVAL] batch:  151 | acc: 75.00%,  total acc: 73.56%   [EVAL] batch:  152 | acc: 56.25%,  total acc: 73.45%   [EVAL] batch:  153 | acc: 68.75%,  total acc: 73.42%   [EVAL] batch:  154 | acc: 50.00%,  total acc: 73.27%   [EVAL] batch:  155 | acc: 50.00%,  total acc: 73.12%   [EVAL] batch:  156 | acc: 43.75%,  total acc: 72.93%   [EVAL] batch:  157 | acc: 43.75%,  total acc: 72.75%   [EVAL] batch:  158 | acc: 43.75%,  total acc: 72.56%   [EVAL] batch:  159 | acc: 37.50%,  total acc: 72.34%   [EVAL] batch:  160 | acc: 50.00%,  total acc: 72.20%   [EVAL] batch:  161 | acc: 43.75%,  total acc: 72.03%   [EVAL] batch:  162 | acc: 37.50%,  total acc: 71.82%   [EVAL] batch:  163 | acc: 43.75%,  total acc: 71.65%   [EVAL] batch:  164 | acc: 62.50%,  total acc: 71.59%   [EVAL] batch:  165 | acc: 50.00%,  total acc: 71.46%   [EVAL] batch:  166 | acc: 37.50%,  total acc: 71.26%   [EVAL] batch:  167 | acc: 75.00%,  total acc: 71.28%   [EVAL] batch:  168 | acc: 56.25%,  total acc: 71.19%   [EVAL] batch:  169 | acc: 25.00%,  total acc: 70.92%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 70.69%   [EVAL] batch:  171 | acc: 18.75%,  total acc: 70.39%   [EVAL] batch:  172 | acc: 31.25%,  total acc: 70.16%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 69.90%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 69.71%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 69.89%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 70.06%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 70.22%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 70.39%   [EVAL] batch:  179 | acc: 100.00%,  total acc: 70.56%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 70.72%   [EVAL] batch:  181 | acc: 87.50%,  total acc: 70.81%   [EVAL] batch:  182 | acc: 93.75%,  total acc: 70.94%   [EVAL] batch:  183 | acc: 100.00%,  total acc: 71.09%   [EVAL] batch:  184 | acc: 100.00%,  total acc: 71.25%   [EVAL] batch:  185 | acc: 100.00%,  total acc: 71.40%   [EVAL] batch:  186 | acc: 100.00%,  total acc: 71.56%   [EVAL] batch:  187 | acc: 81.25%,  total acc: 71.61%   [EVAL] batch:  188 | acc: 87.50%,  total acc: 71.69%   [EVAL] batch:  189 | acc: 75.00%,  total acc: 71.71%   [EVAL] batch:  190 | acc: 68.75%,  total acc: 71.70%   [EVAL] batch:  191 | acc: 50.00%,  total acc: 71.58%   [EVAL] batch:  192 | acc: 81.25%,  total acc: 71.63%   [EVAL] batch:  193 | acc: 75.00%,  total acc: 71.65%   [EVAL] batch:  194 | acc: 81.25%,  total acc: 71.70%   [EVAL] batch:  195 | acc: 75.00%,  total acc: 71.72%   [EVAL] batch:  196 | acc: 56.25%,  total acc: 71.64%   [EVAL] batch:  197 | acc: 68.75%,  total acc: 71.62%   [EVAL] batch:  198 | acc: 93.75%,  total acc: 71.73%   [EVAL] batch:  199 | acc: 87.50%,  total acc: 71.81%   [EVAL] batch:  200 | acc: 100.00%,  total acc: 71.95%   [EVAL] batch:  201 | acc: 93.75%,  total acc: 72.06%   [EVAL] batch:  202 | acc: 87.50%,  total acc: 72.14%   [EVAL] batch:  203 | acc: 93.75%,  total acc: 72.24%   [EVAL] batch:  204 | acc: 87.50%,  total acc: 72.32%   [EVAL] batch:  205 | acc: 100.00%,  total acc: 72.45%   [EVAL] batch:  206 | acc: 62.50%,  total acc: 72.40%   [EVAL] batch:  207 | acc: 62.50%,  total acc: 72.36%   [EVAL] batch:  208 | acc: 81.25%,  total acc: 72.40%   [EVAL] batch:  209 | acc: 68.75%,  total acc: 72.38%   [EVAL] batch:  210 | acc: 75.00%,  total acc: 72.39%   [EVAL] batch:  211 | acc: 75.00%,  total acc: 72.41%   [EVAL] batch:  212 | acc: 75.00%,  total acc: 72.42%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 72.55%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 72.67%   [EVAL] batch:  215 | acc: 93.75%,  total acc: 72.77%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 72.90%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 73.02%   [EVAL] batch:  218 | acc: 93.75%,  total acc: 73.12%   [EVAL] batch:  219 | acc: 100.00%,  total acc: 73.24%   [EVAL] batch:  220 | acc: 100.00%,  total acc: 73.36%   [EVAL] batch:  221 | acc: 100.00%,  total acc: 73.48%   [EVAL] batch:  222 | acc: 100.00%,  total acc: 73.60%   [EVAL] batch:  223 | acc: 100.00%,  total acc: 73.72%   [EVAL] batch:  224 | acc: 100.00%,  total acc: 73.83%   [EVAL] batch:  225 | acc: 93.75%,  total acc: 73.92%   [EVAL] batch:  226 | acc: 93.75%,  total acc: 74.01%   [EVAL] batch:  227 | acc: 93.75%,  total acc: 74.10%   [EVAL] batch:  228 | acc: 87.50%,  total acc: 74.15%   [EVAL] batch:  229 | acc: 93.75%,  total acc: 74.24%   [EVAL] batch:  230 | acc: 87.50%,  total acc: 74.30%   [EVAL] batch:  231 | acc: 68.75%,  total acc: 74.27%   [EVAL] batch:  232 | acc: 43.75%,  total acc: 74.14%   [EVAL] batch:  233 | acc: 50.00%,  total acc: 74.04%   [EVAL] batch:  234 | acc: 43.75%,  total acc: 73.91%   [EVAL] batch:  235 | acc: 56.25%,  total acc: 73.83%   [EVAL] batch:  236 | acc: 50.00%,  total acc: 73.73%   [EVAL] batch:  237 | acc: 81.25%,  total acc: 73.77%   [EVAL] batch:  238 | acc: 87.50%,  total acc: 73.82%   [EVAL] batch:  239 | acc: 100.00%,  total acc: 73.93%   [EVAL] batch:  240 | acc: 87.50%,  total acc: 73.99%   [EVAL] batch:  241 | acc: 87.50%,  total acc: 74.04%   [EVAL] batch:  242 | acc: 93.75%,  total acc: 74.13%   [EVAL] batch:  243 | acc: 87.50%,  total acc: 74.18%   [EVAL] batch:  244 | acc: 43.75%,  total acc: 74.06%   [EVAL] batch:  245 | acc: 68.75%,  total acc: 74.03%   [EVAL] batch:  246 | acc: 62.50%,  total acc: 73.99%   [EVAL] batch:  247 | acc: 50.00%,  total acc: 73.89%   [EVAL] batch:  248 | acc: 56.25%,  total acc: 73.82%   [EVAL] batch:  249 | acc: 68.75%,  total acc: 73.80%   
cur_acc:  ['0.9454', '0.6677', '0.7510', '0.7976']
his_acc:  ['0.9454', '0.8035', '0.7530', '0.7380']
Clustering into  6  clusters
Clusters:  [2 4 2 2 1 1 5 2 2 2 2 2 2 5 5 2 2 2 0 2 5 2 2 2 2 5 2 1 2 5 2 2 2 2 2 2 0
 5 2 5 4 3 2 2 2 5 2 5 2 0]
Losses:  7.3806843757629395 1.3094496726989746
CurrentTrain: epoch  0, batch     0 | loss: 8.6901340Losses:  10.08378791809082 1.1584680080413818
CurrentTrain: epoch  0, batch     1 | loss: 11.2422562Losses:  9.578557968139648 1.191202998161316
CurrentTrain: epoch  0, batch     2 | loss: 10.7697611Losses:  9.30117130279541 1.3908097743988037
CurrentTrain: epoch  0, batch     3 | loss: 10.6919813Losses:  8.824050903320312 1.3523056507110596
CurrentTrain: epoch  0, batch     4 | loss: 10.1763563Losses:  8.857034683227539 1.4329851865768433
CurrentTrain: epoch  0, batch     5 | loss: 10.2900200Losses:  1.8699917793273926 1.0184680223464966
CurrentTrain: epoch  1, batch     0 | loss: 2.8884597Losses:  3.6112184524536133 1.255452275276184
CurrentTrain: epoch  1, batch     1 | loss: 4.8666706Losses:  2.9165940284729004 1.3672425746917725
CurrentTrain: epoch  1, batch     2 | loss: 4.2838364Losses:  2.2727818489074707 1.3086719512939453
CurrentTrain: epoch  1, batch     3 | loss: 3.5814538Losses:  3.074195384979248 1.1317710876464844
CurrentTrain: epoch  1, batch     4 | loss: 4.2059665Losses:  2.5510470867156982 0.6740296483039856
CurrentTrain: epoch  1, batch     5 | loss: 3.2250767Losses:  2.534003734588623 1.0580148696899414
CurrentTrain: epoch  2, batch     0 | loss: 3.5920186Losses:  2.1647660732269287 1.1319406032562256
CurrentTrain: epoch  2, batch     1 | loss: 3.2967067Losses:  2.314676284790039 1.017265796661377
CurrentTrain: epoch  2, batch     2 | loss: 3.3319421Losses:  2.801563024520874 1.1217526197433472
CurrentTrain: epoch  2, batch     3 | loss: 3.9233155Losses:  2.167086601257324 1.061840534210205
CurrentTrain: epoch  2, batch     4 | loss: 3.2289271Losses:  3.0173962116241455 0.7915900945663452
CurrentTrain: epoch  2, batch     5 | loss: 3.8089862Losses:  1.5028594732284546 0.9333895444869995
CurrentTrain: epoch  3, batch     0 | loss: 2.4362490Losses:  3.0135903358459473 1.141521692276001
CurrentTrain: epoch  3, batch     1 | loss: 4.1551123Losses:  1.7951018810272217 0.8342362642288208
CurrentTrain: epoch  3, batch     2 | loss: 2.6293383Losses:  2.4750280380249023 1.3688960075378418
CurrentTrain: epoch  3, batch     3 | loss: 3.8439240Losses:  2.3595755100250244 1.0451046228408813
CurrentTrain: epoch  3, batch     4 | loss: 3.4046803Losses:  2.662666082382202 0.9292470812797546
CurrentTrain: epoch  3, batch     5 | loss: 3.5919132Losses:  2.538011074066162 1.1022170782089233
CurrentTrain: epoch  4, batch     0 | loss: 3.6402283Losses:  2.059406280517578 1.1084656715393066
CurrentTrain: epoch  4, batch     1 | loss: 3.1678720Losses:  2.0300838947296143 0.928482174873352
CurrentTrain: epoch  4, batch     2 | loss: 2.9585662Losses:  2.0640573501586914 0.9650543928146362
CurrentTrain: epoch  4, batch     3 | loss: 3.0291119Losses:  1.8778729438781738 0.9616380929946899
CurrentTrain: epoch  4, batch     4 | loss: 2.8395109Losses:  1.9529558420181274 0.8461721539497375
CurrentTrain: epoch  4, batch     5 | loss: 2.7991281Losses:  2.3619372844696045 0.88541179895401
CurrentTrain: epoch  5, batch     0 | loss: 3.2473490Losses:  1.6770241260528564 0.7333287000656128
CurrentTrain: epoch  5, batch     1 | loss: 2.4103527Losses:  2.101271152496338 1.2531182765960693
CurrentTrain: epoch  5, batch     2 | loss: 3.3543894Losses:  1.6223864555358887 0.8583393096923828
CurrentTrain: epoch  5, batch     3 | loss: 2.4807258Losses:  2.198727607727051 0.9764425158500671
CurrentTrain: epoch  5, batch     4 | loss: 3.1751702Losses:  1.4672590494155884 0.5775424838066101
CurrentTrain: epoch  5, batch     5 | loss: 2.0448015Losses:  1.6669387817382812 0.8032270073890686
CurrentTrain: epoch  6, batch     0 | loss: 2.4701657Losses:  1.5481292009353638 1.0209053754806519
CurrentTrain: epoch  6, batch     1 | loss: 2.5690346Losses:  1.736077070236206 0.8820513486862183
CurrentTrain: epoch  6, batch     2 | loss: 2.6181283Losses:  2.256627082824707 0.8334117531776428
CurrentTrain: epoch  6, batch     3 | loss: 3.0900388Losses:  2.0381100177764893 0.7775052785873413
CurrentTrain: epoch  6, batch     4 | loss: 2.8156152Losses:  1.711344599723816 0.5444576144218445
CurrentTrain: epoch  6, batch     5 | loss: 2.2558022Losses:  1.2801029682159424 0.7673951387405396
CurrentTrain: epoch  7, batch     0 | loss: 2.0474982Losses:  2.1239829063415527 0.8545162677764893
CurrentTrain: epoch  7, batch     1 | loss: 2.9784992Losses:  2.011815071105957 0.746276319026947
CurrentTrain: epoch  7, batch     2 | loss: 2.7580914Losses:  1.429032564163208 0.7169508337974548
CurrentTrain: epoch  7, batch     3 | loss: 2.1459835Losses:  1.7942919731140137 0.7809279561042786
CurrentTrain: epoch  7, batch     4 | loss: 2.5752199Losses:  2.0014965534210205 0.7008091807365417
CurrentTrain: epoch  7, batch     5 | loss: 2.7023058Losses:  1.5474793910980225 0.5875534415245056
CurrentTrain: epoch  8, batch     0 | loss: 2.1350329Losses:  1.5264291763305664 0.7613818645477295
CurrentTrain: epoch  8, batch     1 | loss: 2.2878110Losses:  1.401658535003662 0.8255165815353394
CurrentTrain: epoch  8, batch     2 | loss: 2.2271752Losses:  1.8851289749145508 0.7246665954589844
CurrentTrain: epoch  8, batch     3 | loss: 2.6097956Losses:  1.8064602613449097 0.7438737750053406
CurrentTrain: epoch  8, batch     4 | loss: 2.5503340Losses:  1.872815728187561 0.6502522826194763
CurrentTrain: epoch  8, batch     5 | loss: 2.5230680Losses:  1.5587892532348633 0.5655570030212402
CurrentTrain: epoch  9, batch     0 | loss: 2.1243463Losses:  1.8653990030288696 0.503668487071991
CurrentTrain: epoch  9, batch     1 | loss: 2.3690674Losses:  1.241579532623291 0.699112594127655
CurrentTrain: epoch  9, batch     2 | loss: 1.9406922Losses:  1.6870015859603882 0.7095069885253906
CurrentTrain: epoch  9, batch     3 | loss: 2.3965087Losses:  1.5782430171966553 0.7484802007675171
CurrentTrain: epoch  9, batch     4 | loss: 2.3267231Losses:  1.5012315511703491 0.5495070815086365
CurrentTrain: epoch  9, batch     5 | loss: 2.0507386
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 92.19%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 89.29%   [EVAL] batch:    7 | acc: 68.75%,  total acc: 86.72%   [EVAL] batch:    8 | acc: 75.00%,  total acc: 85.42%   [EVAL] batch:    9 | acc: 56.25%,  total acc: 82.50%   [EVAL] batch:   10 | acc: 50.00%,  total acc: 79.55%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 78.65%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 80.29%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 82.50%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 83.20%   [EVAL] batch:   16 | acc: 87.50%,  total acc: 83.46%   [EVAL] batch:   17 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 85.20%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 85.31%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 86.01%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 86.65%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 87.23%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 88.00%   [EVAL] batch:   25 | acc: 68.75%,  total acc: 87.26%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 85.88%   [EVAL] batch:   27 | acc: 68.75%,  total acc: 85.27%   [EVAL] batch:   28 | acc: 62.50%,  total acc: 84.48%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 83.75%   [EVAL] batch:   30 | acc: 62.50%,  total acc: 83.06%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 82.81%   [EVAL] batch:   32 | acc: 62.50%,  total acc: 82.20%   [EVAL] batch:   33 | acc: 18.75%,  total acc: 80.33%   [EVAL] batch:   34 | acc: 56.25%,  total acc: 79.64%   [EVAL] batch:   35 | acc: 31.25%,  total acc: 78.30%   [EVAL] batch:   36 | acc: 25.00%,  total acc: 76.86%   [EVAL] batch:   37 | acc: 50.00%,  total acc: 76.15%   [EVAL] batch:   38 | acc: 62.50%,  total acc: 75.80%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 75.78%   [EVAL] batch:   40 | acc: 50.00%,  total acc: 75.15%   [EVAL] batch:   41 | acc: 68.75%,  total acc: 75.00%   [EVAL] batch:   42 | acc: 62.50%,  total acc: 74.71%   [EVAL] batch:   43 | acc: 56.25%,  total acc: 74.29%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 74.72%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 75.00%   [EVAL] batch:   46 | acc: 87.50%,  total acc: 75.27%   [EVAL] batch:   47 | acc: 75.00%,  total acc: 75.26%   [EVAL] batch:   48 | acc: 81.25%,  total acc: 75.38%   [EVAL] batch:   49 | acc: 75.00%,  total acc: 75.38%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 75.86%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 76.32%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 76.77%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 77.20%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 77.61%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 78.01%   [EVAL] batch:   56 | acc: 100.00%,  total acc: 78.40%   [EVAL] batch:   57 | acc: 100.00%,  total acc: 78.77%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 79.03%   [EVAL] batch:   59 | acc: 100.00%,  total acc: 79.38%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 79.71%   [EVAL] batch:   61 | acc: 100.00%,  total acc: 80.04%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 79.56%   
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 31.25%,  total acc: 83.04%   [EVAL] batch:    7 | acc: 25.00%,  total acc: 75.78%   [EVAL] batch:    8 | acc: 6.25%,  total acc: 68.06%   [EVAL] batch:    9 | acc: 12.50%,  total acc: 62.50%   [EVAL] batch:   10 | acc: 6.25%,  total acc: 57.39%   [EVAL] batch:   11 | acc: 6.25%,  total acc: 53.12%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 52.88%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 55.80%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 58.33%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 60.94%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 62.87%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 64.58%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 66.45%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 68.12%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 69.64%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 70.17%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 70.92%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 71.88%   [EVAL] batch:   24 | acc: 87.50%,  total acc: 72.50%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 73.56%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 74.54%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 75.45%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 76.29%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 77.08%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 77.82%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 78.52%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 79.17%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 79.41%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 79.46%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 79.86%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 80.41%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 80.92%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 81.41%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 81.88%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 82.32%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 82.44%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 82.70%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 82.81%   [EVAL] batch:   44 | acc: 68.75%,  total acc: 82.50%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 82.47%   [EVAL] batch:   46 | acc: 50.00%,  total acc: 81.78%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 81.51%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 81.63%   [EVAL] batch:   49 | acc: 56.25%,  total acc: 81.12%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 81.37%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 81.61%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 81.84%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 81.94%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 82.05%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 82.14%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 82.24%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 82.11%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 82.20%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 82.40%   [EVAL] batch:   60 | acc: 87.50%,  total acc: 82.48%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 82.56%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 82.04%   [EVAL] batch:   63 | acc: 6.25%,  total acc: 80.86%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 79.62%   [EVAL] batch:   65 | acc: 12.50%,  total acc: 78.60%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 77.71%   [EVAL] batch:   67 | acc: 12.50%,  total acc: 76.75%   [EVAL] batch:   68 | acc: 43.75%,  total acc: 76.27%   [EVAL] batch:   69 | acc: 68.75%,  total acc: 76.16%   [EVAL] batch:   70 | acc: 93.75%,  total acc: 76.41%   [EVAL] batch:   71 | acc: 87.50%,  total acc: 76.56%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 76.71%   [EVAL] batch:   73 | acc: 68.75%,  total acc: 76.60%   [EVAL] batch:   74 | acc: 75.00%,  total acc: 76.58%   [EVAL] batch:   75 | acc: 93.75%,  total acc: 76.81%   [EVAL] batch:   76 | acc: 81.25%,  total acc: 76.87%   [EVAL] batch:   77 | acc: 87.50%,  total acc: 77.00%   [EVAL] batch:   78 | acc: 87.50%,  total acc: 77.14%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 77.42%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 77.62%   [EVAL] batch:   81 | acc: 25.00%,  total acc: 76.98%   [EVAL] batch:   82 | acc: 12.50%,  total acc: 76.20%   [EVAL] batch:   83 | acc: 0.00%,  total acc: 75.30%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 74.56%   [EVAL] batch:   85 | acc: 6.25%,  total acc: 73.76%   [EVAL] batch:   86 | acc: 0.00%,  total acc: 72.92%   [EVAL] batch:   87 | acc: 18.75%,  total acc: 72.30%   [EVAL] batch:   88 | acc: 6.25%,  total acc: 71.56%   [EVAL] batch:   89 | acc: 6.25%,  total acc: 70.83%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 70.05%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 69.29%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 68.55%   [EVAL] batch:   93 | acc: 18.75%,  total acc: 68.02%   [EVAL] batch:   94 | acc: 87.50%,  total acc: 68.22%   [EVAL] batch:   95 | acc: 87.50%,  total acc: 68.42%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 68.56%   [EVAL] batch:   97 | acc: 93.75%,  total acc: 68.81%   [EVAL] batch:   98 | acc: 93.75%,  total acc: 69.07%   [EVAL] batch:   99 | acc: 87.50%,  total acc: 69.25%   [EVAL] batch:  100 | acc: 100.00%,  total acc: 69.55%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 69.79%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 70.02%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 70.31%   [EVAL] batch:  104 | acc: 100.00%,  total acc: 70.60%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 70.87%   [EVAL] batch:  106 | acc: 50.00%,  total acc: 70.68%   [EVAL] batch:  107 | acc: 43.75%,  total acc: 70.43%   [EVAL] batch:  108 | acc: 25.00%,  total acc: 70.01%   [EVAL] batch:  109 | acc: 37.50%,  total acc: 69.72%   [EVAL] batch:  110 | acc: 37.50%,  total acc: 69.43%   [EVAL] batch:  111 | acc: 18.75%,  total acc: 68.97%   [EVAL] batch:  112 | acc: 43.75%,  total acc: 68.75%   [EVAL] batch:  113 | acc: 68.75%,  total acc: 68.75%   [EVAL] batch:  114 | acc: 75.00%,  total acc: 68.80%   [EVAL] batch:  115 | acc: 100.00%,  total acc: 69.07%   [EVAL] batch:  116 | acc: 68.75%,  total acc: 69.07%   [EVAL] batch:  117 | acc: 87.50%,  total acc: 69.23%   [EVAL] batch:  118 | acc: 62.50%,  total acc: 69.17%   [EVAL] batch:  119 | acc: 43.75%,  total acc: 68.96%   [EVAL] batch:  120 | acc: 50.00%,  total acc: 68.80%   [EVAL] batch:  121 | acc: 43.75%,  total acc: 68.60%   [EVAL] batch:  122 | acc: 37.50%,  total acc: 68.34%   [EVAL] batch:  123 | acc: 50.00%,  total acc: 68.20%   [EVAL] batch:  124 | acc: 50.00%,  total acc: 68.05%   [EVAL] batch:  125 | acc: 12.50%,  total acc: 67.61%   [EVAL] batch:  126 | acc: 18.75%,  total acc: 67.22%   [EVAL] batch:  127 | acc: 25.00%,  total acc: 66.89%   [EVAL] batch:  128 | acc: 6.25%,  total acc: 66.42%   [EVAL] batch:  129 | acc: 37.50%,  total acc: 66.20%   [EVAL] batch:  130 | acc: 18.75%,  total acc: 65.84%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 65.96%   [EVAL] batch:  132 | acc: 93.75%,  total acc: 66.17%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 66.32%   [EVAL] batch:  134 | acc: 68.75%,  total acc: 66.34%   [EVAL] batch:  135 | acc: 87.50%,  total acc: 66.50%   [EVAL] batch:  136 | acc: 93.75%,  total acc: 66.70%   [EVAL] batch:  137 | acc: 81.25%,  total acc: 66.80%   [EVAL] batch:  138 | acc: 56.25%,  total acc: 66.73%   [EVAL] batch:  139 | acc: 56.25%,  total acc: 66.65%   [EVAL] batch:  140 | acc: 81.25%,  total acc: 66.76%   [EVAL] batch:  141 | acc: 81.25%,  total acc: 66.86%   [EVAL] batch:  142 | acc: 75.00%,  total acc: 66.91%   [EVAL] batch:  143 | acc: 87.50%,  total acc: 67.06%   [EVAL] batch:  144 | acc: 62.50%,  total acc: 67.03%   [EVAL] batch:  145 | acc: 75.00%,  total acc: 67.08%   [EVAL] batch:  146 | acc: 43.75%,  total acc: 66.92%   [EVAL] batch:  147 | acc: 62.50%,  total acc: 66.89%   [EVAL] batch:  148 | acc: 68.75%,  total acc: 66.90%   [EVAL] batch:  149 | acc: 68.75%,  total acc: 66.92%   [EVAL] batch:  150 | acc: 68.75%,  total acc: 66.93%   [EVAL] batch:  151 | acc: 68.75%,  total acc: 66.94%   [EVAL] batch:  152 | acc: 68.75%,  total acc: 66.95%   [EVAL] batch:  153 | acc: 81.25%,  total acc: 67.05%   [EVAL] batch:  154 | acc: 43.75%,  total acc: 66.90%   [EVAL] batch:  155 | acc: 43.75%,  total acc: 66.75%   [EVAL] batch:  156 | acc: 43.75%,  total acc: 66.60%   [EVAL] batch:  157 | acc: 50.00%,  total acc: 66.50%   [EVAL] batch:  158 | acc: 43.75%,  total acc: 66.35%   [EVAL] batch:  159 | acc: 43.75%,  total acc: 66.21%   [EVAL] batch:  160 | acc: 50.00%,  total acc: 66.11%   [EVAL] batch:  161 | acc: 56.25%,  total acc: 66.05%   [EVAL] batch:  162 | acc: 50.00%,  total acc: 65.95%   [EVAL] batch:  163 | acc: 56.25%,  total acc: 65.89%   [EVAL] batch:  164 | acc: 56.25%,  total acc: 65.83%   [EVAL] batch:  165 | acc: 62.50%,  total acc: 65.81%   [EVAL] batch:  166 | acc: 43.75%,  total acc: 65.68%   [EVAL] batch:  167 | acc: 62.50%,  total acc: 65.66%   [EVAL] batch:  168 | acc: 62.50%,  total acc: 65.64%   [EVAL] batch:  169 | acc: 31.25%,  total acc: 65.44%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 65.24%   [EVAL] batch:  171 | acc: 18.75%,  total acc: 64.97%   [EVAL] batch:  172 | acc: 37.50%,  total acc: 64.81%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 64.58%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 64.43%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 64.63%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 64.83%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 65.03%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 65.22%   [EVAL] batch:  179 | acc: 100.00%,  total acc: 65.42%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 65.61%   [EVAL] batch:  181 | acc: 87.50%,  total acc: 65.73%   [EVAL] batch:  182 | acc: 75.00%,  total acc: 65.78%   [EVAL] batch:  183 | acc: 87.50%,  total acc: 65.90%   [EVAL] batch:  184 | acc: 87.50%,  total acc: 66.01%   [EVAL] batch:  185 | acc: 87.50%,  total acc: 66.13%   [EVAL] batch:  186 | acc: 87.50%,  total acc: 66.24%   [EVAL] batch:  187 | acc: 56.25%,  total acc: 66.19%   [EVAL] batch:  188 | acc: 62.50%,  total acc: 66.17%   [EVAL] batch:  189 | acc: 68.75%,  total acc: 66.18%   [EVAL] batch:  190 | acc: 50.00%,  total acc: 66.10%   [EVAL] batch:  191 | acc: 43.75%,  total acc: 65.98%   [EVAL] batch:  192 | acc: 50.00%,  total acc: 65.90%   [EVAL] batch:  193 | acc: 75.00%,  total acc: 65.95%   [EVAL] batch:  194 | acc: 75.00%,  total acc: 65.99%   [EVAL] batch:  195 | acc: 75.00%,  total acc: 66.04%   [EVAL] batch:  196 | acc: 50.00%,  total acc: 65.96%   [EVAL] batch:  197 | acc: 68.75%,  total acc: 65.97%   [EVAL] batch:  198 | acc: 75.00%,  total acc: 66.02%   [EVAL] batch:  199 | acc: 81.25%,  total acc: 66.09%   [EVAL] batch:  200 | acc: 87.50%,  total acc: 66.20%   [EVAL] batch:  201 | acc: 87.50%,  total acc: 66.31%   [EVAL] batch:  202 | acc: 75.00%,  total acc: 66.35%   [EVAL] batch:  203 | acc: 87.50%,  total acc: 66.45%   [EVAL] batch:  204 | acc: 68.75%,  total acc: 66.46%   [EVAL] batch:  205 | acc: 100.00%,  total acc: 66.63%   [EVAL] batch:  206 | acc: 37.50%,  total acc: 66.49%   [EVAL] batch:  207 | acc: 43.75%,  total acc: 66.38%   [EVAL] batch:  208 | acc: 56.25%,  total acc: 66.33%   [EVAL] batch:  209 | acc: 25.00%,  total acc: 66.13%   [EVAL] batch:  210 | acc: 31.25%,  total acc: 65.97%   [EVAL] batch:  211 | acc: 50.00%,  total acc: 65.89%   [EVAL] batch:  212 | acc: 50.00%,  total acc: 65.82%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 65.98%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 66.13%   [EVAL] batch:  215 | acc: 100.00%,  total acc: 66.29%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 66.45%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 66.60%   [EVAL] batch:  218 | acc: 100.00%,  total acc: 66.75%   [EVAL] batch:  219 | acc: 100.00%,  total acc: 66.90%   [EVAL] batch:  220 | acc: 100.00%,  total acc: 67.05%   [EVAL] batch:  221 | acc: 100.00%,  total acc: 67.20%   [EVAL] batch:  222 | acc: 100.00%,  total acc: 67.35%   [EVAL] batch:  223 | acc: 100.00%,  total acc: 67.49%   [EVAL] batch:  224 | acc: 100.00%,  total acc: 67.64%   [EVAL] batch:  225 | acc: 87.50%,  total acc: 67.73%   [EVAL] batch:  226 | acc: 87.50%,  total acc: 67.81%   [EVAL] batch:  227 | acc: 87.50%,  total acc: 67.90%   [EVAL] batch:  228 | acc: 81.25%,  total acc: 67.96%   [EVAL] batch:  229 | acc: 93.75%,  total acc: 68.07%   [EVAL] batch:  230 | acc: 81.25%,  total acc: 68.13%   [EVAL] batch:  231 | acc: 68.75%,  total acc: 68.13%   [EVAL] batch:  232 | acc: 31.25%,  total acc: 67.97%   [EVAL] batch:  233 | acc: 50.00%,  total acc: 67.90%   [EVAL] batch:  234 | acc: 50.00%,  total acc: 67.82%   [EVAL] batch:  235 | acc: 56.25%,  total acc: 67.77%   [EVAL] batch:  236 | acc: 43.75%,  total acc: 67.67%   [EVAL] batch:  237 | acc: 87.50%,  total acc: 67.75%   [EVAL] batch:  238 | acc: 87.50%,  total acc: 67.83%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 67.94%   [EVAL] batch:  240 | acc: 87.50%,  total acc: 68.02%   [EVAL] batch:  241 | acc: 87.50%,  total acc: 68.10%   [EVAL] batch:  242 | acc: 93.75%,  total acc: 68.21%   [EVAL] batch:  243 | acc: 87.50%,  total acc: 68.29%   [EVAL] batch:  244 | acc: 50.00%,  total acc: 68.21%   [EVAL] batch:  245 | acc: 75.00%,  total acc: 68.24%   [EVAL] batch:  246 | acc: 68.75%,  total acc: 68.24%   [EVAL] batch:  247 | acc: 50.00%,  total acc: 68.17%   [EVAL] batch:  248 | acc: 68.75%,  total acc: 68.17%   [EVAL] batch:  249 | acc: 68.75%,  total acc: 68.17%   [EVAL] batch:  250 | acc: 93.75%,  total acc: 68.28%   [EVAL] batch:  251 | acc: 87.50%,  total acc: 68.35%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 68.45%   [EVAL] batch:  253 | acc: 93.75%,  total acc: 68.55%   [EVAL] batch:  254 | acc: 93.75%,  total acc: 68.65%   [EVAL] batch:  255 | acc: 100.00%,  total acc: 68.77%   [EVAL] batch:  256 | acc: 62.50%,  total acc: 68.75%   [EVAL] batch:  257 | acc: 68.75%,  total acc: 68.75%   [EVAL] batch:  258 | acc: 75.00%,  total acc: 68.77%   [EVAL] batch:  259 | acc: 56.25%,  total acc: 68.73%   [EVAL] batch:  260 | acc: 50.00%,  total acc: 68.65%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 68.65%   [EVAL] batch:  262 | acc: 100.00%,  total acc: 68.77%   [EVAL] batch:  263 | acc: 93.75%,  total acc: 68.87%   [EVAL] batch:  264 | acc: 100.00%,  total acc: 68.99%   [EVAL] batch:  265 | acc: 93.75%,  total acc: 69.08%   [EVAL] batch:  266 | acc: 87.50%,  total acc: 69.15%   [EVAL] batch:  267 | acc: 100.00%,  total acc: 69.26%   [EVAL] batch:  268 | acc: 100.00%,  total acc: 69.38%   [EVAL] batch:  269 | acc: 87.50%,  total acc: 69.44%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 69.56%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 69.67%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 69.78%   [EVAL] batch:  273 | acc: 93.75%,  total acc: 69.87%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 69.98%   [EVAL] batch:  275 | acc: 68.75%,  total acc: 69.97%   [EVAL] batch:  276 | acc: 50.00%,  total acc: 69.90%   [EVAL] batch:  277 | acc: 68.75%,  total acc: 69.90%   [EVAL] batch:  278 | acc: 62.50%,  total acc: 69.87%   [EVAL] batch:  279 | acc: 62.50%,  total acc: 69.84%   [EVAL] batch:  280 | acc: 62.50%,  total acc: 69.82%   [EVAL] batch:  281 | acc: 75.00%,  total acc: 69.84%   [EVAL] batch:  282 | acc: 62.50%,  total acc: 69.81%   [EVAL] batch:  283 | acc: 18.75%,  total acc: 69.63%   [EVAL] batch:  284 | acc: 56.25%,  total acc: 69.58%   [EVAL] batch:  285 | acc: 31.25%,  total acc: 69.45%   [EVAL] batch:  286 | acc: 25.00%,  total acc: 69.29%   [EVAL] batch:  287 | acc: 50.00%,  total acc: 69.23%   [EVAL] batch:  288 | acc: 62.50%,  total acc: 69.20%   [EVAL] batch:  289 | acc: 75.00%,  total acc: 69.22%   [EVAL] batch:  290 | acc: 50.00%,  total acc: 69.16%   [EVAL] batch:  291 | acc: 68.75%,  total acc: 69.16%   [EVAL] batch:  292 | acc: 62.50%,  total acc: 69.13%   [EVAL] batch:  293 | acc: 56.25%,  total acc: 69.09%   [EVAL] batch:  294 | acc: 93.75%,  total acc: 69.17%   [EVAL] batch:  295 | acc: 87.50%,  total acc: 69.24%   [EVAL] batch:  296 | acc: 87.50%,  total acc: 69.30%   [EVAL] batch:  297 | acc: 75.00%,  total acc: 69.32%   [EVAL] batch:  298 | acc: 81.25%,  total acc: 69.36%   [EVAL] batch:  299 | acc: 75.00%,  total acc: 69.38%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 69.48%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 69.58%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 69.68%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 69.78%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 69.88%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 69.98%   [EVAL] batch:  306 | acc: 100.00%,  total acc: 70.07%   [EVAL] batch:  307 | acc: 100.00%,  total acc: 70.17%   [EVAL] batch:  308 | acc: 93.75%,  total acc: 70.25%   [EVAL] batch:  309 | acc: 100.00%,  total acc: 70.34%   [EVAL] batch:  310 | acc: 100.00%,  total acc: 70.44%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 70.53%   [EVAL] batch:  312 | acc: 50.00%,  total acc: 70.47%   
cur_acc:  ['0.9454', '0.6677', '0.7510', '0.7976', '0.7956']
his_acc:  ['0.9454', '0.8035', '0.7530', '0.7380', '0.7047']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Losses:  7.0565643310546875 1.0639679431915283
CurrentTrain: epoch  0, batch     0 | loss: 8.1205320Losses:  9.210661888122559 1.1356658935546875
CurrentTrain: epoch  0, batch     1 | loss: 10.3463278Losses:  9.396540641784668 1.288712978363037
CurrentTrain: epoch  0, batch     2 | loss: 10.6852531Losses:  9.896652221679688 1.3875787258148193
CurrentTrain: epoch  0, batch     3 | loss: 11.2842312Losses:  9.306844711303711 1.186187744140625
CurrentTrain: epoch  0, batch     4 | loss: 10.4930325Losses:  9.51020622253418 1.2422460317611694
CurrentTrain: epoch  0, batch     5 | loss: 10.7524519Losses:  8.630077362060547 0.3625393509864807
CurrentTrain: epoch  0, batch     6 | loss: 8.9926167Losses:  3.1559154987335205 1.3350794315338135
CurrentTrain: epoch  1, batch     0 | loss: 4.4909949Losses:  2.880837917327881 0.8323159217834473
CurrentTrain: epoch  1, batch     1 | loss: 3.7131538Losses:  2.1542797088623047 1.0663968324661255
CurrentTrain: epoch  1, batch     2 | loss: 3.2206764Losses:  3.367842197418213 1.1866484880447388
CurrentTrain: epoch  1, batch     3 | loss: 4.5544906Losses:  2.390599250793457 1.1596721410751343
CurrentTrain: epoch  1, batch     4 | loss: 3.5502715Losses:  2.942704677581787 1.3002827167510986
CurrentTrain: epoch  1, batch     5 | loss: 4.2429876Losses:  2.8189644813537598 0.2877030372619629
CurrentTrain: epoch  1, batch     6 | loss: 3.1066675Losses:  2.634622812271118 1.3164196014404297
CurrentTrain: epoch  2, batch     0 | loss: 3.9510424Losses:  2.360508918762207 1.057321310043335
CurrentTrain: epoch  2, batch     1 | loss: 3.4178302Losses:  2.0259275436401367 0.8630063533782959
CurrentTrain: epoch  2, batch     2 | loss: 2.8889339Losses:  2.2639503479003906 0.9139814972877502
CurrentTrain: epoch  2, batch     3 | loss: 3.1779318Losses:  2.5747907161712646 1.2007150650024414
CurrentTrain: epoch  2, batch     4 | loss: 3.7755058Losses:  3.0177903175354004 1.3964906930923462
CurrentTrain: epoch  2, batch     5 | loss: 4.4142809Losses:  4.287099838256836 0.7034404277801514
CurrentTrain: epoch  2, batch     6 | loss: 4.9905405Losses:  1.7185291051864624 0.8913731575012207
CurrentTrain: epoch  3, batch     0 | loss: 2.6099024Losses:  2.77481746673584 1.07298743724823
CurrentTrain: epoch  3, batch     1 | loss: 3.8478050Losses:  2.072119951248169 1.0745521783828735
CurrentTrain: epoch  3, batch     2 | loss: 3.1466722Losses:  2.000657081604004 0.8034435510635376
CurrentTrain: epoch  3, batch     3 | loss: 2.8041005Losses:  3.0125458240509033 0.9757652282714844
CurrentTrain: epoch  3, batch     4 | loss: 3.9883111Losses:  2.2544736862182617 1.2023545503616333
CurrentTrain: epoch  3, batch     5 | loss: 3.4568281Losses:  3.3940930366516113 0.6091333627700806
CurrentTrain: epoch  3, batch     6 | loss: 4.0032263Losses:  1.5831985473632812 0.9720605611801147
CurrentTrain: epoch  4, batch     0 | loss: 2.5552592Losses:  3.0237979888916016 1.1307809352874756
CurrentTrain: epoch  4, batch     1 | loss: 4.1545792Losses:  2.2376856803894043 1.1124234199523926
CurrentTrain: epoch  4, batch     2 | loss: 3.3501091Losses:  1.8614132404327393 0.7561525106430054
CurrentTrain: epoch  4, batch     3 | loss: 2.6175656Losses:  1.7247886657714844 0.9422748684883118
CurrentTrain: epoch  4, batch     4 | loss: 2.6670635Losses:  3.015058994293213 0.9037497639656067
CurrentTrain: epoch  4, batch     5 | loss: 3.9188087Losses:  2.1139817237854004 0.4018230736255646
CurrentTrain: epoch  4, batch     6 | loss: 2.5158048Losses:  2.346796751022339 0.8585172891616821
CurrentTrain: epoch  5, batch     0 | loss: 3.2053142Losses:  1.8799569606781006 0.7561111450195312
CurrentTrain: epoch  5, batch     1 | loss: 2.6360681Losses:  1.939310073852539 1.0709519386291504
CurrentTrain: epoch  5, batch     2 | loss: 3.0102620Losses:  2.2625629901885986 0.958624005317688
CurrentTrain: epoch  5, batch     3 | loss: 3.2211871Losses:  2.290318727493286 0.8868976831436157
CurrentTrain: epoch  5, batch     4 | loss: 3.1772165Losses:  2.2141966819763184 0.9117276668548584
CurrentTrain: epoch  5, batch     5 | loss: 3.1259243Losses:  1.6285483837127686 0.3999594449996948
CurrentTrain: epoch  5, batch     6 | loss: 2.0285077Losses:  2.579275131225586 1.0036083459854126
CurrentTrain: epoch  6, batch     0 | loss: 3.5828834Losses:  1.869424819946289 0.7487644553184509
CurrentTrain: epoch  6, batch     1 | loss: 2.6181893Losses:  1.7114204168319702 0.7979425191879272
CurrentTrain: epoch  6, batch     2 | loss: 2.5093629Losses:  2.0336599349975586 0.7866912484169006
CurrentTrain: epoch  6, batch     3 | loss: 2.8203511Losses:  1.5488048791885376 0.7638005018234253
CurrentTrain: epoch  6, batch     4 | loss: 2.3126054Losses:  2.370232582092285 0.8205344676971436
CurrentTrain: epoch  6, batch     5 | loss: 3.1907670Losses:  1.5449481010437012 0.4591572880744934
CurrentTrain: epoch  6, batch     6 | loss: 2.0041053Losses:  1.5178639888763428 0.9499960541725159
CurrentTrain: epoch  7, batch     0 | loss: 2.4678600Losses:  1.7996107339859009 0.7342263460159302
CurrentTrain: epoch  7, batch     1 | loss: 2.5338371Losses:  1.9225574731826782 0.7605056762695312
CurrentTrain: epoch  7, batch     2 | loss: 2.6830630Losses:  1.985642910003662 0.7442427277565002
CurrentTrain: epoch  7, batch     3 | loss: 2.7298856Losses:  2.125369071960449 0.8719396591186523
CurrentTrain: epoch  7, batch     4 | loss: 2.9973087Losses:  1.73695707321167 0.9195215702056885
CurrentTrain: epoch  7, batch     5 | loss: 2.6564786Losses:  1.8251603841781616 0.13774466514587402
CurrentTrain: epoch  7, batch     6 | loss: 1.9629050Losses:  2.1665244102478027 0.8560017347335815
CurrentTrain: epoch  8, batch     0 | loss: 3.0225263Losses:  2.020801067352295 0.8622909188270569
CurrentTrain: epoch  8, batch     1 | loss: 2.8830919Losses:  1.5941462516784668 0.7309178709983826
CurrentTrain: epoch  8, batch     2 | loss: 2.3250642Losses:  1.1578381061553955 0.7531384229660034
CurrentTrain: epoch  8, batch     3 | loss: 1.9109765Losses:  1.938354730606079 0.7313851118087769
CurrentTrain: epoch  8, batch     4 | loss: 2.6697397Losses:  1.643290638923645 0.8538520336151123
CurrentTrain: epoch  8, batch     5 | loss: 2.4971428Losses:  2.747220754623413 0.48406070470809937
CurrentTrain: epoch  8, batch     6 | loss: 3.2312815Losses:  1.563804268836975 0.7779045104980469
CurrentTrain: epoch  9, batch     0 | loss: 2.3417087Losses:  1.6566858291625977 0.8077620267868042
CurrentTrain: epoch  9, batch     1 | loss: 2.4644480Losses:  1.462831735610962 0.7676016092300415
CurrentTrain: epoch  9, batch     2 | loss: 2.2304335Losses:  2.016505718231201 0.9083606600761414
CurrentTrain: epoch  9, batch     3 | loss: 2.9248664Losses:  2.182393789291382 0.6507601737976074
CurrentTrain: epoch  9, batch     4 | loss: 2.8331540Losses:  1.507561206817627 0.8208151459693909
CurrentTrain: epoch  9, batch     5 | loss: 2.3283763Losses:  1.4071965217590332 0.21186015009880066
CurrentTrain: epoch  9, batch     6 | loss: 1.6190567
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 50.00%,  total acc: 62.50%   [EVAL] batch:    2 | acc: 75.00%,  total acc: 66.67%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 71.88%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 75.00%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 76.04%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 77.68%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 79.69%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 80.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 81.82%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 82.81%   [EVAL] batch:   12 | acc: 68.75%,  total acc: 81.73%   [EVAL] batch:   13 | acc: 18.75%,  total acc: 77.23%   [EVAL] batch:   14 | acc: 31.25%,  total acc: 74.17%   [EVAL] batch:   15 | acc: 31.25%,  total acc: 71.48%   [EVAL] batch:   16 | acc: 37.50%,  total acc: 69.49%   [EVAL] batch:   17 | acc: 43.75%,  total acc: 68.06%   [EVAL] batch:   18 | acc: 37.50%,  total acc: 66.45%   [EVAL] batch:   19 | acc: 93.75%,  total acc: 67.81%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 69.35%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 70.74%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 72.01%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 73.18%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 74.00%   [EVAL] batch:   25 | acc: 18.75%,  total acc: 71.88%   [EVAL] batch:   26 | acc: 6.25%,  total acc: 69.44%   [EVAL] batch:   27 | acc: 18.75%,  total acc: 67.63%   [EVAL] batch:   28 | acc: 25.00%,  total acc: 66.16%   [EVAL] batch:   29 | acc: 6.25%,  total acc: 64.17%   [EVAL] batch:   30 | acc: 12.50%,  total acc: 62.50%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 62.89%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 63.83%   [EVAL] batch:   33 | acc: 100.00%,  total acc: 64.89%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 65.71%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 66.49%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 67.40%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 68.26%   [EVAL] batch:   38 | acc: 81.25%,  total acc: 68.59%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 69.22%   [EVAL] batch:   40 | acc: 93.75%,  total acc: 69.82%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 70.24%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 70.78%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 71.16%   [EVAL] batch:   44 | acc: 81.25%,  total acc: 71.39%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 71.88%   [EVAL] batch:   46 | acc: 93.75%,  total acc: 72.34%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 72.27%   [EVAL] batch:   48 | acc: 81.25%,  total acc: 72.45%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 72.75%   [EVAL] batch:   50 | acc: 68.75%,  total acc: 72.67%   [EVAL] batch:   51 | acc: 75.00%,  total acc: 72.72%   [EVAL] batch:   52 | acc: 68.75%,  total acc: 72.64%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 72.92%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 73.30%   [EVAL] batch:   55 | acc: 75.00%,  total acc: 73.33%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 73.36%   [EVAL] batch:   57 | acc: 81.25%,  total acc: 73.49%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 73.83%   [EVAL] batch:   59 | acc: 81.25%,  total acc: 73.96%   [EVAL] batch:   60 | acc: 93.75%,  total acc: 74.28%   [EVAL] batch:   61 | acc: 81.25%,  total acc: 74.40%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 74.01%   
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 50.00%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 43.75%,  total acc: 80.47%   [EVAL] batch:    8 | acc: 25.00%,  total acc: 74.31%   [EVAL] batch:    9 | acc: 31.25%,  total acc: 70.00%   [EVAL] batch:   10 | acc: 37.50%,  total acc: 67.05%   [EVAL] batch:   11 | acc: 37.50%,  total acc: 64.58%   [EVAL] batch:   12 | acc: 62.50%,  total acc: 64.42%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 66.52%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 68.33%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 70.31%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 71.69%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 74.34%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 75.00%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 75.60%   [EVAL] batch:   21 | acc: 75.00%,  total acc: 75.57%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 75.82%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 76.56%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 76.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 77.64%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 78.47%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 79.24%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 79.96%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 80.62%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 81.84%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 82.39%   [EVAL] batch:   33 | acc: 81.25%,  total acc: 82.35%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 82.32%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 82.64%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 83.11%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 83.55%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 83.97%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 84.76%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 84.82%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 85.03%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 85.09%   [EVAL] batch:   44 | acc: 81.25%,  total acc: 85.00%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 85.19%   [EVAL] batch:   46 | acc: 62.50%,  total acc: 84.71%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 84.38%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 84.69%   [EVAL] batch:   49 | acc: 81.25%,  total acc: 84.62%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 84.80%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 84.98%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 85.14%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 85.19%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 85.23%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 85.38%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 84.87%   [EVAL] batch:   57 | acc: 43.75%,  total acc: 84.16%   [EVAL] batch:   58 | acc: 56.25%,  total acc: 83.69%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 83.23%   [EVAL] batch:   60 | acc: 50.00%,  total acc: 82.68%   [EVAL] batch:   61 | acc: 81.25%,  total acc: 82.66%   [EVAL] batch:   62 | acc: 31.25%,  total acc: 81.85%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 80.57%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 79.33%   [EVAL] batch:   65 | acc: 0.00%,  total acc: 78.12%   [EVAL] batch:   66 | acc: 0.00%,  total acc: 76.96%   [EVAL] batch:   67 | acc: 0.00%,  total acc: 75.83%   [EVAL] batch:   68 | acc: 25.00%,  total acc: 75.09%   [EVAL] batch:   69 | acc: 62.50%,  total acc: 74.91%   [EVAL] batch:   70 | acc: 93.75%,  total acc: 75.18%   [EVAL] batch:   71 | acc: 93.75%,  total acc: 75.43%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 75.60%   [EVAL] batch:   73 | acc: 68.75%,  total acc: 75.51%   [EVAL] batch:   74 | acc: 62.50%,  total acc: 75.33%   [EVAL] batch:   75 | acc: 62.50%,  total acc: 75.16%   [EVAL] batch:   76 | acc: 43.75%,  total acc: 74.76%   [EVAL] batch:   77 | acc: 68.75%,  total acc: 74.68%   [EVAL] batch:   78 | acc: 62.50%,  total acc: 74.53%   [EVAL] batch:   79 | acc: 43.75%,  total acc: 74.14%   [EVAL] batch:   80 | acc: 43.75%,  total acc: 73.77%   [EVAL] batch:   81 | acc: 12.50%,  total acc: 73.02%   [EVAL] batch:   82 | acc: 12.50%,  total acc: 72.29%   [EVAL] batch:   83 | acc: 0.00%,  total acc: 71.43%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 70.74%   [EVAL] batch:   85 | acc: 6.25%,  total acc: 69.99%   [EVAL] batch:   86 | acc: 0.00%,  total acc: 69.18%   [EVAL] batch:   87 | acc: 12.50%,  total acc: 68.54%   [EVAL] batch:   88 | acc: 0.00%,  total acc: 67.77%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 67.01%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 66.28%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 65.56%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 64.85%   [EVAL] batch:   93 | acc: 18.75%,  total acc: 64.36%   [EVAL] batch:   94 | acc: 87.50%,  total acc: 64.61%   [EVAL] batch:   95 | acc: 81.25%,  total acc: 64.78%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 64.95%   [EVAL] batch:   97 | acc: 93.75%,  total acc: 65.24%   [EVAL] batch:   98 | acc: 68.75%,  total acc: 65.28%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 65.44%   [EVAL] batch:  100 | acc: 100.00%,  total acc: 65.78%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 66.05%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 66.32%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 66.65%   [EVAL] batch:  104 | acc: 100.00%,  total acc: 66.96%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 67.28%   [EVAL] batch:  106 | acc: 75.00%,  total acc: 67.35%   [EVAL] batch:  107 | acc: 50.00%,  total acc: 67.19%   [EVAL] batch:  108 | acc: 37.50%,  total acc: 66.92%   [EVAL] batch:  109 | acc: 50.00%,  total acc: 66.76%   [EVAL] batch:  110 | acc: 56.25%,  total acc: 66.67%   [EVAL] batch:  111 | acc: 31.25%,  total acc: 66.35%   [EVAL] batch:  112 | acc: 31.25%,  total acc: 66.04%   [EVAL] batch:  113 | acc: 43.75%,  total acc: 65.84%   [EVAL] batch:  114 | acc: 56.25%,  total acc: 65.76%   [EVAL] batch:  115 | acc: 81.25%,  total acc: 65.89%   [EVAL] batch:  116 | acc: 56.25%,  total acc: 65.81%   [EVAL] batch:  117 | acc: 62.50%,  total acc: 65.78%   [EVAL] batch:  118 | acc: 56.25%,  total acc: 65.70%   [EVAL] batch:  119 | acc: 37.50%,  total acc: 65.47%   [EVAL] batch:  120 | acc: 50.00%,  total acc: 65.34%   [EVAL] batch:  121 | acc: 43.75%,  total acc: 65.16%   [EVAL] batch:  122 | acc: 43.75%,  total acc: 64.99%   [EVAL] batch:  123 | acc: 62.50%,  total acc: 64.97%   [EVAL] batch:  124 | acc: 50.00%,  total acc: 64.85%   [EVAL] batch:  125 | acc: 6.25%,  total acc: 64.38%   [EVAL] batch:  126 | acc: 25.00%,  total acc: 64.07%   [EVAL] batch:  127 | acc: 31.25%,  total acc: 63.82%   [EVAL] batch:  128 | acc: 6.25%,  total acc: 63.37%   [EVAL] batch:  129 | acc: 37.50%,  total acc: 63.17%   [EVAL] batch:  130 | acc: 12.50%,  total acc: 62.79%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 62.93%   [EVAL] batch:  132 | acc: 100.00%,  total acc: 63.20%   [EVAL] batch:  133 | acc: 93.75%,  total acc: 63.43%   [EVAL] batch:  134 | acc: 81.25%,  total acc: 63.56%   [EVAL] batch:  135 | acc: 93.75%,  total acc: 63.79%   [EVAL] batch:  136 | acc: 100.00%,  total acc: 64.05%   [EVAL] batch:  137 | acc: 93.75%,  total acc: 64.27%   [EVAL] batch:  138 | acc: 56.25%,  total acc: 64.21%   [EVAL] batch:  139 | acc: 43.75%,  total acc: 64.06%   [EVAL] batch:  140 | acc: 75.00%,  total acc: 64.14%   [EVAL] batch:  141 | acc: 75.00%,  total acc: 64.22%   [EVAL] batch:  142 | acc: 81.25%,  total acc: 64.34%   [EVAL] batch:  143 | acc: 75.00%,  total acc: 64.41%   [EVAL] batch:  144 | acc: 50.00%,  total acc: 64.31%   [EVAL] batch:  145 | acc: 50.00%,  total acc: 64.21%   [EVAL] batch:  146 | acc: 37.50%,  total acc: 64.03%   [EVAL] batch:  147 | acc: 43.75%,  total acc: 63.89%   [EVAL] batch:  148 | acc: 56.25%,  total acc: 63.84%   [EVAL] batch:  149 | acc: 25.00%,  total acc: 63.58%   [EVAL] batch:  150 | acc: 68.75%,  total acc: 63.62%   [EVAL] batch:  151 | acc: 81.25%,  total acc: 63.73%   [EVAL] batch:  152 | acc: 75.00%,  total acc: 63.81%   [EVAL] batch:  153 | acc: 81.25%,  total acc: 63.92%   [EVAL] batch:  154 | acc: 56.25%,  total acc: 63.87%   [EVAL] batch:  155 | acc: 43.75%,  total acc: 63.74%   [EVAL] batch:  156 | acc: 50.00%,  total acc: 63.65%   [EVAL] batch:  157 | acc: 43.75%,  total acc: 63.53%   [EVAL] batch:  158 | acc: 37.50%,  total acc: 63.36%   [EVAL] batch:  159 | acc: 37.50%,  total acc: 63.20%   [EVAL] batch:  160 | acc: 43.75%,  total acc: 63.08%   [EVAL] batch:  161 | acc: 50.00%,  total acc: 63.00%   [EVAL] batch:  162 | acc: 50.00%,  total acc: 62.92%   [EVAL] batch:  163 | acc: 56.25%,  total acc: 62.88%   [EVAL] batch:  164 | acc: 56.25%,  total acc: 62.84%   [EVAL] batch:  165 | acc: 56.25%,  total acc: 62.80%   [EVAL] batch:  166 | acc: 50.00%,  total acc: 62.72%   [EVAL] batch:  167 | acc: 68.75%,  total acc: 62.76%   [EVAL] batch:  168 | acc: 62.50%,  total acc: 62.76%   [EVAL] batch:  169 | acc: 31.25%,  total acc: 62.57%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 62.39%   [EVAL] batch:  171 | acc: 18.75%,  total acc: 62.14%   [EVAL] batch:  172 | acc: 31.25%,  total acc: 61.96%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 61.75%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 61.61%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 61.83%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 62.04%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 62.25%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 62.47%   [EVAL] batch:  179 | acc: 100.00%,  total acc: 62.67%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 62.88%   [EVAL] batch:  181 | acc: 87.50%,  total acc: 63.02%   [EVAL] batch:  182 | acc: 68.75%,  total acc: 63.05%   [EVAL] batch:  183 | acc: 87.50%,  total acc: 63.18%   [EVAL] batch:  184 | acc: 87.50%,  total acc: 63.31%   [EVAL] batch:  185 | acc: 81.25%,  total acc: 63.41%   [EVAL] batch:  186 | acc: 75.00%,  total acc: 63.47%   [EVAL] batch:  187 | acc: 62.50%,  total acc: 63.46%   [EVAL] batch:  188 | acc: 68.75%,  total acc: 63.49%   [EVAL] batch:  189 | acc: 75.00%,  total acc: 63.55%   [EVAL] batch:  190 | acc: 56.25%,  total acc: 63.51%   [EVAL] batch:  191 | acc: 50.00%,  total acc: 63.44%   [EVAL] batch:  192 | acc: 50.00%,  total acc: 63.37%   [EVAL] batch:  193 | acc: 75.00%,  total acc: 63.43%   [EVAL] batch:  194 | acc: 68.75%,  total acc: 63.46%   [EVAL] batch:  195 | acc: 68.75%,  total acc: 63.49%   [EVAL] batch:  196 | acc: 43.75%,  total acc: 63.39%   [EVAL] batch:  197 | acc: 75.00%,  total acc: 63.45%   [EVAL] batch:  198 | acc: 75.00%,  total acc: 63.51%   [EVAL] batch:  199 | acc: 75.00%,  total acc: 63.56%   [EVAL] batch:  200 | acc: 87.50%,  total acc: 63.68%   [EVAL] batch:  201 | acc: 81.25%,  total acc: 63.77%   [EVAL] batch:  202 | acc: 75.00%,  total acc: 63.82%   [EVAL] batch:  203 | acc: 75.00%,  total acc: 63.88%   [EVAL] batch:  204 | acc: 68.75%,  total acc: 63.90%   [EVAL] batch:  205 | acc: 87.50%,  total acc: 64.02%   [EVAL] batch:  206 | acc: 37.50%,  total acc: 63.89%   [EVAL] batch:  207 | acc: 37.50%,  total acc: 63.76%   [EVAL] batch:  208 | acc: 56.25%,  total acc: 63.73%   [EVAL] batch:  209 | acc: 18.75%,  total acc: 63.51%   [EVAL] batch:  210 | acc: 25.00%,  total acc: 63.33%   [EVAL] batch:  211 | acc: 37.50%,  total acc: 63.21%   [EVAL] batch:  212 | acc: 50.00%,  total acc: 63.15%   [EVAL] batch:  213 | acc: 100.00%,  total acc: 63.32%   [EVAL] batch:  214 | acc: 100.00%,  total acc: 63.49%   [EVAL] batch:  215 | acc: 93.75%,  total acc: 63.63%   [EVAL] batch:  216 | acc: 100.00%,  total acc: 63.80%   [EVAL] batch:  217 | acc: 100.00%,  total acc: 63.96%   [EVAL] batch:  218 | acc: 93.75%,  total acc: 64.10%   [EVAL] batch:  219 | acc: 100.00%,  total acc: 64.26%   [EVAL] batch:  220 | acc: 100.00%,  total acc: 64.42%   [EVAL] batch:  221 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:  222 | acc: 100.00%,  total acc: 64.74%   [EVAL] batch:  223 | acc: 100.00%,  total acc: 64.90%   [EVAL] batch:  224 | acc: 100.00%,  total acc: 65.06%   [EVAL] batch:  225 | acc: 87.50%,  total acc: 65.15%   [EVAL] batch:  226 | acc: 87.50%,  total acc: 65.25%   [EVAL] batch:  227 | acc: 87.50%,  total acc: 65.35%   [EVAL] batch:  228 | acc: 81.25%,  total acc: 65.42%   [EVAL] batch:  229 | acc: 93.75%,  total acc: 65.54%   [EVAL] batch:  230 | acc: 81.25%,  total acc: 65.61%   [EVAL] batch:  231 | acc: 68.75%,  total acc: 65.62%   [EVAL] batch:  232 | acc: 31.25%,  total acc: 65.48%   [EVAL] batch:  233 | acc: 56.25%,  total acc: 65.44%   [EVAL] batch:  234 | acc: 56.25%,  total acc: 65.40%   [EVAL] batch:  235 | acc: 62.50%,  total acc: 65.39%   [EVAL] batch:  236 | acc: 50.00%,  total acc: 65.32%   [EVAL] batch:  237 | acc: 81.25%,  total acc: 65.39%   [EVAL] batch:  238 | acc: 87.50%,  total acc: 65.48%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 65.60%   [EVAL] batch:  240 | acc: 81.25%,  total acc: 65.66%   [EVAL] batch:  241 | acc: 87.50%,  total acc: 65.75%   [EVAL] batch:  242 | acc: 87.50%,  total acc: 65.84%   [EVAL] batch:  243 | acc: 81.25%,  total acc: 65.91%   [EVAL] batch:  244 | acc: 50.00%,  total acc: 65.84%   [EVAL] batch:  245 | acc: 62.50%,  total acc: 65.83%   [EVAL] batch:  246 | acc: 62.50%,  total acc: 65.81%   [EVAL] batch:  247 | acc: 50.00%,  total acc: 65.75%   [EVAL] batch:  248 | acc: 62.50%,  total acc: 65.74%   [EVAL] batch:  249 | acc: 68.75%,  total acc: 65.75%   [EVAL] batch:  250 | acc: 93.75%,  total acc: 65.86%   [EVAL] batch:  251 | acc: 87.50%,  total acc: 65.95%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 66.06%   [EVAL] batch:  253 | acc: 93.75%,  total acc: 66.17%   [EVAL] batch:  254 | acc: 93.75%,  total acc: 66.27%   [EVAL] batch:  255 | acc: 100.00%,  total acc: 66.41%   [EVAL] batch:  256 | acc: 68.75%,  total acc: 66.42%   [EVAL] batch:  257 | acc: 68.75%,  total acc: 66.42%   [EVAL] batch:  258 | acc: 81.25%,  total acc: 66.48%   [EVAL] batch:  259 | acc: 56.25%,  total acc: 66.44%   [EVAL] batch:  260 | acc: 43.75%,  total acc: 66.36%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 66.36%   [EVAL] batch:  262 | acc: 68.75%,  total acc: 66.37%   [EVAL] batch:  263 | acc: 50.00%,  total acc: 66.31%   [EVAL] batch:  264 | acc: 56.25%,  total acc: 66.27%   [EVAL] batch:  265 | acc: 43.75%,  total acc: 66.19%   [EVAL] batch:  266 | acc: 50.00%,  total acc: 66.13%   [EVAL] batch:  267 | acc: 50.00%,  total acc: 66.07%   [EVAL] batch:  268 | acc: 87.50%,  total acc: 66.15%   [EVAL] batch:  269 | acc: 87.50%,  total acc: 66.23%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 66.35%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 66.48%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 66.60%   [EVAL] batch:  273 | acc: 87.50%,  total acc: 66.67%   [EVAL] batch:  274 | acc: 93.75%,  total acc: 66.77%   [EVAL] batch:  275 | acc: 68.75%,  total acc: 66.78%   [EVAL] batch:  276 | acc: 43.75%,  total acc: 66.70%   [EVAL] batch:  277 | acc: 62.50%,  total acc: 66.68%   [EVAL] batch:  278 | acc: 68.75%,  total acc: 66.69%   [EVAL] batch:  279 | acc: 56.25%,  total acc: 66.65%   [EVAL] batch:  280 | acc: 62.50%,  total acc: 66.64%   [EVAL] batch:  281 | acc: 62.50%,  total acc: 66.62%   [EVAL] batch:  282 | acc: 62.50%,  total acc: 66.61%   [EVAL] batch:  283 | acc: 25.00%,  total acc: 66.46%   [EVAL] batch:  284 | acc: 56.25%,  total acc: 66.43%   [EVAL] batch:  285 | acc: 25.00%,  total acc: 66.28%   [EVAL] batch:  286 | acc: 18.75%,  total acc: 66.11%   [EVAL] batch:  287 | acc: 50.00%,  total acc: 66.06%   [EVAL] batch:  288 | acc: 62.50%,  total acc: 66.05%   [EVAL] batch:  289 | acc: 68.75%,  total acc: 66.06%   [EVAL] batch:  290 | acc: 50.00%,  total acc: 66.00%   [EVAL] batch:  291 | acc: 68.75%,  total acc: 66.01%   [EVAL] batch:  292 | acc: 62.50%,  total acc: 66.00%   [EVAL] batch:  293 | acc: 56.25%,  total acc: 65.97%   [EVAL] batch:  294 | acc: 87.50%,  total acc: 66.04%   [EVAL] batch:  295 | acc: 81.25%,  total acc: 66.09%   [EVAL] batch:  296 | acc: 75.00%,  total acc: 66.12%   [EVAL] batch:  297 | acc: 68.75%,  total acc: 66.13%   [EVAL] batch:  298 | acc: 81.25%,  total acc: 66.18%   [EVAL] batch:  299 | acc: 75.00%,  total acc: 66.21%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 66.32%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 66.43%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 66.54%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 66.65%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 66.76%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 66.87%   [EVAL] batch:  306 | acc: 100.00%,  total acc: 66.98%   [EVAL] batch:  307 | acc: 100.00%,  total acc: 67.09%   [EVAL] batch:  308 | acc: 93.75%,  total acc: 67.17%   [EVAL] batch:  309 | acc: 100.00%,  total acc: 67.28%   [EVAL] batch:  310 | acc: 100.00%,  total acc: 67.38%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 67.49%   [EVAL] batch:  312 | acc: 87.50%,  total acc: 67.55%   [EVAL] batch:  313 | acc: 68.75%,  total acc: 67.56%   [EVAL] batch:  314 | acc: 56.25%,  total acc: 67.52%   [EVAL] batch:  315 | acc: 87.50%,  total acc: 67.58%   [EVAL] batch:  316 | acc: 81.25%,  total acc: 67.63%   [EVAL] batch:  317 | acc: 81.25%,  total acc: 67.67%   [EVAL] batch:  318 | acc: 81.25%,  total acc: 67.71%   [EVAL] batch:  319 | acc: 100.00%,  total acc: 67.81%   [EVAL] batch:  320 | acc: 87.50%,  total acc: 67.87%   [EVAL] batch:  321 | acc: 87.50%,  total acc: 67.93%   [EVAL] batch:  322 | acc: 87.50%,  total acc: 68.00%   [EVAL] batch:  323 | acc: 93.75%,  total acc: 68.07%   [EVAL] batch:  324 | acc: 87.50%,  total acc: 68.13%   [EVAL] batch:  325 | acc: 25.00%,  total acc: 68.00%   [EVAL] batch:  326 | acc: 37.50%,  total acc: 67.91%   [EVAL] batch:  327 | acc: 25.00%,  total acc: 67.78%   [EVAL] batch:  328 | acc: 43.75%,  total acc: 67.71%   [EVAL] batch:  329 | acc: 37.50%,  total acc: 67.61%   [EVAL] batch:  330 | acc: 25.00%,  total acc: 67.48%   [EVAL] batch:  331 | acc: 75.00%,  total acc: 67.51%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 67.61%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 67.70%   [EVAL] batch:  334 | acc: 100.00%,  total acc: 67.80%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 67.89%   [EVAL] batch:  336 | acc: 93.75%,  total acc: 67.97%   [EVAL] batch:  337 | acc: 62.50%,  total acc: 67.95%   [EVAL] batch:  338 | acc: 6.25%,  total acc: 67.77%   [EVAL] batch:  339 | acc: 18.75%,  total acc: 67.63%   [EVAL] batch:  340 | acc: 18.75%,  total acc: 67.49%   [EVAL] batch:  341 | acc: 12.50%,  total acc: 67.32%   [EVAL] batch:  342 | acc: 6.25%,  total acc: 67.15%   [EVAL] batch:  343 | acc: 37.50%,  total acc: 67.06%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 67.16%   [EVAL] batch:  345 | acc: 93.75%,  total acc: 67.23%   [EVAL] batch:  346 | acc: 93.75%,  total acc: 67.31%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 67.39%   [EVAL] batch:  348 | acc: 100.00%,  total acc: 67.48%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 67.57%   [EVAL] batch:  350 | acc: 87.50%,  total acc: 67.63%   [EVAL] batch:  351 | acc: 87.50%,  total acc: 67.68%   [EVAL] batch:  352 | acc: 100.00%,  total acc: 67.78%   [EVAL] batch:  353 | acc: 87.50%,  total acc: 67.83%   [EVAL] batch:  354 | acc: 93.75%,  total acc: 67.90%   [EVAL] batch:  355 | acc: 81.25%,  total acc: 67.94%   [EVAL] batch:  356 | acc: 87.50%,  total acc: 68.00%   [EVAL] batch:  357 | acc: 93.75%,  total acc: 68.07%   [EVAL] batch:  358 | acc: 87.50%,  total acc: 68.12%   [EVAL] batch:  359 | acc: 93.75%,  total acc: 68.19%   [EVAL] batch:  360 | acc: 75.00%,  total acc: 68.21%   [EVAL] batch:  361 | acc: 75.00%,  total acc: 68.23%   [EVAL] batch:  362 | acc: 81.25%,  total acc: 68.27%   [EVAL] batch:  363 | acc: 62.50%,  total acc: 68.25%   [EVAL] batch:  364 | acc: 75.00%,  total acc: 68.27%   [EVAL] batch:  365 | acc: 87.50%,  total acc: 68.32%   [EVAL] batch:  366 | acc: 87.50%,  total acc: 68.38%   [EVAL] batch:  367 | acc: 75.00%,  total acc: 68.39%   [EVAL] batch:  368 | acc: 68.75%,  total acc: 68.39%   [EVAL] batch:  369 | acc: 93.75%,  total acc: 68.46%   [EVAL] batch:  370 | acc: 87.50%,  total acc: 68.51%   [EVAL] batch:  371 | acc: 81.25%,  total acc: 68.55%   [EVAL] batch:  372 | acc: 87.50%,  total acc: 68.60%   [EVAL] batch:  373 | acc: 87.50%,  total acc: 68.65%   [EVAL] batch:  374 | acc: 93.75%,  total acc: 68.72%   
cur_acc:  ['0.9454', '0.6677', '0.7510', '0.7976', '0.7956', '0.7401']
his_acc:  ['0.9454', '0.8035', '0.7530', '0.7380', '0.7047', '0.6872']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]
Losses:  6.952063083648682 0.8941417932510376
CurrentTrain: epoch  0, batch     0 | loss: 7.8462048Losses:  10.335199356079102 1.3159286975860596
CurrentTrain: epoch  0, batch     1 | loss: 11.6511278Losses:  8.627425193786621 0.9264714121818542
CurrentTrain: epoch  0, batch     2 | loss: 9.5538969Losses:  9.889948844909668 1.2045361995697021
CurrentTrain: epoch  0, batch     3 | loss: 11.0944853Losses:  9.235268592834473 1.2502481937408447
CurrentTrain: epoch  0, batch     4 | loss: 10.4855165Losses:  8.856330871582031 0.9824394583702087
CurrentTrain: epoch  0, batch     5 | loss: 9.8387699Losses:  8.978514671325684 0.8572713732719421
CurrentTrain: epoch  0, batch     6 | loss: 9.8357859Losses:  2.11443829536438 0.8106204271316528
CurrentTrain: epoch  1, batch     0 | loss: 2.9250588Losses:  1.873415470123291 0.9674379229545593
CurrentTrain: epoch  1, batch     1 | loss: 2.8408535Losses:  2.4828548431396484 1.1698380708694458
CurrentTrain: epoch  1, batch     2 | loss: 3.6526928Losses:  2.066356658935547 0.9235208034515381
CurrentTrain: epoch  1, batch     3 | loss: 2.9898775Losses:  2.0595033168792725 1.0168235301971436
CurrentTrain: epoch  1, batch     4 | loss: 3.0763268Losses:  2.0791990756988525 0.8455361127853394
CurrentTrain: epoch  1, batch     5 | loss: 2.9247351Losses:  2.900031089782715 0.8621037602424622
CurrentTrain: epoch  1, batch     6 | loss: 3.7621348Losses:  2.3074707984924316 0.9208522439002991
CurrentTrain: epoch  2, batch     0 | loss: 3.2283230Losses:  1.9661798477172852 1.014636754989624
CurrentTrain: epoch  2, batch     1 | loss: 2.9808166Losses:  2.272949695587158 0.8224743604660034
CurrentTrain: epoch  2, batch     2 | loss: 3.0954242Losses:  1.7805287837982178 0.8619939684867859
CurrentTrain: epoch  2, batch     3 | loss: 2.6425228Losses:  1.506898045539856 0.9211301207542419
CurrentTrain: epoch  2, batch     4 | loss: 2.4280281Losses:  1.6296980381011963 0.8602684736251831
CurrentTrain: epoch  2, batch     5 | loss: 2.4899664Losses:  2.715052604675293 0.9099794626235962
CurrentTrain: epoch  2, batch     6 | loss: 3.6250319Losses:  2.2046732902526855 0.9414454102516174
CurrentTrain: epoch  3, batch     0 | loss: 3.1461186Losses:  1.418807029724121 0.6924207210540771
CurrentTrain: epoch  3, batch     1 | loss: 2.1112278Losses:  2.5849218368530273 1.095442295074463
CurrentTrain: epoch  3, batch     2 | loss: 3.6803641Losses:  1.594167947769165 0.967711329460144
CurrentTrain: epoch  3, batch     3 | loss: 2.5618792Losses:  1.8985443115234375 0.8668621778488159
CurrentTrain: epoch  3, batch     4 | loss: 2.7654066Losses:  1.403610348701477 0.6271216869354248
CurrentTrain: epoch  3, batch     5 | loss: 2.0307322Losses:  1.8082823753356934 0.7474369406700134
CurrentTrain: epoch  3, batch     6 | loss: 2.5557194Losses:  1.9835972785949707 0.8667247295379639
CurrentTrain: epoch  4, batch     0 | loss: 2.8503220Losses:  1.9010688066482544 0.7799652814865112
CurrentTrain: epoch  4, batch     1 | loss: 2.6810341Losses:  1.2659872770309448 0.9431279897689819
CurrentTrain: epoch  4, batch     2 | loss: 2.2091153Losses:  1.5328781604766846 0.6813485622406006
CurrentTrain: epoch  4, batch     3 | loss: 2.2142267Losses:  1.8032186031341553 0.8075153231620789
CurrentTrain: epoch  4, batch     4 | loss: 2.6107340Losses:  1.7729414701461792 0.7774707674980164
CurrentTrain: epoch  4, batch     5 | loss: 2.5504122Losses:  1.8200886249542236 0.6542003154754639
CurrentTrain: epoch  4, batch     6 | loss: 2.4742889Losses:  1.6577701568603516 0.8034900426864624
CurrentTrain: epoch  5, batch     0 | loss: 2.4612603Losses:  1.788965106010437 0.6825786828994751
CurrentTrain: epoch  5, batch     1 | loss: 2.4715438Losses:  1.7237344980239868 0.9427292346954346
CurrentTrain: epoch  5, batch     2 | loss: 2.6664639Losses:  1.5178418159484863 0.6207407712936401
CurrentTrain: epoch  5, batch     3 | loss: 2.1385827Losses:  1.486253261566162 0.7325706481933594
CurrentTrain: epoch  5, batch     4 | loss: 2.2188239Losses:  1.7096428871154785 0.638523280620575
CurrentTrain: epoch  5, batch     5 | loss: 2.3481662Losses:  1.570562481880188 0.6107473373413086
CurrentTrain: epoch  5, batch     6 | loss: 2.1813097Losses:  1.5047643184661865 0.6238906979560852
CurrentTrain: epoch  6, batch     0 | loss: 2.1286550Losses:  1.821561336517334 0.5809614658355713
CurrentTrain: epoch  6, batch     1 | loss: 2.4025228Losses:  1.547240972518921 0.8492339253425598
CurrentTrain: epoch  6, batch     2 | loss: 2.3964748Losses:  1.6593729257583618 0.7062498927116394
CurrentTrain: epoch  6, batch     3 | loss: 2.3656228Losses:  1.7080764770507812 0.6624068021774292
CurrentTrain: epoch  6, batch     4 | loss: 2.3704834Losses:  1.1345750093460083 0.8785238265991211
CurrentTrain: epoch  6, batch     5 | loss: 2.0130987Losses:  1.4976487159729004 0.7061804533004761
CurrentTrain: epoch  6, batch     6 | loss: 2.2038293Losses:  1.2704790830612183 0.7429410219192505
CurrentTrain: epoch  7, batch     0 | loss: 2.0134201Losses:  1.3833014965057373 0.6687841415405273
CurrentTrain: epoch  7, batch     1 | loss: 2.0520856Losses:  1.6660493612289429 0.534714937210083
CurrentTrain: epoch  7, batch     2 | loss: 2.2007642Losses:  1.0038177967071533 0.48481619358062744
CurrentTrain: epoch  7, batch     3 | loss: 1.4886340Losses:  1.7067885398864746 0.6400463581085205
CurrentTrain: epoch  7, batch     4 | loss: 2.3468349Losses:  1.447323203086853 0.6544097661972046
CurrentTrain: epoch  7, batch     5 | loss: 2.1017330Losses:  1.9024375677108765 0.6949536204338074
CurrentTrain: epoch  7, batch     6 | loss: 2.5973911Losses:  1.3413959741592407 0.6822201013565063
CurrentTrain: epoch  8, batch     0 | loss: 2.0236161Losses:  1.4167009592056274 0.6739076375961304
CurrentTrain: epoch  8, batch     1 | loss: 2.0906086Losses:  1.2258492708206177 0.6158588528633118
CurrentTrain: epoch  8, batch     2 | loss: 1.8417082Losses:  1.4897892475128174 0.6259093284606934
CurrentTrain: epoch  8, batch     3 | loss: 2.1156986Losses:  1.344382405281067 0.7968235611915588
CurrentTrain: epoch  8, batch     4 | loss: 2.1412060Losses:  1.3221100568771362 0.6283422708511353
CurrentTrain: epoch  8, batch     5 | loss: 1.9504523Losses:  1.5637123584747314 0.6451685428619385
CurrentTrain: epoch  8, batch     6 | loss: 2.2088809Losses:  1.3540719747543335 0.5474556684494019
CurrentTrain: epoch  9, batch     0 | loss: 1.9015276Losses:  1.0109400749206543 0.4848463237285614
CurrentTrain: epoch  9, batch     1 | loss: 1.4957864Losses:  1.4239497184753418 0.657231330871582
CurrentTrain: epoch  9, batch     2 | loss: 2.0811810Losses:  1.6897733211517334 0.7265136241912842
CurrentTrain: epoch  9, batch     3 | loss: 2.4162869Losses:  1.4605185985565186 0.6623045802116394
CurrentTrain: epoch  9, batch     4 | loss: 2.1228232Losses:  1.090181589126587 0.630864143371582
CurrentTrain: epoch  9, batch     5 | loss: 1.7210457Losses:  1.2974785566329956 0.5734539031982422
CurrentTrain: epoch  9, batch     6 | loss: 1.8709325
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 91.07%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 91.41%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 90.97%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 91.25%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 92.05%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 91.83%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 90.18%   [EVAL] batch:   14 | acc: 62.50%,  total acc: 88.33%   [EVAL] batch:   15 | acc: 62.50%,  total acc: 86.72%   [EVAL] batch:   16 | acc: 56.25%,  total acc: 84.93%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 83.68%   [EVAL] batch:   18 | acc: 50.00%,  total acc: 81.91%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 81.25%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 81.55%   [EVAL] batch:   21 | acc: 62.50%,  total acc: 80.68%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 80.43%   [EVAL] batch:   23 | acc: 75.00%,  total acc: 80.21%   [EVAL] batch:   24 | acc: 56.25%,  total acc: 79.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 80.05%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 80.79%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 81.47%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 82.11%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 82.71%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 83.27%   [EVAL] batch:   31 | acc: 87.50%,  total acc: 83.40%   [EVAL] batch:   32 | acc: 87.50%,  total acc: 83.52%   [EVAL] batch:   33 | acc: 68.75%,  total acc: 83.09%   [EVAL] batch:   34 | acc: 87.50%,  total acc: 83.21%   [EVAL] batch:   35 | acc: 75.00%,  total acc: 82.99%   [EVAL] batch:   36 | acc: 68.75%,  total acc: 82.60%   [EVAL] batch:   37 | acc: 75.00%,  total acc: 82.40%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 82.85%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 83.28%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 83.69%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 84.08%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 84.45%   [EVAL] batch:   43 | acc: 93.75%,  total acc: 84.66%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 85.00%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 85.33%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 85.64%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 85.94%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 86.22%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 86.50%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 86.64%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 86.78%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 86.91%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 87.04%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 87.05%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 87.28%   [EVAL] batch:   56 | acc: 93.75%,  total acc: 87.39%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 87.61%   [EVAL] batch:   59 | acc: 100.00%,  total acc: 87.81%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 88.01%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 88.10%   [EVAL] batch:   62 | acc: 50.00%,  total acc: 87.50%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 88.54%   [EVAL] batch:    6 | acc: 56.25%,  total acc: 83.93%   [EVAL] batch:    7 | acc: 56.25%,  total acc: 80.47%   [EVAL] batch:    8 | acc: 37.50%,  total acc: 75.69%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 73.12%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 69.32%   [EVAL] batch:   11 | acc: 25.00%,  total acc: 65.62%   [EVAL] batch:   12 | acc: 62.50%,  total acc: 65.38%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 67.41%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 69.17%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 71.09%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 72.43%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 73.61%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 75.00%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:   21 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 75.26%   [EVAL] batch:   24 | acc: 75.00%,  total acc: 75.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 76.20%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 77.08%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 77.90%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 78.45%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 79.17%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 79.84%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 80.47%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 81.06%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 81.60%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 82.09%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 82.57%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 83.01%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 83.44%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 83.84%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 83.93%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 84.16%   [EVAL] batch:   43 | acc: 81.25%,  total acc: 84.09%   [EVAL] batch:   44 | acc: 81.25%,  total acc: 84.03%   [EVAL] batch:   45 | acc: 87.50%,  total acc: 84.10%   [EVAL] batch:   46 | acc: 75.00%,  total acc: 83.91%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 83.59%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 83.80%   [EVAL] batch:   49 | acc: 75.00%,  total acc: 83.62%   [EVAL] batch:   50 | acc: 75.00%,  total acc: 83.46%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 83.53%   [EVAL] batch:   52 | acc: 87.50%,  total acc: 83.61%   [EVAL] batch:   53 | acc: 62.50%,  total acc: 83.22%   [EVAL] batch:   54 | acc: 62.50%,  total acc: 82.84%   [EVAL] batch:   55 | acc: 68.75%,  total acc: 82.59%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 82.13%   [EVAL] batch:   57 | acc: 50.00%,  total acc: 81.57%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 81.25%   [EVAL] batch:   59 | acc: 68.75%,  total acc: 81.04%   [EVAL] batch:   60 | acc: 62.50%,  total acc: 80.74%   [EVAL] batch:   61 | acc: 81.25%,  total acc: 80.75%   [EVAL] batch:   62 | acc: 31.25%,  total acc: 79.96%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 78.71%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 77.50%   [EVAL] batch:   65 | acc: 0.00%,  total acc: 76.33%   [EVAL] batch:   66 | acc: 0.00%,  total acc: 75.19%   [EVAL] batch:   67 | acc: 0.00%,  total acc: 74.08%   [EVAL] batch:   68 | acc: 25.00%,  total acc: 73.37%   [EVAL] batch:   69 | acc: 62.50%,  total acc: 73.21%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 73.59%   [EVAL] batch:   71 | acc: 93.75%,  total acc: 73.87%   [EVAL] batch:   72 | acc: 87.50%,  total acc: 74.06%   [EVAL] batch:   73 | acc: 62.50%,  total acc: 73.90%   [EVAL] batch:   74 | acc: 75.00%,  total acc: 73.92%   [EVAL] batch:   75 | acc: 75.00%,  total acc: 73.93%   [EVAL] batch:   76 | acc: 56.25%,  total acc: 73.70%   [EVAL] batch:   77 | acc: 81.25%,  total acc: 73.80%   [EVAL] batch:   78 | acc: 81.25%,  total acc: 73.89%   [EVAL] batch:   79 | acc: 68.75%,  total acc: 73.83%   [EVAL] batch:   80 | acc: 62.50%,  total acc: 73.69%   [EVAL] batch:   81 | acc: 12.50%,  total acc: 72.94%   [EVAL] batch:   82 | acc: 12.50%,  total acc: 72.21%   [EVAL] batch:   83 | acc: 0.00%,  total acc: 71.35%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 70.66%   [EVAL] batch:   85 | acc: 12.50%,  total acc: 69.99%   [EVAL] batch:   86 | acc: 0.00%,  total acc: 69.18%   [EVAL] batch:   87 | acc: 18.75%,  total acc: 68.61%   [EVAL] batch:   88 | acc: 0.00%,  total acc: 67.84%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 67.08%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 66.35%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 65.62%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 64.92%   [EVAL] batch:   93 | acc: 18.75%,  total acc: 64.43%   [EVAL] batch:   94 | acc: 87.50%,  total acc: 64.67%   [EVAL] batch:   95 | acc: 87.50%,  total acc: 64.91%   [EVAL] batch:   96 | acc: 81.25%,  total acc: 65.08%   [EVAL] batch:   97 | acc: 93.75%,  total acc: 65.37%   [EVAL] batch:   98 | acc: 68.75%,  total acc: 65.40%   [EVAL] batch:   99 | acc: 75.00%,  total acc: 65.50%   [EVAL] batch:  100 | acc: 100.00%,  total acc: 65.84%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 66.12%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 66.38%   [EVAL] batch:  103 | acc: 93.75%,  total acc: 66.65%   [EVAL] batch:  104 | acc: 100.00%,  total acc: 66.96%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 67.28%   [EVAL] batch:  106 | acc: 75.00%,  total acc: 67.35%   [EVAL] batch:  107 | acc: 56.25%,  total acc: 67.25%   [EVAL] batch:  108 | acc: 50.00%,  total acc: 67.09%   [EVAL] batch:  109 | acc: 50.00%,  total acc: 66.93%   [EVAL] batch:  110 | acc: 50.00%,  total acc: 66.78%   [EVAL] batch:  111 | acc: 43.75%,  total acc: 66.57%   [EVAL] batch:  112 | acc: 25.00%,  total acc: 66.21%   [EVAL] batch:  113 | acc: 31.25%,  total acc: 65.90%   [EVAL] batch:  114 | acc: 50.00%,  total acc: 65.76%   [EVAL] batch:  115 | acc: 81.25%,  total acc: 65.89%   [EVAL] batch:  116 | acc: 62.50%,  total acc: 65.87%   [EVAL] batch:  117 | acc: 68.75%,  total acc: 65.89%   [EVAL] batch:  118 | acc: 50.00%,  total acc: 65.76%   [EVAL] batch:  119 | acc: 37.50%,  total acc: 65.52%   [EVAL] batch:  120 | acc: 37.50%,  total acc: 65.29%   [EVAL] batch:  121 | acc: 31.25%,  total acc: 65.01%   [EVAL] batch:  122 | acc: 25.00%,  total acc: 64.68%   [EVAL] batch:  123 | acc: 50.00%,  total acc: 64.57%   [EVAL] batch:  124 | acc: 43.75%,  total acc: 64.40%   [EVAL] batch:  125 | acc: 31.25%,  total acc: 64.14%   [EVAL] batch:  126 | acc: 31.25%,  total acc: 63.88%   [EVAL] batch:  127 | acc: 37.50%,  total acc: 63.67%   [EVAL] batch:  128 | acc: 6.25%,  total acc: 63.23%   [EVAL] batch:  129 | acc: 43.75%,  total acc: 63.08%   [EVAL] batch:  130 | acc: 18.75%,  total acc: 62.74%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 62.88%   [EVAL] batch:  132 | acc: 100.00%,  total acc: 63.16%   [EVAL] batch:  133 | acc: 87.50%,  total acc: 63.34%   [EVAL] batch:  134 | acc: 81.25%,  total acc: 63.47%   [EVAL] batch:  135 | acc: 100.00%,  total acc: 63.74%   [EVAL] batch:  136 | acc: 100.00%,  total acc: 64.01%   [EVAL] batch:  137 | acc: 93.75%,  total acc: 64.22%   [EVAL] batch:  138 | acc: 56.25%,  total acc: 64.16%   [EVAL] batch:  139 | acc: 68.75%,  total acc: 64.20%   [EVAL] batch:  140 | acc: 81.25%,  total acc: 64.32%   [EVAL] batch:  141 | acc: 81.25%,  total acc: 64.44%   [EVAL] batch:  142 | acc: 81.25%,  total acc: 64.55%   [EVAL] batch:  143 | acc: 81.25%,  total acc: 64.67%   [EVAL] batch:  144 | acc: 37.50%,  total acc: 64.48%   [EVAL] batch:  145 | acc: 43.75%,  total acc: 64.34%   [EVAL] batch:  146 | acc: 18.75%,  total acc: 64.03%   [EVAL] batch:  147 | acc: 31.25%,  total acc: 63.81%   [EVAL] batch:  148 | acc: 43.75%,  total acc: 63.67%   [EVAL] batch:  149 | acc: 18.75%,  total acc: 63.38%   [EVAL] batch:  150 | acc: 68.75%,  total acc: 63.41%   [EVAL] batch:  151 | acc: 75.00%,  total acc: 63.49%   [EVAL] batch:  152 | acc: 75.00%,  total acc: 63.56%   [EVAL] batch:  153 | acc: 81.25%,  total acc: 63.68%   [EVAL] batch:  154 | acc: 50.00%,  total acc: 63.59%   [EVAL] batch:  155 | acc: 43.75%,  total acc: 63.46%   [EVAL] batch:  156 | acc: 56.25%,  total acc: 63.42%   [EVAL] batch:  157 | acc: 50.00%,  total acc: 63.33%   [EVAL] batch:  158 | acc: 50.00%,  total acc: 63.25%   [EVAL] batch:  159 | acc: 43.75%,  total acc: 63.12%   [EVAL] batch:  160 | acc: 56.25%,  total acc: 63.08%   [EVAL] batch:  161 | acc: 50.00%,  total acc: 63.00%   [EVAL] batch:  162 | acc: 56.25%,  total acc: 62.96%   [EVAL] batch:  163 | acc: 68.75%,  total acc: 63.00%   [EVAL] batch:  164 | acc: 68.75%,  total acc: 63.03%   [EVAL] batch:  165 | acc: 56.25%,  total acc: 62.99%   [EVAL] batch:  166 | acc: 56.25%,  total acc: 62.95%   [EVAL] batch:  167 | acc: 81.25%,  total acc: 63.06%   [EVAL] batch:  168 | acc: 68.75%,  total acc: 63.09%   [EVAL] batch:  169 | acc: 31.25%,  total acc: 62.90%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 62.72%   [EVAL] batch:  171 | acc: 18.75%,  total acc: 62.46%   [EVAL] batch:  172 | acc: 37.50%,  total acc: 62.32%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 62.10%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 61.96%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 62.18%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 62.39%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 62.61%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 62.81%   [EVAL] batch:  179 | acc: 100.00%,  total acc: 63.02%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 63.23%   [EVAL] batch:  181 | acc: 87.50%,  total acc: 63.36%   [EVAL] batch:  182 | acc: 75.00%,  total acc: 63.42%   [EVAL] batch:  183 | acc: 87.50%,  total acc: 63.55%   [EVAL] batch:  184 | acc: 93.75%,  total acc: 63.72%   [EVAL] batch:  185 | acc: 81.25%,  total acc: 63.81%   [EVAL] batch:  186 | acc: 75.00%,  total acc: 63.87%   [EVAL] batch:  187 | acc: 68.75%,  total acc: 63.90%   [EVAL] batch:  188 | acc: 62.50%,  total acc: 63.89%   [EVAL] batch:  189 | acc: 68.75%,  total acc: 63.91%   [EVAL] batch:  190 | acc: 56.25%,  total acc: 63.87%   [EVAL] batch:  191 | acc: 50.00%,  total acc: 63.80%   [EVAL] batch:  192 | acc: 50.00%,  total acc: 63.73%   [EVAL] batch:  193 | acc: 68.75%,  total acc: 63.76%   [EVAL] batch:  194 | acc: 56.25%,  total acc: 63.72%   [EVAL] batch:  195 | acc: 56.25%,  total acc: 63.68%   [EVAL] batch:  196 | acc: 43.75%,  total acc: 63.58%   [EVAL] batch:  197 | acc: 75.00%,  total acc: 63.64%   [EVAL] batch:  198 | acc: 68.75%,  total acc: 63.66%   [EVAL] batch:  199 | acc: 68.75%,  total acc: 63.69%   [EVAL] batch:  200 | acc: 75.00%,  total acc: 63.74%   [EVAL] batch:  201 | acc: 87.50%,  total acc: 63.86%   [EVAL] batch:  202 | acc: 75.00%,  total acc: 63.92%   [EVAL] batch:  203 | acc: 81.25%,  total acc: 64.00%   [EVAL] batch:  204 | acc: 68.75%,  total acc: 64.02%   [EVAL] batch:  205 | acc: 93.75%,  total acc: 64.17%   [EVAL] batch:  206 | acc: 37.50%,  total acc: 64.04%   [EVAL] batch:  207 | acc: 37.50%,  total acc: 63.91%   [EVAL] batch:  208 | acc: 50.00%,  total acc: 63.85%   [EVAL] batch:  209 | acc: 25.00%,  total acc: 63.66%   [EVAL] batch:  210 | acc: 25.00%,  total acc: 63.48%   [EVAL] batch:  211 | acc: 37.50%,  total acc: 63.35%   [EVAL] batch:  212 | acc: 37.50%,  total acc: 63.23%   [EVAL] batch:  213 | acc: 87.50%,  total acc: 63.35%   [EVAL] batch:  214 | acc: 68.75%,  total acc: 63.37%   [EVAL] batch:  215 | acc: 37.50%,  total acc: 63.25%   [EVAL] batch:  216 | acc: 93.75%,  total acc: 63.39%   [EVAL] batch:  217 | acc: 68.75%,  total acc: 63.42%   [EVAL] batch:  218 | acc: 68.75%,  total acc: 63.44%   [EVAL] batch:  219 | acc: 100.00%,  total acc: 63.61%   [EVAL] batch:  220 | acc: 100.00%,  total acc: 63.77%   [EVAL] batch:  221 | acc: 100.00%,  total acc: 63.94%   [EVAL] batch:  222 | acc: 100.00%,  total acc: 64.10%   [EVAL] batch:  223 | acc: 100.00%,  total acc: 64.26%   [EVAL] batch:  224 | acc: 100.00%,  total acc: 64.42%   [EVAL] batch:  225 | acc: 87.50%,  total acc: 64.52%   [EVAL] batch:  226 | acc: 87.50%,  total acc: 64.62%   [EVAL] batch:  227 | acc: 75.00%,  total acc: 64.67%   [EVAL] batch:  228 | acc: 81.25%,  total acc: 64.74%   [EVAL] batch:  229 | acc: 93.75%,  total acc: 64.86%   [EVAL] batch:  230 | acc: 81.25%,  total acc: 64.94%   [EVAL] batch:  231 | acc: 62.50%,  total acc: 64.92%   [EVAL] batch:  232 | acc: 31.25%,  total acc: 64.78%   [EVAL] batch:  233 | acc: 50.00%,  total acc: 64.72%   [EVAL] batch:  234 | acc: 43.75%,  total acc: 64.63%   [EVAL] batch:  235 | acc: 50.00%,  total acc: 64.57%   [EVAL] batch:  236 | acc: 50.00%,  total acc: 64.50%   [EVAL] batch:  237 | acc: 75.00%,  total acc: 64.55%   [EVAL] batch:  238 | acc: 87.50%,  total acc: 64.64%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 64.77%   [EVAL] batch:  240 | acc: 81.25%,  total acc: 64.83%   [EVAL] batch:  241 | acc: 87.50%,  total acc: 64.93%   [EVAL] batch:  242 | acc: 93.75%,  total acc: 65.05%   [EVAL] batch:  243 | acc: 81.25%,  total acc: 65.11%   [EVAL] batch:  244 | acc: 56.25%,  total acc: 65.08%   [EVAL] batch:  245 | acc: 68.75%,  total acc: 65.09%   [EVAL] batch:  246 | acc: 62.50%,  total acc: 65.08%   [EVAL] batch:  247 | acc: 50.00%,  total acc: 65.02%   [EVAL] batch:  248 | acc: 56.25%,  total acc: 64.98%   [EVAL] batch:  249 | acc: 75.00%,  total acc: 65.03%   [EVAL] batch:  250 | acc: 75.00%,  total acc: 65.06%   [EVAL] batch:  251 | acc: 87.50%,  total acc: 65.15%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 65.27%   [EVAL] batch:  253 | acc: 87.50%,  total acc: 65.35%   [EVAL] batch:  254 | acc: 93.75%,  total acc: 65.47%   [EVAL] batch:  255 | acc: 93.75%,  total acc: 65.58%   [EVAL] batch:  256 | acc: 68.75%,  total acc: 65.59%   [EVAL] batch:  257 | acc: 68.75%,  total acc: 65.60%   [EVAL] batch:  258 | acc: 68.75%,  total acc: 65.61%   [EVAL] batch:  259 | acc: 50.00%,  total acc: 65.55%   [EVAL] batch:  260 | acc: 43.75%,  total acc: 65.47%   [EVAL] batch:  261 | acc: 68.75%,  total acc: 65.48%   [EVAL] batch:  262 | acc: 68.75%,  total acc: 65.49%   [EVAL] batch:  263 | acc: 50.00%,  total acc: 65.44%   [EVAL] batch:  264 | acc: 50.00%,  total acc: 65.38%   [EVAL] batch:  265 | acc: 37.50%,  total acc: 65.27%   [EVAL] batch:  266 | acc: 43.75%,  total acc: 65.19%   [EVAL] batch:  267 | acc: 43.75%,  total acc: 65.11%   [EVAL] batch:  268 | acc: 75.00%,  total acc: 65.15%   [EVAL] batch:  269 | acc: 93.75%,  total acc: 65.25%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 65.38%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 65.51%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 65.64%   [EVAL] batch:  273 | acc: 87.50%,  total acc: 65.72%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 65.84%   [EVAL] batch:  275 | acc: 62.50%,  total acc: 65.83%   [EVAL] batch:  276 | acc: 31.25%,  total acc: 65.70%   [EVAL] batch:  277 | acc: 62.50%,  total acc: 65.69%   [EVAL] batch:  278 | acc: 62.50%,  total acc: 65.68%   [EVAL] batch:  279 | acc: 43.75%,  total acc: 65.60%   [EVAL] batch:  280 | acc: 56.25%,  total acc: 65.57%   [EVAL] batch:  281 | acc: 62.50%,  total acc: 65.56%   [EVAL] batch:  282 | acc: 62.50%,  total acc: 65.55%   [EVAL] batch:  283 | acc: 18.75%,  total acc: 65.38%   [EVAL] batch:  284 | acc: 56.25%,  total acc: 65.35%   [EVAL] batch:  285 | acc: 25.00%,  total acc: 65.21%   [EVAL] batch:  286 | acc: 12.50%,  total acc: 65.03%   [EVAL] batch:  287 | acc: 37.50%,  total acc: 64.93%   [EVAL] batch:  288 | acc: 31.25%,  total acc: 64.81%   [EVAL] batch:  289 | acc: 31.25%,  total acc: 64.70%   [EVAL] batch:  290 | acc: 31.25%,  total acc: 64.58%   [EVAL] batch:  291 | acc: 43.75%,  total acc: 64.51%   [EVAL] batch:  292 | acc: 50.00%,  total acc: 64.46%   [EVAL] batch:  293 | acc: 37.50%,  total acc: 64.37%   [EVAL] batch:  294 | acc: 81.25%,  total acc: 64.43%   [EVAL] batch:  295 | acc: 81.25%,  total acc: 64.48%   [EVAL] batch:  296 | acc: 75.00%,  total acc: 64.52%   [EVAL] batch:  297 | acc: 81.25%,  total acc: 64.58%   [EVAL] batch:  298 | acc: 81.25%,  total acc: 64.63%   [EVAL] batch:  299 | acc: 81.25%,  total acc: 64.69%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 64.80%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 64.92%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 65.04%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 65.15%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 65.27%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 65.38%   [EVAL] batch:  306 | acc: 100.00%,  total acc: 65.49%   [EVAL] batch:  307 | acc: 93.75%,  total acc: 65.58%   [EVAL] batch:  308 | acc: 93.75%,  total acc: 65.68%   [EVAL] batch:  309 | acc: 100.00%,  total acc: 65.79%   [EVAL] batch:  310 | acc: 100.00%,  total acc: 65.90%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 66.01%   [EVAL] batch:  312 | acc: 81.25%,  total acc: 66.05%   [EVAL] batch:  313 | acc: 62.50%,  total acc: 66.04%   [EVAL] batch:  314 | acc: 37.50%,  total acc: 65.95%   [EVAL] batch:  315 | acc: 81.25%,  total acc: 66.00%   [EVAL] batch:  316 | acc: 50.00%,  total acc: 65.95%   [EVAL] batch:  317 | acc: 68.75%,  total acc: 65.96%   [EVAL] batch:  318 | acc: 62.50%,  total acc: 65.95%   [EVAL] batch:  319 | acc: 100.00%,  total acc: 66.05%   [EVAL] batch:  320 | acc: 100.00%,  total acc: 66.16%   [EVAL] batch:  321 | acc: 87.50%,  total acc: 66.23%   [EVAL] batch:  322 | acc: 93.75%,  total acc: 66.31%   [EVAL] batch:  323 | acc: 93.75%,  total acc: 66.40%   [EVAL] batch:  324 | acc: 87.50%,  total acc: 66.46%   [EVAL] batch:  325 | acc: 31.25%,  total acc: 66.35%   [EVAL] batch:  326 | acc: 31.25%,  total acc: 66.25%   [EVAL] batch:  327 | acc: 18.75%,  total acc: 66.10%   [EVAL] batch:  328 | acc: 31.25%,  total acc: 66.00%   [EVAL] batch:  329 | acc: 37.50%,  total acc: 65.91%   [EVAL] batch:  330 | acc: 12.50%,  total acc: 65.75%   [EVAL] batch:  331 | acc: 75.00%,  total acc: 65.78%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 65.88%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 65.98%   [EVAL] batch:  334 | acc: 100.00%,  total acc: 66.08%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 66.18%   [EVAL] batch:  336 | acc: 93.75%,  total acc: 66.26%   [EVAL] batch:  337 | acc: 62.50%,  total acc: 66.25%   [EVAL] batch:  338 | acc: 0.00%,  total acc: 66.06%   [EVAL] batch:  339 | acc: 12.50%,  total acc: 65.90%   [EVAL] batch:  340 | acc: 6.25%,  total acc: 65.73%   [EVAL] batch:  341 | acc: 18.75%,  total acc: 65.59%   [EVAL] batch:  342 | acc: 0.00%,  total acc: 65.40%   [EVAL] batch:  343 | acc: 43.75%,  total acc: 65.33%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 65.43%   [EVAL] batch:  345 | acc: 93.75%,  total acc: 65.52%   [EVAL] batch:  346 | acc: 93.75%,  total acc: 65.60%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 65.68%   [EVAL] batch:  348 | acc: 100.00%,  total acc: 65.78%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 65.88%   [EVAL] batch:  350 | acc: 18.75%,  total acc: 65.74%   [EVAL] batch:  351 | acc: 31.25%,  total acc: 65.64%   [EVAL] batch:  352 | acc: 18.75%,  total acc: 65.51%   [EVAL] batch:  353 | acc: 18.75%,  total acc: 65.38%   [EVAL] batch:  354 | acc: 18.75%,  total acc: 65.25%   [EVAL] batch:  355 | acc: 18.75%,  total acc: 65.12%   [EVAL] batch:  356 | acc: 56.25%,  total acc: 65.09%   [EVAL] batch:  357 | acc: 81.25%,  total acc: 65.14%   [EVAL] batch:  358 | acc: 81.25%,  total acc: 65.18%   [EVAL] batch:  359 | acc: 87.50%,  total acc: 65.24%   [EVAL] batch:  360 | acc: 68.75%,  total acc: 65.25%   [EVAL] batch:  361 | acc: 68.75%,  total acc: 65.26%   [EVAL] batch:  362 | acc: 81.25%,  total acc: 65.31%   [EVAL] batch:  363 | acc: 62.50%,  total acc: 65.30%   [EVAL] batch:  364 | acc: 75.00%,  total acc: 65.33%   [EVAL] batch:  365 | acc: 68.75%,  total acc: 65.33%   [EVAL] batch:  366 | acc: 81.25%,  total acc: 65.38%   [EVAL] batch:  367 | acc: 75.00%,  total acc: 65.40%   [EVAL] batch:  368 | acc: 62.50%,  total acc: 65.40%   [EVAL] batch:  369 | acc: 87.50%,  total acc: 65.46%   [EVAL] batch:  370 | acc: 87.50%,  total acc: 65.52%   [EVAL] batch:  371 | acc: 81.25%,  total acc: 65.56%   [EVAL] batch:  372 | acc: 93.75%,  total acc: 65.63%   [EVAL] batch:  373 | acc: 81.25%,  total acc: 65.68%   [EVAL] batch:  374 | acc: 87.50%,  total acc: 65.73%   [EVAL] batch:  375 | acc: 93.75%,  total acc: 65.81%   [EVAL] batch:  376 | acc: 93.75%,  total acc: 65.88%   [EVAL] batch:  377 | acc: 87.50%,  total acc: 65.94%   [EVAL] batch:  378 | acc: 81.25%,  total acc: 65.98%   [EVAL] batch:  379 | acc: 93.75%,  total acc: 66.05%   [EVAL] batch:  380 | acc: 100.00%,  total acc: 66.14%   [EVAL] batch:  381 | acc: 87.50%,  total acc: 66.20%   [EVAL] batch:  382 | acc: 93.75%,  total acc: 66.27%   [EVAL] batch:  383 | acc: 87.50%,  total acc: 66.32%   [EVAL] batch:  384 | acc: 93.75%,  total acc: 66.40%   [EVAL] batch:  385 | acc: 100.00%,  total acc: 66.48%   [EVAL] batch:  386 | acc: 87.50%,  total acc: 66.54%   [EVAL] batch:  387 | acc: 93.75%,  total acc: 66.61%   [EVAL] batch:  388 | acc: 68.75%,  total acc: 66.61%   [EVAL] batch:  389 | acc: 62.50%,  total acc: 66.60%   [EVAL] batch:  390 | acc: 62.50%,  total acc: 66.59%   [EVAL] batch:  391 | acc: 56.25%,  total acc: 66.57%   [EVAL] batch:  392 | acc: 62.50%,  total acc: 66.56%   [EVAL] batch:  393 | acc: 50.00%,  total acc: 66.51%   [EVAL] batch:  394 | acc: 68.75%,  total acc: 66.52%   [EVAL] batch:  395 | acc: 87.50%,  total acc: 66.57%   [EVAL] batch:  396 | acc: 62.50%,  total acc: 66.56%   [EVAL] batch:  397 | acc: 75.00%,  total acc: 66.58%   [EVAL] batch:  398 | acc: 75.00%,  total acc: 66.60%   [EVAL] batch:  399 | acc: 56.25%,  total acc: 66.58%   [EVAL] batch:  400 | acc: 100.00%,  total acc: 66.66%   [EVAL] batch:  401 | acc: 100.00%,  total acc: 66.74%   [EVAL] batch:  402 | acc: 100.00%,  total acc: 66.83%   [EVAL] batch:  403 | acc: 100.00%,  total acc: 66.91%   [EVAL] batch:  404 | acc: 100.00%,  total acc: 66.99%   [EVAL] batch:  405 | acc: 100.00%,  total acc: 67.07%   [EVAL] batch:  406 | acc: 87.50%,  total acc: 67.12%   [EVAL] batch:  407 | acc: 87.50%,  total acc: 67.17%   [EVAL] batch:  408 | acc: 68.75%,  total acc: 67.18%   [EVAL] batch:  409 | acc: 87.50%,  total acc: 67.23%   [EVAL] batch:  410 | acc: 75.00%,  total acc: 67.24%   [EVAL] batch:  411 | acc: 68.75%,  total acc: 67.25%   [EVAL] batch:  412 | acc: 75.00%,  total acc: 67.27%   [EVAL] batch:  413 | acc: 100.00%,  total acc: 67.35%   [EVAL] batch:  414 | acc: 100.00%,  total acc: 67.42%   [EVAL] batch:  415 | acc: 100.00%,  total acc: 67.50%   [EVAL] batch:  416 | acc: 100.00%,  total acc: 67.58%   [EVAL] batch:  417 | acc: 100.00%,  total acc: 67.66%   [EVAL] batch:  418 | acc: 93.75%,  total acc: 67.72%   [EVAL] batch:  419 | acc: 100.00%,  total acc: 67.80%   [EVAL] batch:  420 | acc: 100.00%,  total acc: 67.87%   [EVAL] batch:  421 | acc: 100.00%,  total acc: 67.95%   [EVAL] batch:  422 | acc: 100.00%,  total acc: 68.03%   [EVAL] batch:  423 | acc: 100.00%,  total acc: 68.10%   [EVAL] batch:  424 | acc: 100.00%,  total acc: 68.18%   [EVAL] batch:  425 | acc: 93.75%,  total acc: 68.24%   [EVAL] batch:  426 | acc: 93.75%,  total acc: 68.30%   [EVAL] batch:  427 | acc: 93.75%,  total acc: 68.36%   [EVAL] batch:  428 | acc: 93.75%,  total acc: 68.41%   [EVAL] batch:  429 | acc: 87.50%,  total acc: 68.46%   [EVAL] batch:  430 | acc: 100.00%,  total acc: 68.53%   [EVAL] batch:  431 | acc: 93.75%,  total acc: 68.59%   [EVAL] batch:  432 | acc: 93.75%,  total acc: 68.65%   [EVAL] batch:  433 | acc: 93.75%,  total acc: 68.71%   [EVAL] batch:  434 | acc: 100.00%,  total acc: 68.78%   [EVAL] batch:  435 | acc: 100.00%,  total acc: 68.85%   [EVAL] batch:  436 | acc: 93.75%,  total acc: 68.91%   [EVAL] batch:  437 | acc: 50.00%,  total acc: 68.86%   
cur_acc:  ['0.9454', '0.6677', '0.7510', '0.7976', '0.7956', '0.7401', '0.8750']
his_acc:  ['0.9454', '0.8035', '0.7530', '0.7380', '0.7047', '0.6872', '0.6886']
Clustering into  2  clusters
Clusters:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0]
Losses:  7.124915599822998 1.1442244052886963
CurrentTrain: epoch  0, batch     0 | loss: 8.2691402Losses:  8.869804382324219 1.0357437133789062
CurrentTrain: epoch  0, batch     1 | loss: 9.9055481Losses:  9.68913459777832 1.1217222213745117
CurrentTrain: epoch  0, batch     2 | loss: 10.8108568Losses:  10.266263008117676 0.9574591517448425
CurrentTrain: epoch  0, batch     3 | loss: 11.2237225Losses:  10.003238677978516 1.1854948997497559
CurrentTrain: epoch  0, batch     4 | loss: 11.1887341Losses:  9.795694351196289 1.0625202655792236
CurrentTrain: epoch  0, batch     5 | loss: 10.8582144Losses:  9.267864227294922 1.20505690574646
CurrentTrain: epoch  0, batch     6 | loss: 10.4729214Losses:  8.281413078308105 0.8997676968574524
CurrentTrain: epoch  0, batch     7 | loss: 9.1811810Losses:  2.0626749992370605 0.9108288884162903
CurrentTrain: epoch  1, batch     0 | loss: 2.9735038Losses:  1.8157294988632202 0.8463441729545593
CurrentTrain: epoch  1, batch     1 | loss: 2.6620736Losses:  2.8307900428771973 0.9676960706710815
CurrentTrain: epoch  1, batch     2 | loss: 3.7984862Losses:  2.367457866668701 1.0003833770751953
CurrentTrain: epoch  1, batch     3 | loss: 3.3678412Losses:  3.262735366821289 0.9164658784866333
CurrentTrain: epoch  1, batch     4 | loss: 4.1792011Losses:  2.490128517150879 0.8652698993682861
CurrentTrain: epoch  1, batch     5 | loss: 3.3553984Losses:  3.1596930027008057 0.9749451875686646
CurrentTrain: epoch  1, batch     6 | loss: 4.1346383Losses:  2.1102983951568604 0.8040963411331177
CurrentTrain: epoch  1, batch     7 | loss: 2.9143949Losses:  1.6251529455184937 0.8765361309051514
CurrentTrain: epoch  2, batch     0 | loss: 2.5016890Losses:  2.90252685546875 1.0832488536834717
CurrentTrain: epoch  2, batch     1 | loss: 3.9857757Losses:  1.960706114768982 0.9410232305526733
CurrentTrain: epoch  2, batch     2 | loss: 2.9017293Losses:  2.520995616912842 0.9938851594924927
CurrentTrain: epoch  2, batch     3 | loss: 3.5148807Losses:  2.3210134506225586 0.9518369436264038
CurrentTrain: epoch  2, batch     4 | loss: 3.2728505Losses:  2.8397278785705566 0.9403313398361206
CurrentTrain: epoch  2, batch     5 | loss: 3.7800593Losses:  1.4980742931365967 0.7459460496902466
CurrentTrain: epoch  2, batch     6 | loss: 2.2440205Losses:  2.2589423656463623 0.6744918823242188
CurrentTrain: epoch  2, batch     7 | loss: 2.9334342Losses:  1.96193528175354 0.9812909960746765
CurrentTrain: epoch  3, batch     0 | loss: 2.9432263Losses:  2.0321543216705322 1.0066713094711304
CurrentTrain: epoch  3, batch     1 | loss: 3.0388255Losses:  1.7494657039642334 0.8129784464836121
CurrentTrain: epoch  3, batch     2 | loss: 2.5624442Losses:  2.1431572437286377 0.8706222176551819
CurrentTrain: epoch  3, batch     3 | loss: 3.0137794Losses:  2.04651141166687 0.8211439847946167
CurrentTrain: epoch  3, batch     4 | loss: 2.8676553Losses:  2.126675844192505 0.9552650451660156
CurrentTrain: epoch  3, batch     5 | loss: 3.0819409Losses:  1.8042799234390259 0.9459378123283386
CurrentTrain: epoch  3, batch     6 | loss: 2.7502177Losses:  2.643383502960205 0.4359714686870575
CurrentTrain: epoch  3, batch     7 | loss: 3.0793550Losses:  1.7663241624832153 0.7794738411903381
CurrentTrain: epoch  4, batch     0 | loss: 2.5457981Losses:  1.8536152839660645 0.9110711216926575
CurrentTrain: epoch  4, batch     1 | loss: 2.7646863Losses:  2.030163526535034 0.8409724235534668
CurrentTrain: epoch  4, batch     2 | loss: 2.8711360Losses:  1.830495834350586 0.6417514681816101
CurrentTrain: epoch  4, batch     3 | loss: 2.4722474Losses:  1.4681851863861084 0.7533016204833984
CurrentTrain: epoch  4, batch     4 | loss: 2.2214868Losses:  1.9833192825317383 0.8083143830299377
CurrentTrain: epoch  4, batch     5 | loss: 2.7916336Losses:  1.9700859785079956 0.9011514782905579
CurrentTrain: epoch  4, batch     6 | loss: 2.8712375Losses:  2.1140449047088623 0.5382091999053955
CurrentTrain: epoch  4, batch     7 | loss: 2.6522541Losses:  1.970591425895691 0.8834048509597778
CurrentTrain: epoch  5, batch     0 | loss: 2.8539963Losses:  1.6758394241333008 1.0002597570419312
CurrentTrain: epoch  5, batch     1 | loss: 2.6760993Losses:  1.389082670211792 0.6171342134475708
CurrentTrain: epoch  5, batch     2 | loss: 2.0062170Losses:  1.8247230052947998 0.8555586934089661
CurrentTrain: epoch  5, batch     3 | loss: 2.6802816Losses:  1.9712226390838623 0.9967374205589294
CurrentTrain: epoch  5, batch     4 | loss: 2.9679601Losses:  1.917595386505127 0.6746289730072021
CurrentTrain: epoch  5, batch     5 | loss: 2.5922244Losses:  1.2110344171524048 0.7712758779525757
CurrentTrain: epoch  5, batch     6 | loss: 1.9823103Losses:  1.5572494268417358 0.4845620393753052
CurrentTrain: epoch  5, batch     7 | loss: 2.0418115Losses:  1.5802308320999146 0.9265908002853394
CurrentTrain: epoch  6, batch     0 | loss: 2.5068216Losses:  1.2288942337036133 0.6610954403877258
CurrentTrain: epoch  6, batch     1 | loss: 1.8899896Losses:  2.0332694053649902 0.7996711730957031
CurrentTrain: epoch  6, batch     2 | loss: 2.8329406Losses:  1.8243260383605957 0.8618777990341187
CurrentTrain: epoch  6, batch     3 | loss: 2.6862040Losses:  1.4908756017684937 0.9001447558403015
CurrentTrain: epoch  6, batch     4 | loss: 2.3910203Losses:  1.8695534467697144 0.7176022529602051
CurrentTrain: epoch  6, batch     5 | loss: 2.5871558Losses:  1.3476481437683105 0.7124783992767334
CurrentTrain: epoch  6, batch     6 | loss: 2.0601265Losses:  1.279376745223999 0.3605779707431793
CurrentTrain: epoch  6, batch     7 | loss: 1.6399547Losses:  1.4607172012329102 0.8617869019508362
CurrentTrain: epoch  7, batch     0 | loss: 2.3225040Losses:  1.6424261331558228 0.7130347490310669
CurrentTrain: epoch  7, batch     1 | loss: 2.3554609Losses:  1.3035173416137695 0.611544132232666
CurrentTrain: epoch  7, batch     2 | loss: 1.9150615Losses:  1.4824258089065552 0.8223954439163208
CurrentTrain: epoch  7, batch     3 | loss: 2.3048213Losses:  1.7523406744003296 0.5788794755935669
CurrentTrain: epoch  7, batch     4 | loss: 2.3312201Losses:  1.4683468341827393 0.7355754375457764
CurrentTrain: epoch  7, batch     5 | loss: 2.2039223Losses:  1.6938444375991821 0.8358393907546997
CurrentTrain: epoch  7, batch     6 | loss: 2.5296838Losses:  1.3238000869750977 0.4190491735935211
CurrentTrain: epoch  7, batch     7 | loss: 1.7428492Losses:  1.6858768463134766 0.7522052526473999
CurrentTrain: epoch  8, batch     0 | loss: 2.4380822Losses:  1.1416558027267456 0.672245979309082
CurrentTrain: epoch  8, batch     1 | loss: 1.8139018Losses:  1.3171123266220093 0.631999135017395
CurrentTrain: epoch  8, batch     2 | loss: 1.9491115Losses:  1.5119268894195557 0.7066545486450195
CurrentTrain: epoch  8, batch     3 | loss: 2.2185814Losses:  2.1111884117126465 0.681725263595581
CurrentTrain: epoch  8, batch     4 | loss: 2.7929137Losses:  1.1043606996536255 0.7243111729621887
CurrentTrain: epoch  8, batch     5 | loss: 1.8286719Losses:  1.3552194833755493 0.6714198589324951
CurrentTrain: epoch  8, batch     6 | loss: 2.0266395Losses:  1.2227061986923218 0.5050957798957825
CurrentTrain: epoch  8, batch     7 | loss: 1.7278020Losses:  1.6088892221450806 0.7437666654586792
CurrentTrain: epoch  9, batch     0 | loss: 2.3526559Losses:  1.0623605251312256 0.6404194831848145
CurrentTrain: epoch  9, batch     1 | loss: 1.7027800Losses:  1.3754644393920898 0.8903977274894714
CurrentTrain: epoch  9, batch     2 | loss: 2.2658622Losses:  1.3326067924499512 0.6043903231620789
CurrentTrain: epoch  9, batch     3 | loss: 1.9369972Losses:  0.9995650053024292 0.5707077383995056
CurrentTrain: epoch  9, batch     4 | loss: 1.5702727Losses:  0.9578970670700073 0.6158459186553955
CurrentTrain: epoch  9, batch     5 | loss: 1.5737430Losses:  2.179774284362793 0.6498017311096191
CurrentTrain: epoch  9, batch     6 | loss: 2.8295760Losses:  1.892616868019104 0.40410315990448
CurrentTrain: epoch  9, batch     7 | loss: 2.2967200
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 40.62%   [EVAL] batch:    2 | acc: 31.25%,  total acc: 37.50%   [EVAL] batch:    3 | acc: 37.50%,  total acc: 37.50%   [EVAL] batch:    4 | acc: 31.25%,  total acc: 36.25%   [EVAL] batch:    5 | acc: 37.50%,  total acc: 36.46%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 41.96%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 49.22%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 54.86%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 59.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 63.07%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 66.15%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 66.83%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 64.29%   [EVAL] batch:   14 | acc: 50.00%,  total acc: 63.33%   [EVAL] batch:   15 | acc: 37.50%,  total acc: 61.72%   [EVAL] batch:   16 | acc: 56.25%,  total acc: 61.40%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 61.81%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 61.51%   [EVAL] batch:   19 | acc: 100.00%,  total acc: 63.44%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 65.18%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 66.48%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 67.93%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 69.27%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 70.25%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 71.15%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 71.76%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 72.54%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 73.28%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 73.75%   [EVAL] batch:   30 | acc: 93.75%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 75.95%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 76.47%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 76.96%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 77.43%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 77.87%   [EVAL] batch:   37 | acc: 75.00%,  total acc: 77.80%   [EVAL] batch:   38 | acc: 56.25%,  total acc: 77.24%   [EVAL] batch:   39 | acc: 87.50%,  total acc: 77.50%   [EVAL] batch:   40 | acc: 68.75%,  total acc: 77.29%   [EVAL] batch:   41 | acc: 75.00%,  total acc: 77.23%   [EVAL] batch:   42 | acc: 43.75%,  total acc: 76.45%   [EVAL] batch:   43 | acc: 75.00%,  total acc: 76.42%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 76.94%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 77.31%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 77.79%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 78.26%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 78.70%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 79.00%   [EVAL] batch:   50 | acc: 93.75%,  total acc: 79.29%   [EVAL] batch:   51 | acc: 62.50%,  total acc: 78.97%   [EVAL] batch:   52 | acc: 68.75%,  total acc: 78.77%   [EVAL] batch:   53 | acc: 87.50%,  total acc: 78.94%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 78.98%   [EVAL] batch:   55 | acc: 50.00%,  total acc: 78.46%   [EVAL] batch:   56 | acc: 43.75%,  total acc: 77.85%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 77.80%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 77.54%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 77.50%   [EVAL] batch:   60 | acc: 81.25%,  total acc: 77.56%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 77.72%   [EVAL] batch:   62 | acc: 31.25%,  total acc: 76.98%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 92.19%   [EVAL] batch:    4 | acc: 81.25%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 88.54%   [EVAL] batch:    6 | acc: 43.75%,  total acc: 82.14%   [EVAL] batch:    7 | acc: 50.00%,  total acc: 78.12%   [EVAL] batch:    8 | acc: 25.00%,  total acc: 72.22%   [EVAL] batch:    9 | acc: 37.50%,  total acc: 68.75%   [EVAL] batch:   10 | acc: 25.00%,  total acc: 64.77%   [EVAL] batch:   11 | acc: 31.25%,  total acc: 61.98%   [EVAL] batch:   12 | acc: 68.75%,  total acc: 62.50%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 64.73%   [EVAL] batch:   14 | acc: 93.75%,  total acc: 66.67%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 68.75%   [EVAL] batch:   16 | acc: 93.75%,  total acc: 70.22%   [EVAL] batch:   17 | acc: 93.75%,  total acc: 71.53%   [EVAL] batch:   18 | acc: 100.00%,  total acc: 73.03%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 73.12%   [EVAL] batch:   20 | acc: 81.25%,  total acc: 73.51%   [EVAL] batch:   21 | acc: 62.50%,  total acc: 73.01%   [EVAL] batch:   22 | acc: 50.00%,  total acc: 72.01%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 72.40%   [EVAL] batch:   24 | acc: 56.25%,  total acc: 71.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 72.84%   [EVAL] batch:   26 | acc: 100.00%,  total acc: 73.84%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 74.78%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 75.43%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 76.25%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 77.02%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 77.73%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 78.41%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 78.68%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 78.75%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 79.17%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 79.73%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 80.26%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 80.77%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 81.71%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 81.85%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 82.12%   [EVAL] batch:   43 | acc: 81.25%,  total acc: 82.10%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 82.36%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 82.34%   [EVAL] batch:   46 | acc: 75.00%,  total acc: 82.18%   [EVAL] batch:   47 | acc: 68.75%,  total acc: 81.90%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 82.02%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 82.12%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 82.23%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 82.33%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 82.55%   [EVAL] batch:   53 | acc: 62.50%,  total acc: 82.18%   [EVAL] batch:   54 | acc: 62.50%,  total acc: 81.82%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 81.92%   [EVAL] batch:   56 | acc: 43.75%,  total acc: 81.25%   [EVAL] batch:   57 | acc: 25.00%,  total acc: 80.28%   [EVAL] batch:   58 | acc: 31.25%,  total acc: 79.45%   [EVAL] batch:   59 | acc: 37.50%,  total acc: 78.75%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 78.18%   [EVAL] batch:   61 | acc: 62.50%,  total acc: 77.92%   [EVAL] batch:   62 | acc: 18.75%,  total acc: 76.98%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 75.78%   [EVAL] batch:   64 | acc: 0.00%,  total acc: 74.62%   [EVAL] batch:   65 | acc: 0.00%,  total acc: 73.48%   [EVAL] batch:   66 | acc: 0.00%,  total acc: 72.39%   [EVAL] batch:   67 | acc: 0.00%,  total acc: 71.32%   [EVAL] batch:   68 | acc: 25.00%,  total acc: 70.65%   [EVAL] batch:   69 | acc: 68.75%,  total acc: 70.62%   [EVAL] batch:   70 | acc: 93.75%,  total acc: 70.95%   [EVAL] batch:   71 | acc: 87.50%,  total acc: 71.18%   [EVAL] batch:   72 | acc: 93.75%,  total acc: 71.49%   [EVAL] batch:   73 | acc: 68.75%,  total acc: 71.45%   [EVAL] batch:   74 | acc: 75.00%,  total acc: 71.50%   [EVAL] batch:   75 | acc: 75.00%,  total acc: 71.55%   [EVAL] batch:   76 | acc: 56.25%,  total acc: 71.35%   [EVAL] batch:   77 | acc: 81.25%,  total acc: 71.47%   [EVAL] batch:   78 | acc: 81.25%,  total acc: 71.60%   [EVAL] batch:   79 | acc: 68.75%,  total acc: 71.56%   [EVAL] batch:   80 | acc: 62.50%,  total acc: 71.45%   [EVAL] batch:   81 | acc: 12.50%,  total acc: 70.73%   [EVAL] batch:   82 | acc: 6.25%,  total acc: 69.95%   [EVAL] batch:   83 | acc: 0.00%,  total acc: 69.12%   [EVAL] batch:   84 | acc: 12.50%,  total acc: 68.46%   [EVAL] batch:   85 | acc: 12.50%,  total acc: 67.81%   [EVAL] batch:   86 | acc: 0.00%,  total acc: 67.03%   [EVAL] batch:   87 | acc: 12.50%,  total acc: 66.41%   [EVAL] batch:   88 | acc: 0.00%,  total acc: 65.66%   [EVAL] batch:   89 | acc: 0.00%,  total acc: 64.93%   [EVAL] batch:   90 | acc: 0.00%,  total acc: 64.22%   [EVAL] batch:   91 | acc: 0.00%,  total acc: 63.52%   [EVAL] batch:   92 | acc: 0.00%,  total acc: 62.84%   [EVAL] batch:   93 | acc: 18.75%,  total acc: 62.37%   [EVAL] batch:   94 | acc: 87.50%,  total acc: 62.63%   [EVAL] batch:   95 | acc: 81.25%,  total acc: 62.83%   [EVAL] batch:   96 | acc: 75.00%,  total acc: 62.95%   [EVAL] batch:   97 | acc: 93.75%,  total acc: 63.27%   [EVAL] batch:   98 | acc: 68.75%,  total acc: 63.32%   [EVAL] batch:   99 | acc: 68.75%,  total acc: 63.38%   [EVAL] batch:  100 | acc: 100.00%,  total acc: 63.74%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 64.03%   [EVAL] batch:  102 | acc: 87.50%,  total acc: 64.26%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 64.60%   [EVAL] batch:  104 | acc: 100.00%,  total acc: 64.94%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 65.27%   [EVAL] batch:  106 | acc: 68.75%,  total acc: 65.30%   [EVAL] batch:  107 | acc: 25.00%,  total acc: 64.93%   [EVAL] batch:  108 | acc: 31.25%,  total acc: 64.62%   [EVAL] batch:  109 | acc: 25.00%,  total acc: 64.26%   [EVAL] batch:  110 | acc: 31.25%,  total acc: 63.96%   [EVAL] batch:  111 | acc: 37.50%,  total acc: 63.73%   [EVAL] batch:  112 | acc: 18.75%,  total acc: 63.33%   [EVAL] batch:  113 | acc: 37.50%,  total acc: 63.10%   [EVAL] batch:  114 | acc: 56.25%,  total acc: 63.04%   [EVAL] batch:  115 | acc: 81.25%,  total acc: 63.20%   [EVAL] batch:  116 | acc: 62.50%,  total acc: 63.19%   [EVAL] batch:  117 | acc: 62.50%,  total acc: 63.19%   [EVAL] batch:  118 | acc: 50.00%,  total acc: 63.08%   [EVAL] batch:  119 | acc: 31.25%,  total acc: 62.81%   [EVAL] batch:  120 | acc: 31.25%,  total acc: 62.55%   [EVAL] batch:  121 | acc: 31.25%,  total acc: 62.30%   [EVAL] batch:  122 | acc: 25.00%,  total acc: 61.99%   [EVAL] batch:  123 | acc: 43.75%,  total acc: 61.84%   [EVAL] batch:  124 | acc: 43.75%,  total acc: 61.70%   [EVAL] batch:  125 | acc: 6.25%,  total acc: 61.26%   [EVAL] batch:  126 | acc: 18.75%,  total acc: 60.93%   [EVAL] batch:  127 | acc: 25.00%,  total acc: 60.64%   [EVAL] batch:  128 | acc: 0.00%,  total acc: 60.17%   [EVAL] batch:  129 | acc: 37.50%,  total acc: 60.00%   [EVAL] batch:  130 | acc: 6.25%,  total acc: 59.59%   [EVAL] batch:  131 | acc: 81.25%,  total acc: 59.75%   [EVAL] batch:  132 | acc: 100.00%,  total acc: 60.06%   [EVAL] batch:  133 | acc: 93.75%,  total acc: 60.31%   [EVAL] batch:  134 | acc: 87.50%,  total acc: 60.51%   [EVAL] batch:  135 | acc: 100.00%,  total acc: 60.80%   [EVAL] batch:  136 | acc: 93.75%,  total acc: 61.04%   [EVAL] batch:  137 | acc: 93.75%,  total acc: 61.28%   [EVAL] batch:  138 | acc: 50.00%,  total acc: 61.20%   [EVAL] batch:  139 | acc: 50.00%,  total acc: 61.12%   [EVAL] batch:  140 | acc: 81.25%,  total acc: 61.26%   [EVAL] batch:  141 | acc: 81.25%,  total acc: 61.40%   [EVAL] batch:  142 | acc: 81.25%,  total acc: 61.54%   [EVAL] batch:  143 | acc: 62.50%,  total acc: 61.55%   [EVAL] batch:  144 | acc: 43.75%,  total acc: 61.42%   [EVAL] batch:  145 | acc: 37.50%,  total acc: 61.26%   [EVAL] batch:  146 | acc: 6.25%,  total acc: 60.88%   [EVAL] batch:  147 | acc: 25.00%,  total acc: 60.64%   [EVAL] batch:  148 | acc: 37.50%,  total acc: 60.49%   [EVAL] batch:  149 | acc: 12.50%,  total acc: 60.17%   [EVAL] batch:  150 | acc: 75.00%,  total acc: 60.26%   [EVAL] batch:  151 | acc: 75.00%,  total acc: 60.36%   [EVAL] batch:  152 | acc: 81.25%,  total acc: 60.50%   [EVAL] batch:  153 | acc: 81.25%,  total acc: 60.63%   [EVAL] batch:  154 | acc: 56.25%,  total acc: 60.60%   [EVAL] batch:  155 | acc: 68.75%,  total acc: 60.66%   [EVAL] batch:  156 | acc: 31.25%,  total acc: 60.47%   [EVAL] batch:  157 | acc: 25.00%,  total acc: 60.25%   [EVAL] batch:  158 | acc: 18.75%,  total acc: 59.98%   [EVAL] batch:  159 | acc: 31.25%,  total acc: 59.80%   [EVAL] batch:  160 | acc: 18.75%,  total acc: 59.55%   [EVAL] batch:  161 | acc: 18.75%,  total acc: 59.30%   [EVAL] batch:  162 | acc: 37.50%,  total acc: 59.16%   [EVAL] batch:  163 | acc: 68.75%,  total acc: 59.22%   [EVAL] batch:  164 | acc: 62.50%,  total acc: 59.24%   [EVAL] batch:  165 | acc: 62.50%,  total acc: 59.26%   [EVAL] batch:  166 | acc: 62.50%,  total acc: 59.28%   [EVAL] batch:  167 | acc: 75.00%,  total acc: 59.38%   [EVAL] batch:  168 | acc: 62.50%,  total acc: 59.39%   [EVAL] batch:  169 | acc: 37.50%,  total acc: 59.26%   [EVAL] batch:  170 | acc: 31.25%,  total acc: 59.10%   [EVAL] batch:  171 | acc: 18.75%,  total acc: 58.87%   [EVAL] batch:  172 | acc: 37.50%,  total acc: 58.74%   [EVAL] batch:  173 | acc: 25.00%,  total acc: 58.55%   [EVAL] batch:  174 | acc: 37.50%,  total acc: 58.43%   [EVAL] batch:  175 | acc: 100.00%,  total acc: 58.66%   [EVAL] batch:  176 | acc: 100.00%,  total acc: 58.90%   [EVAL] batch:  177 | acc: 100.00%,  total acc: 59.13%   [EVAL] batch:  178 | acc: 100.00%,  total acc: 59.36%   [EVAL] batch:  179 | acc: 100.00%,  total acc: 59.58%   [EVAL] batch:  180 | acc: 100.00%,  total acc: 59.81%   [EVAL] batch:  181 | acc: 68.75%,  total acc: 59.86%   [EVAL] batch:  182 | acc: 43.75%,  total acc: 59.77%   [EVAL] batch:  183 | acc: 43.75%,  total acc: 59.68%   [EVAL] batch:  184 | acc: 68.75%,  total acc: 59.73%   [EVAL] batch:  185 | acc: 43.75%,  total acc: 59.64%   [EVAL] batch:  186 | acc: 56.25%,  total acc: 59.63%   [EVAL] batch:  187 | acc: 56.25%,  total acc: 59.61%   [EVAL] batch:  188 | acc: 50.00%,  total acc: 59.56%   [EVAL] batch:  189 | acc: 56.25%,  total acc: 59.54%   [EVAL] batch:  190 | acc: 43.75%,  total acc: 59.46%   [EVAL] batch:  191 | acc: 43.75%,  total acc: 59.38%   [EVAL] batch:  192 | acc: 18.75%,  total acc: 59.16%   [EVAL] batch:  193 | acc: 56.25%,  total acc: 59.15%   [EVAL] batch:  194 | acc: 56.25%,  total acc: 59.13%   [EVAL] batch:  195 | acc: 56.25%,  total acc: 59.12%   [EVAL] batch:  196 | acc: 43.75%,  total acc: 59.04%   [EVAL] batch:  197 | acc: 81.25%,  total acc: 59.15%   [EVAL] batch:  198 | acc: 62.50%,  total acc: 59.17%   [EVAL] batch:  199 | acc: 62.50%,  total acc: 59.19%   [EVAL] batch:  200 | acc: 81.25%,  total acc: 59.30%   [EVAL] batch:  201 | acc: 75.00%,  total acc: 59.38%   [EVAL] batch:  202 | acc: 75.00%,  total acc: 59.45%   [EVAL] batch:  203 | acc: 87.50%,  total acc: 59.59%   [EVAL] batch:  204 | acc: 62.50%,  total acc: 59.60%   [EVAL] batch:  205 | acc: 87.50%,  total acc: 59.74%   [EVAL] batch:  206 | acc: 37.50%,  total acc: 59.63%   [EVAL] batch:  207 | acc: 37.50%,  total acc: 59.53%   [EVAL] batch:  208 | acc: 50.00%,  total acc: 59.48%   [EVAL] batch:  209 | acc: 18.75%,  total acc: 59.29%   [EVAL] batch:  210 | acc: 25.00%,  total acc: 59.12%   [EVAL] batch:  211 | acc: 37.50%,  total acc: 59.02%   [EVAL] batch:  212 | acc: 37.50%,  total acc: 58.92%   [EVAL] batch:  213 | acc: 81.25%,  total acc: 59.02%   [EVAL] batch:  214 | acc: 75.00%,  total acc: 59.10%   [EVAL] batch:  215 | acc: 43.75%,  total acc: 59.03%   [EVAL] batch:  216 | acc: 87.50%,  total acc: 59.16%   [EVAL] batch:  217 | acc: 68.75%,  total acc: 59.20%   [EVAL] batch:  218 | acc: 68.75%,  total acc: 59.25%   [EVAL] batch:  219 | acc: 100.00%,  total acc: 59.43%   [EVAL] batch:  220 | acc: 93.75%,  total acc: 59.59%   [EVAL] batch:  221 | acc: 100.00%,  total acc: 59.77%   [EVAL] batch:  222 | acc: 100.00%,  total acc: 59.95%   [EVAL] batch:  223 | acc: 100.00%,  total acc: 60.13%   [EVAL] batch:  224 | acc: 100.00%,  total acc: 60.31%   [EVAL] batch:  225 | acc: 87.50%,  total acc: 60.43%   [EVAL] batch:  226 | acc: 81.25%,  total acc: 60.52%   [EVAL] batch:  227 | acc: 75.00%,  total acc: 60.58%   [EVAL] batch:  228 | acc: 81.25%,  total acc: 60.67%   [EVAL] batch:  229 | acc: 93.75%,  total acc: 60.82%   [EVAL] batch:  230 | acc: 81.25%,  total acc: 60.90%   [EVAL] batch:  231 | acc: 37.50%,  total acc: 60.80%   [EVAL] batch:  232 | acc: 12.50%,  total acc: 60.60%   [EVAL] batch:  233 | acc: 12.50%,  total acc: 60.39%   [EVAL] batch:  234 | acc: 6.25%,  total acc: 60.16%   [EVAL] batch:  235 | acc: 43.75%,  total acc: 60.09%   [EVAL] batch:  236 | acc: 12.50%,  total acc: 59.89%   [EVAL] batch:  237 | acc: 62.50%,  total acc: 59.90%   [EVAL] batch:  238 | acc: 87.50%,  total acc: 60.02%   [EVAL] batch:  239 | acc: 93.75%,  total acc: 60.16%   [EVAL] batch:  240 | acc: 81.25%,  total acc: 60.24%   [EVAL] batch:  241 | acc: 87.50%,  total acc: 60.36%   [EVAL] batch:  242 | acc: 87.50%,  total acc: 60.47%   [EVAL] batch:  243 | acc: 62.50%,  total acc: 60.48%   [EVAL] batch:  244 | acc: 12.50%,  total acc: 60.28%   [EVAL] batch:  245 | acc: 6.25%,  total acc: 60.06%   [EVAL] batch:  246 | acc: 18.75%,  total acc: 59.89%   [EVAL] batch:  247 | acc: 6.25%,  total acc: 59.68%   [EVAL] batch:  248 | acc: 12.50%,  total acc: 59.49%   [EVAL] batch:  249 | acc: 12.50%,  total acc: 59.30%   [EVAL] batch:  250 | acc: 81.25%,  total acc: 59.39%   [EVAL] batch:  251 | acc: 81.25%,  total acc: 59.47%   [EVAL] batch:  252 | acc: 93.75%,  total acc: 59.61%   [EVAL] batch:  253 | acc: 81.25%,  total acc: 59.69%   [EVAL] batch:  254 | acc: 81.25%,  total acc: 59.78%   [EVAL] batch:  255 | acc: 87.50%,  total acc: 59.89%   [EVAL] batch:  256 | acc: 56.25%,  total acc: 59.87%   [EVAL] batch:  257 | acc: 68.75%,  total acc: 59.91%   [EVAL] batch:  258 | acc: 62.50%,  total acc: 59.92%   [EVAL] batch:  259 | acc: 56.25%,  total acc: 59.90%   [EVAL] batch:  260 | acc: 43.75%,  total acc: 59.84%   [EVAL] batch:  261 | acc: 62.50%,  total acc: 59.85%   [EVAL] batch:  262 | acc: 62.50%,  total acc: 59.86%   [EVAL] batch:  263 | acc: 50.00%,  total acc: 59.82%   [EVAL] batch:  264 | acc: 37.50%,  total acc: 59.74%   [EVAL] batch:  265 | acc: 25.00%,  total acc: 59.61%   [EVAL] batch:  266 | acc: 43.75%,  total acc: 59.55%   [EVAL] batch:  267 | acc: 31.25%,  total acc: 59.44%   [EVAL] batch:  268 | acc: 75.00%,  total acc: 59.50%   [EVAL] batch:  269 | acc: 93.75%,  total acc: 59.63%   [EVAL] batch:  270 | acc: 100.00%,  total acc: 59.78%   [EVAL] batch:  271 | acc: 100.00%,  total acc: 59.93%   [EVAL] batch:  272 | acc: 100.00%,  total acc: 60.07%   [EVAL] batch:  273 | acc: 93.75%,  total acc: 60.20%   [EVAL] batch:  274 | acc: 100.00%,  total acc: 60.34%   [EVAL] batch:  275 | acc: 62.50%,  total acc: 60.35%   [EVAL] batch:  276 | acc: 31.25%,  total acc: 60.24%   [EVAL] batch:  277 | acc: 62.50%,  total acc: 60.25%   [EVAL] batch:  278 | acc: 75.00%,  total acc: 60.30%   [EVAL] batch:  279 | acc: 43.75%,  total acc: 60.25%   [EVAL] batch:  280 | acc: 50.00%,  total acc: 60.21%   [EVAL] batch:  281 | acc: 43.75%,  total acc: 60.15%   [EVAL] batch:  282 | acc: 31.25%,  total acc: 60.05%   [EVAL] batch:  283 | acc: 6.25%,  total acc: 59.86%   [EVAL] batch:  284 | acc: 18.75%,  total acc: 59.71%   [EVAL] batch:  285 | acc: 6.25%,  total acc: 59.53%   [EVAL] batch:  286 | acc: 0.00%,  total acc: 59.32%   [EVAL] batch:  287 | acc: 31.25%,  total acc: 59.22%   [EVAL] batch:  288 | acc: 37.50%,  total acc: 59.15%   [EVAL] batch:  289 | acc: 50.00%,  total acc: 59.12%   [EVAL] batch:  290 | acc: 31.25%,  total acc: 59.02%   [EVAL] batch:  291 | acc: 62.50%,  total acc: 59.03%   [EVAL] batch:  292 | acc: 56.25%,  total acc: 59.02%   [EVAL] batch:  293 | acc: 43.75%,  total acc: 58.97%   [EVAL] batch:  294 | acc: 56.25%,  total acc: 58.96%   [EVAL] batch:  295 | acc: 50.00%,  total acc: 58.93%   [EVAL] batch:  296 | acc: 25.00%,  total acc: 58.82%   [EVAL] batch:  297 | acc: 50.00%,  total acc: 58.79%   [EVAL] batch:  298 | acc: 43.75%,  total acc: 58.74%   [EVAL] batch:  299 | acc: 50.00%,  total acc: 58.71%   [EVAL] batch:  300 | acc: 100.00%,  total acc: 58.85%   [EVAL] batch:  301 | acc: 100.00%,  total acc: 58.98%   [EVAL] batch:  302 | acc: 100.00%,  total acc: 59.12%   [EVAL] batch:  303 | acc: 100.00%,  total acc: 59.25%   [EVAL] batch:  304 | acc: 100.00%,  total acc: 59.39%   [EVAL] batch:  305 | acc: 100.00%,  total acc: 59.52%   [EVAL] batch:  306 | acc: 93.75%,  total acc: 59.63%   [EVAL] batch:  307 | acc: 87.50%,  total acc: 59.72%   [EVAL] batch:  308 | acc: 75.00%,  total acc: 59.77%   [EVAL] batch:  309 | acc: 100.00%,  total acc: 59.90%   [EVAL] batch:  310 | acc: 87.50%,  total acc: 59.99%   [EVAL] batch:  311 | acc: 100.00%,  total acc: 60.12%   [EVAL] batch:  312 | acc: 87.50%,  total acc: 60.20%   [EVAL] batch:  313 | acc: 62.50%,  total acc: 60.21%   [EVAL] batch:  314 | acc: 37.50%,  total acc: 60.14%   [EVAL] batch:  315 | acc: 81.25%,  total acc: 60.21%   [EVAL] batch:  316 | acc: 50.00%,  total acc: 60.17%   [EVAL] batch:  317 | acc: 68.75%,  total acc: 60.20%   [EVAL] batch:  318 | acc: 62.50%,  total acc: 60.21%   [EVAL] batch:  319 | acc: 100.00%,  total acc: 60.33%   [EVAL] batch:  320 | acc: 100.00%,  total acc: 60.46%   [EVAL] batch:  321 | acc: 87.50%,  total acc: 60.54%   [EVAL] batch:  322 | acc: 93.75%,  total acc: 60.64%   [EVAL] batch:  323 | acc: 93.75%,  total acc: 60.74%   [EVAL] batch:  324 | acc: 81.25%,  total acc: 60.81%   [EVAL] batch:  325 | acc: 37.50%,  total acc: 60.74%   [EVAL] batch:  326 | acc: 25.00%,  total acc: 60.63%   [EVAL] batch:  327 | acc: 25.00%,  total acc: 60.52%   [EVAL] batch:  328 | acc: 31.25%,  total acc: 60.43%   [EVAL] batch:  329 | acc: 37.50%,  total acc: 60.36%   [EVAL] batch:  330 | acc: 12.50%,  total acc: 60.22%   [EVAL] batch:  331 | acc: 75.00%,  total acc: 60.26%   [EVAL] batch:  332 | acc: 100.00%,  total acc: 60.38%   [EVAL] batch:  333 | acc: 100.00%,  total acc: 60.50%   [EVAL] batch:  334 | acc: 100.00%,  total acc: 60.62%   [EVAL] batch:  335 | acc: 100.00%,  total acc: 60.73%   [EVAL] batch:  336 | acc: 93.75%,  total acc: 60.83%   [EVAL] batch:  337 | acc: 56.25%,  total acc: 60.82%   [EVAL] batch:  338 | acc: 0.00%,  total acc: 60.64%   [EVAL] batch:  339 | acc: 6.25%,  total acc: 60.48%   [EVAL] batch:  340 | acc: 12.50%,  total acc: 60.34%   [EVAL] batch:  341 | acc: 12.50%,  total acc: 60.20%   [EVAL] batch:  342 | acc: 0.00%,  total acc: 60.02%   [EVAL] batch:  343 | acc: 25.00%,  total acc: 59.92%   [EVAL] batch:  344 | acc: 100.00%,  total acc: 60.04%   [EVAL] batch:  345 | acc: 93.75%,  total acc: 60.13%   [EVAL] batch:  346 | acc: 87.50%,  total acc: 60.21%   [EVAL] batch:  347 | acc: 93.75%,  total acc: 60.31%   [EVAL] batch:  348 | acc: 100.00%,  total acc: 60.42%   [EVAL] batch:  349 | acc: 100.00%,  total acc: 60.54%   [EVAL] batch:  350 | acc: 6.25%,  total acc: 60.38%   [EVAL] batch:  351 | acc: 25.00%,  total acc: 60.28%   [EVAL] batch:  352 | acc: 6.25%,  total acc: 60.13%   [EVAL] batch:  353 | acc: 0.00%,  total acc: 59.96%   [EVAL] batch:  354 | acc: 18.75%,  total acc: 59.84%   [EVAL] batch:  355 | acc: 18.75%,  total acc: 59.73%   [EVAL] batch:  356 | acc: 31.25%,  total acc: 59.65%   [EVAL] batch:  357 | acc: 37.50%,  total acc: 59.58%   [EVAL] batch:  358 | acc: 50.00%,  total acc: 59.56%   [EVAL] batch:  359 | acc: 50.00%,  total acc: 59.53%   [EVAL] batch:  360 | acc: 50.00%,  total acc: 59.50%   [EVAL] batch:  361 | acc: 37.50%,  total acc: 59.44%   [EVAL] batch:  362 | acc: 75.00%,  total acc: 59.49%   [EVAL] batch:  363 | acc: 62.50%,  total acc: 59.50%   [EVAL] batch:  364 | acc: 75.00%,  total acc: 59.54%   [EVAL] batch:  365 | acc: 75.00%,  total acc: 59.58%   [EVAL] batch:  366 | acc: 75.00%,  total acc: 59.62%   [EVAL] batch:  367 | acc: 75.00%,  total acc: 59.66%   [EVAL] batch:  368 | acc: 62.50%,  total acc: 59.67%   [EVAL] batch:  369 | acc: 87.50%,  total acc: 59.75%   [EVAL] batch:  370 | acc: 93.75%,  total acc: 59.84%   [EVAL] batch:  371 | acc: 81.25%,  total acc: 59.90%   [EVAL] batch:  372 | acc: 93.75%,  total acc: 59.99%   [EVAL] batch:  373 | acc: 87.50%,  total acc: 60.06%   [EVAL] batch:  374 | acc: 100.00%,  total acc: 60.17%   [EVAL] batch:  375 | acc: 100.00%,  total acc: 60.27%   [EVAL] batch:  376 | acc: 93.75%,  total acc: 60.36%   [EVAL] batch:  377 | acc: 100.00%,  total acc: 60.47%   [EVAL] batch:  378 | acc: 87.50%,  total acc: 60.54%   [EVAL] batch:  379 | acc: 93.75%,  total acc: 60.62%   [EVAL] batch:  380 | acc: 100.00%,  total acc: 60.73%   [EVAL] batch:  381 | acc: 75.00%,  total acc: 60.77%   [EVAL] batch:  382 | acc: 81.25%,  total acc: 60.82%   [EVAL] batch:  383 | acc: 87.50%,  total acc: 60.89%   [EVAL] batch:  384 | acc: 93.75%,  total acc: 60.97%   [EVAL] batch:  385 | acc: 56.25%,  total acc: 60.96%   [EVAL] batch:  386 | acc: 81.25%,  total acc: 61.01%   [EVAL] batch:  387 | acc: 87.50%,  total acc: 61.08%   [EVAL] batch:  388 | acc: 75.00%,  total acc: 61.12%   [EVAL] batch:  389 | acc: 62.50%,  total acc: 61.12%   [EVAL] batch:  390 | acc: 56.25%,  total acc: 61.11%   [EVAL] batch:  391 | acc: 50.00%,  total acc: 61.08%   [EVAL] batch:  392 | acc: 56.25%,  total acc: 61.07%   [EVAL] batch:  393 | acc: 50.00%,  total acc: 61.04%   [EVAL] batch:  394 | acc: 75.00%,  total acc: 61.08%   [EVAL] batch:  395 | acc: 87.50%,  total acc: 61.14%   [EVAL] batch:  396 | acc: 43.75%,  total acc: 61.10%   [EVAL] batch:  397 | acc: 75.00%,  total acc: 61.13%   [EVAL] batch:  398 | acc: 81.25%,  total acc: 61.18%   [EVAL] batch:  399 | acc: 56.25%,  total acc: 61.17%   [EVAL] batch:  400 | acc: 100.00%,  total acc: 61.27%   [EVAL] batch:  401 | acc: 100.00%,  total acc: 61.37%   [EVAL] batch:  402 | acc: 100.00%,  total acc: 61.46%   [EVAL] batch:  403 | acc: 100.00%,  total acc: 61.56%   [EVAL] batch:  404 | acc: 100.00%,  total acc: 61.65%   [EVAL] batch:  405 | acc: 100.00%,  total acc: 61.75%   [EVAL] batch:  406 | acc: 87.50%,  total acc: 61.81%   [EVAL] batch:  407 | acc: 87.50%,  total acc: 61.87%   [EVAL] batch:  408 | acc: 75.00%,  total acc: 61.90%   [EVAL] batch:  409 | acc: 87.50%,  total acc: 61.97%   [EVAL] batch:  410 | acc: 75.00%,  total acc: 62.00%   [EVAL] batch:  411 | acc: 68.75%,  total acc: 62.01%   [EVAL] batch:  412 | acc: 75.00%,  total acc: 62.05%   [EVAL] batch:  413 | acc: 100.00%,  total acc: 62.14%   [EVAL] batch:  414 | acc: 100.00%,  total acc: 62.23%   [EVAL] batch:  415 | acc: 100.00%,  total acc: 62.32%   [EVAL] batch:  416 | acc: 100.00%,  total acc: 62.41%   [EVAL] batch:  417 | acc: 100.00%,  total acc: 62.50%   [EVAL] batch:  418 | acc: 93.75%,  total acc: 62.57%   [EVAL] batch:  419 | acc: 100.00%,  total acc: 62.66%   [EVAL] batch:  420 | acc: 100.00%,  total acc: 62.75%   [EVAL] batch:  421 | acc: 100.00%,  total acc: 62.84%   [EVAL] batch:  422 | acc: 100.00%,  total acc: 62.93%   [EVAL] batch:  423 | acc: 100.00%,  total acc: 63.02%   [EVAL] batch:  424 | acc: 100.00%,  total acc: 63.10%   [EVAL] batch:  425 | acc: 93.75%,  total acc: 63.17%   [EVAL] batch:  426 | acc: 93.75%,  total acc: 63.25%   [EVAL] batch:  427 | acc: 93.75%,  total acc: 63.32%   [EVAL] batch:  428 | acc: 93.75%,  total acc: 63.39%   [EVAL] batch:  429 | acc: 87.50%,  total acc: 63.44%   [EVAL] batch:  430 | acc: 100.00%,  total acc: 63.53%   [EVAL] batch:  431 | acc: 93.75%,  total acc: 63.60%   [EVAL] batch:  432 | acc: 93.75%,  total acc: 63.67%   [EVAL] batch:  433 | acc: 93.75%,  total acc: 63.74%   [EVAL] batch:  434 | acc: 100.00%,  total acc: 63.82%   [EVAL] batch:  435 | acc: 100.00%,  total acc: 63.90%   [EVAL] batch:  436 | acc: 87.50%,  total acc: 63.96%   [EVAL] batch:  437 | acc: 68.75%,  total acc: 63.97%   [EVAL] batch:  438 | acc: 43.75%,  total acc: 63.92%   [EVAL] batch:  439 | acc: 25.00%,  total acc: 63.84%   [EVAL] batch:  440 | acc: 37.50%,  total acc: 63.78%   [EVAL] batch:  441 | acc: 37.50%,  total acc: 63.72%   [EVAL] batch:  442 | acc: 43.75%,  total acc: 63.67%   [EVAL] batch:  443 | acc: 37.50%,  total acc: 63.61%   [EVAL] batch:  444 | acc: 100.00%,  total acc: 63.69%   [EVAL] batch:  445 | acc: 100.00%,  total acc: 63.78%   [EVAL] batch:  446 | acc: 100.00%,  total acc: 63.86%   [EVAL] batch:  447 | acc: 100.00%,  total acc: 63.94%   [EVAL] batch:  448 | acc: 100.00%,  total acc: 64.02%   [EVAL] batch:  449 | acc: 100.00%,  total acc: 64.10%   [EVAL] batch:  450 | acc: 50.00%,  total acc: 64.07%   [EVAL] batch:  451 | acc: 25.00%,  total acc: 63.98%   [EVAL] batch:  452 | acc: 43.75%,  total acc: 63.93%   [EVAL] batch:  453 | acc: 56.25%,  total acc: 63.92%   [EVAL] batch:  454 | acc: 56.25%,  total acc: 63.90%   [EVAL] batch:  455 | acc: 56.25%,  total acc: 63.88%   [EVAL] batch:  456 | acc: 87.50%,  total acc: 63.94%   [EVAL] batch:  457 | acc: 100.00%,  total acc: 64.01%   [EVAL] batch:  458 | acc: 100.00%,  total acc: 64.09%   [EVAL] batch:  459 | acc: 93.75%,  total acc: 64.16%   [EVAL] batch:  460 | acc: 100.00%,  total acc: 64.24%   [EVAL] batch:  461 | acc: 100.00%,  total acc: 64.31%   [EVAL] batch:  462 | acc: 93.75%,  total acc: 64.38%   [EVAL] batch:  463 | acc: 81.25%,  total acc: 64.41%   [EVAL] batch:  464 | acc: 93.75%,  total acc: 64.48%   [EVAL] batch:  465 | acc: 100.00%,  total acc: 64.55%   [EVAL] batch:  466 | acc: 81.25%,  total acc: 64.59%   [EVAL] batch:  467 | acc: 100.00%,  total acc: 64.66%   [EVAL] batch:  468 | acc: 93.75%,  total acc: 64.73%   [EVAL] batch:  469 | acc: 100.00%,  total acc: 64.80%   [EVAL] batch:  470 | acc: 100.00%,  total acc: 64.88%   [EVAL] batch:  471 | acc: 87.50%,  total acc: 64.92%   [EVAL] batch:  472 | acc: 93.75%,  total acc: 64.98%   [EVAL] batch:  473 | acc: 93.75%,  total acc: 65.04%   [EVAL] batch:  474 | acc: 100.00%,  total acc: 65.12%   [EVAL] batch:  475 | acc: 56.25%,  total acc: 65.10%   [EVAL] batch:  476 | acc: 68.75%,  total acc: 65.11%   [EVAL] batch:  477 | acc: 75.00%,  total acc: 65.13%   [EVAL] batch:  478 | acc: 87.50%,  total acc: 65.17%   [EVAL] batch:  479 | acc: 43.75%,  total acc: 65.13%   [EVAL] batch:  480 | acc: 62.50%,  total acc: 65.12%   [EVAL] batch:  481 | acc: 87.50%,  total acc: 65.17%   [EVAL] batch:  482 | acc: 93.75%,  total acc: 65.23%   [EVAL] batch:  483 | acc: 100.00%,  total acc: 65.30%   [EVAL] batch:  484 | acc: 100.00%,  total acc: 65.37%   [EVAL] batch:  485 | acc: 100.00%,  total acc: 65.44%   [EVAL] batch:  486 | acc: 93.75%,  total acc: 65.50%   [EVAL] batch:  487 | acc: 93.75%,  total acc: 65.56%   [EVAL] batch:  488 | acc: 81.25%,  total acc: 65.59%   [EVAL] batch:  489 | acc: 68.75%,  total acc: 65.60%   [EVAL] batch:  490 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:  491 | acc: 87.50%,  total acc: 65.66%   [EVAL] batch:  492 | acc: 62.50%,  total acc: 65.66%   [EVAL] batch:  493 | acc: 50.00%,  total acc: 65.62%   [EVAL] batch:  494 | acc: 62.50%,  total acc: 65.62%   [EVAL] batch:  495 | acc: 68.75%,  total acc: 65.62%   [EVAL] batch:  496 | acc: 62.50%,  total acc: 65.62%   [EVAL] batch:  497 | acc: 81.25%,  total acc: 65.65%   [EVAL] batch:  498 | acc: 87.50%,  total acc: 65.69%   [EVAL] batch:  499 | acc: 68.75%,  total acc: 65.70%   
cur_acc:  ['0.9454', '0.6677', '0.7510', '0.7976', '0.7956', '0.7401', '0.8750', '0.7698']
his_acc:  ['0.9454', '0.8035', '0.7530', '0.7380', '0.7047', '0.6872', '0.6886', '0.6570']
--------Round  2
seed:  300
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/train.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/valid.pkl
data/CFRLFewRel/CFRLdata_10_100_10_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
Clustering into  2  clusters
Clusters:  [0 1 0 0 0 0 0 0 0 0]
Losses:  11.816307067871094 1.9885611534118652
CurrentTrain: epoch  0, batch     0 | loss: 13.8048687Losses:  13.37979507446289 1.8192028999328613
CurrentTrain: epoch  0, batch     1 | loss: 15.1989975Losses:  13.556406021118164 1.6770509481430054
CurrentTrain: epoch  0, batch     2 | loss: 15.2334566Losses:  14.053993225097656 1.675065040588379
CurrentTrain: epoch  0, batch     3 | loss: 15.7290583Losses:  13.69017505645752 1.570518136024475
CurrentTrain: epoch  0, batch     4 | loss: 15.2606936Losses:  13.470280647277832 1.6664336919784546
CurrentTrain: epoch  0, batch     5 | loss: 15.1367140Losses:  13.63599681854248 1.7421033382415771
CurrentTrain: epoch  0, batch     6 | loss: 15.3781004Losses:  13.431657791137695 1.4058926105499268
CurrentTrain: epoch  0, batch     7 | loss: 14.8375502Losses:  12.953975677490234 1.5465723276138306
CurrentTrain: epoch  0, batch     8 | loss: 14.5005484Losses:  12.753581047058105 1.4742738008499146
CurrentTrain: epoch  0, batch     9 | loss: 14.2278547Losses:  12.349787712097168 1.534398078918457
CurrentTrain: epoch  0, batch    10 | loss: 13.8841858Losses:  12.54121208190918 1.4934691190719604
CurrentTrain: epoch  0, batch    11 | loss: 14.0346813Losses:  12.200992584228516 1.5795093774795532
CurrentTrain: epoch  0, batch    12 | loss: 13.7805023Losses:  12.237810134887695 1.6360070705413818
CurrentTrain: epoch  0, batch    13 | loss: 13.8738174Losses:  12.139458656311035 1.8241360187530518
CurrentTrain: epoch  0, batch    14 | loss: 13.9635944Losses:  12.400581359863281 1.6634010076522827
CurrentTrain: epoch  0, batch    15 | loss: 14.0639820Losses:  11.7001371383667 1.4774589538574219
CurrentTrain: epoch  0, batch    16 | loss: 13.1775961Losses:  12.194486618041992 1.8770546913146973
CurrentTrain: epoch  0, batch    17 | loss: 14.0715408Losses:  12.364028930664062 1.8582355976104736
CurrentTrain: epoch  0, batch    18 | loss: 14.2222643Losses:  12.058727264404297 1.6453006267547607
CurrentTrain: epoch  0, batch    19 | loss: 13.7040281Losses:  12.26515007019043 1.5244194269180298
CurrentTrain: epoch  0, batch    20 | loss: 13.7895699Losses:  11.585142135620117 1.4710885286331177
CurrentTrain: epoch  0, batch    21 | loss: 13.0562305Losses:  10.713935852050781 0.802598237991333
CurrentTrain: epoch  0, batch    22 | loss: 11.5165339Losses:  11.548164367675781 1.530002236366272
