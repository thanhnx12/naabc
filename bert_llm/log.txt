#############params############
cuda
Task=Tacred, 5-shot
Encoding model: bert
pattern=hybridprompt
mem=1, margin=0.3, gen=0, gen_num=2
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hybridprompt_12token/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 19.4081745CurrentTrain: epoch  0, batch     1 | loss: 21.7869492CurrentTrain: epoch  0, batch     2 | loss: 13.9594307CurrentTrain: epoch  0, batch     3 | loss: 13.3448277CurrentTrain: epoch  0, batch     4 | loss: 19.7512093CurrentTrain: epoch  0, batch     5 | loss: 15.3507900CurrentTrain: epoch  0, batch     6 | loss: 11.2298012CurrentTrain: epoch  0, batch     7 | loss: 17.1717510CurrentTrain: epoch  0, batch     8 | loss: 17.7265053CurrentTrain: epoch  0, batch     9 | loss: 12.2518330CurrentTrain: epoch  0, batch    10 | loss: 10.4568100CurrentTrain: epoch  0, batch    11 | loss: 9.8071613CurrentTrain: epoch  0, batch    12 | loss: 12.1600428CurrentTrain: epoch  0, batch    13 | loss: 12.7505512CurrentTrain: epoch  0, batch    14 | loss: 11.0455074CurrentTrain: epoch  0, batch    15 | loss: 11.3455276CurrentTrain: epoch  0, batch    16 | loss: 14.0320377CurrentTrain: epoch  0, batch    17 | loss: 10.1727772CurrentTrain: epoch  0, batch    18 | loss: 9.5896416CurrentTrain: epoch  0, batch    19 | loss: 10.9111252CurrentTrain: epoch  0, batch    20 | loss: 9.8548985CurrentTrain: epoch  0, batch    21 | loss: 8.0690746CurrentTrain: epoch  0, batch    22 | loss: 8.9217072CurrentTrain: epoch  0, batch    23 | loss: 9.2941647CurrentTrain: epoch  0, batch    24 | loss: 7.8028536CurrentTrain: epoch  0, batch    25 | loss: 9.5560732CurrentTrain: epoch  0, batch    26 | loss: 8.9968414CurrentTrain: epoch  0, batch    27 | loss: 7.7091494CurrentTrain: epoch  0, batch    28 | loss: 7.8529768CurrentTrain: epoch  0, batch    29 | loss: 7.5081334CurrentTrain: epoch  0, batch    30 | loss: 7.0176225CurrentTrain: epoch  0, batch    31 | loss: 6.8321681CurrentTrain: epoch  0, batch    32 | loss: 6.8562994CurrentTrain: epoch  0, batch    33 | loss: 6.1265521CurrentTrain: epoch  0, batch    34 | loss: 6.2594061CurrentTrain: epoch  0, batch    35 | loss: 7.2304029CurrentTrain: epoch  0, batch    36 | loss: 6.1517148CurrentTrain: epoch  0, batch    37 | loss: 9.7112122CurrentTrain: epoch  1, batch     0 | loss: 6.4914379CurrentTrain: epoch  1, batch     1 | loss: 6.1995492CurrentTrain: epoch  1, batch     2 | loss: 6.6214848CurrentTrain: epoch  1, batch     3 | loss: 6.9622369CurrentTrain: epoch  1, batch     4 | loss: 8.7284603CurrentTrain: epoch  1, batch     5 | loss: 6.6206608CurrentTrain: epoch  1, batch     6 | loss: 8.0635796CurrentTrain: epoch  1, batch     7 | loss: 6.3616028CurrentTrain: epoch  1, batch     8 | loss: 7.3066473CurrentTrain: epoch  1, batch     9 | loss: 6.9079409CurrentTrain: epoch  1, batch    10 | loss: 6.7147851CurrentTrain: epoch  1, batch    11 | loss: 6.8014336CurrentTrain: epoch  1, batch    12 | loss: 6.2580538CurrentTrain: epoch  1, batch    13 | loss: 7.0370359CurrentTrain: epoch  1, batch    14 | loss: 6.7035985CurrentTrain: epoch  1, batch    15 | loss: 6.4549837CurrentTrain: epoch  1, batch    16 | loss: 6.8191795CurrentTrain: epoch  1, batch    17 | loss: 6.7693143CurrentTrain: epoch  1, batch    18 | loss: 7.1770916CurrentTrain: epoch  1, batch    19 | loss: 7.6374216CurrentTrain: epoch  1, batch    20 | loss: 6.7982063CurrentTrain: epoch  1, batch    21 | loss: 6.8259654CurrentTrain: epoch  1, batch    22 | loss: 6.2816744CurrentTrain: epoch  1, batch    23 | loss: 6.2793226CurrentTrain: epoch  1, batch    24 | loss: 6.8630838CurrentTrain: epoch  1, batch    25 | loss: 7.1041083CurrentTrain: epoch  1, batch    26 | loss: 6.0469584CurrentTrain: epoch  1, batch    27 | loss: 6.4026666CurrentTrain: epoch  1, batch    28 | loss: 6.8115172CurrentTrain: epoch  1, batch    29 | loss: 6.3407407CurrentTrain: epoch  1, batch    30 | loss: 6.0632987CurrentTrain: epoch  1, batch    31 | loss: 7.5926766CurrentTrain: epoch  1, batch    32 | loss: 6.6158657CurrentTrain: epoch  1, batch    33 | loss: 5.9614010CurrentTrain: epoch  1, batch    34 | loss: 7.1366525CurrentTrain: epoch  1, batch    35 | loss: 6.2870502CurrentTrain: epoch  1, batch    36 | loss: 6.0355954CurrentTrain: epoch  1, batch    37 | loss: 7.5628076CurrentTrain: epoch  2, batch     0 | loss: 6.0232601CurrentTrain: epoch  2, batch     1 | loss: 6.5216227CurrentTrain: epoch  2, batch     2 | loss: 6.5175128CurrentTrain: epoch  2, batch     3 | loss: 6.2616000CurrentTrain: epoch  2, batch     4 | loss: 6.2164044CurrentTrain: epoch  2, batch     5 | loss: 5.8921442CurrentTrain: epoch  2, batch     6 | loss: 6.4882498CurrentTrain: epoch  2, batch     7 | loss: 6.0243001CurrentTrain: epoch  2, batch     8 | loss: 5.9304600CurrentTrain: epoch  2, batch     9 | loss: 6.3815346CurrentTrain: epoch  2, batch    10 | loss: 6.5906043CurrentTrain: epoch  2, batch    11 | loss: 6.0758553CurrentTrain: epoch  2, batch    12 | loss: 5.8395915CurrentTrain: epoch  2, batch    13 | loss: 6.9333067CurrentTrain: epoch  2, batch    14 | loss: 6.5410371CurrentTrain: epoch  2, batch    15 | loss: 6.1846766CurrentTrain: epoch  2, batch    16 | loss: 5.8566451CurrentTrain: epoch  2, batch    17 | loss: 5.8599062CurrentTrain: epoch  2, batch    18 | loss: 7.1365290CurrentTrain: epoch  2, batch    19 | loss: 6.0825195CurrentTrain: epoch  2, batch    20 | loss: 6.1883783CurrentTrain: epoch  2, batch    21 | loss: 6.0162010CurrentTrain: epoch  2, batch    22 | loss: 6.5179572CurrentTrain: epoch  2, batch    23 | loss: 6.9535465CurrentTrain: epoch  2, batch    24 | loss: 6.0636058CurrentTrain: epoch  2, batch    25 | loss: 5.9014711CurrentTrain: epoch  2, batch    26 | loss: 5.9016948CurrentTrain: epoch  2, batch    27 | loss: 6.2216139CurrentTrain: epoch  2, batch    28 | loss: 6.7571683CurrentTrain: epoch  2, batch    29 | loss: 6.2275739CurrentTrain: epoch  2, batch    30 | loss: 6.3384080CurrentTrain: epoch  2, batch    31 | loss: 6.4421787CurrentTrain: epoch  2, batch    32 | loss: 6.3120241CurrentTrain: epoch  2, batch    33 | loss: 6.3786702CurrentTrain: epoch  2, batch    34 | loss: 5.8631639CurrentTrain: epoch  2, batch    35 | loss: 6.9534101CurrentTrain: epoch  2, batch    36 | loss: 7.2171278CurrentTrain: epoch  2, batch    37 | loss: 7.9929562CurrentTrain: epoch  3, batch     0 | loss: 6.9362597CurrentTrain: epoch  3, batch     1 | loss: 5.7640605CurrentTrain: epoch  3, batch     2 | loss: 6.1040373CurrentTrain: epoch  3, batch     3 | loss: 6.3212786CurrentTrain: epoch  3, batch     4 | loss: 5.9831734CurrentTrain: epoch  3, batch     5 | loss: 5.8225422CurrentTrain: epoch  3, batch     6 | loss: 6.0278792CurrentTrain: epoch  3, batch     7 | loss: 6.4238381CurrentTrain: epoch  3, batch     8 | loss: 6.0210943CurrentTrain: epoch  3, batch     9 | loss: 7.1568909CurrentTrain: epoch  3, batch    10 | loss: 6.8068538CurrentTrain: epoch  3, batch    11 | loss: 5.7562914CurrentTrain: epoch  3, batch    12 | loss: 6.9682903CurrentTrain: epoch  3, batch    13 | loss: 5.7543344CurrentTrain: epoch  3, batch    14 | loss: 5.8883662CurrentTrain: epoch  3, batch    15 | loss: 7.8046446CurrentTrain: epoch  3, batch    16 | loss: 5.9589353CurrentTrain: epoch  3, batch    17 | loss: 6.8539605CurrentTrain: epoch  3, batch    18 | loss: 6.0052123CurrentTrain: epoch  3, batch    19 | loss: 5.8182578CurrentTrain: epoch  3, batch    20 | loss: 5.8900466CurrentTrain: epoch  3, batch    21 | loss: 5.7660375CurrentTrain: epoch  3, batch    22 | loss: 6.7794533CurrentTrain: epoch  3, batch    23 | loss: 5.7507210CurrentTrain: epoch  3, batch    24 | loss: 6.1171236CurrentTrain: epoch  3, batch    25 | loss: 6.1630521CurrentTrain: epoch  3, batch    26 | loss: 5.9411306CurrentTrain: epoch  3, batch    27 | loss: 6.7169948CurrentTrain: epoch  3, batch    28 | loss: 5.9234905CurrentTrain: epoch  3, batch    29 | loss: 5.7750397CurrentTrain: epoch  3, batch    30 | loss: 6.4992061CurrentTrain: epoch  3, batch    31 | loss: 6.4724808CurrentTrain: epoch  3, batch    32 | loss: 5.9005818CurrentTrain: epoch  3, batch    33 | loss: 5.7891998CurrentTrain: epoch  3, batch    34 | loss: 5.8288126CurrentTrain: epoch  3, batch    35 | loss: 5.8706012CurrentTrain: epoch  3, batch    36 | loss: 6.1675816CurrentTrain: epoch  3, batch    37 | loss: 5.8035898CurrentTrain: epoch  4, batch     0 | loss: 5.9923706CurrentTrain: epoch  4, batch     1 | loss: 5.7014003CurrentTrain: epoch  4, batch     2 | loss: 6.1675472CurrentTrain: epoch  4, batch     3 | loss: 5.6390624CurrentTrain: epoch  4, batch     4 | loss: 6.2218151CurrentTrain: epoch  4, batch     5 | loss: 7.1350012CurrentTrain: epoch  4, batch     6 | loss: 5.7453747CurrentTrain: epoch  4, batch     7 | loss: 5.7695518CurrentTrain: epoch  4, batch     8 | loss: 5.7144437CurrentTrain: epoch  4, batch     9 | loss: 6.2582784CurrentTrain: epoch  4, batch    10 | loss: 5.9819808CurrentTrain: epoch  4, batch    11 | loss: 5.8698702CurrentTrain: epoch  4, batch    12 | loss: 6.0325727CurrentTrain: epoch  4, batch    13 | loss: 5.7028103CurrentTrain: epoch  4, batch    14 | loss: 7.1285248CurrentTrain: epoch  4, batch    15 | loss: 6.0909886CurrentTrain: epoch  4, batch    16 | loss: 5.6335168CurrentTrain: epoch  4, batch    17 | loss: 5.6888609CurrentTrain: epoch  4, batch    18 | loss: 6.0205598CurrentTrain: epoch  4, batch    19 | loss: 5.6073170CurrentTrain: epoch  4, batch    20 | loss: 5.9696078CurrentTrain: epoch  4, batch    21 | loss: 5.5983500CurrentTrain: epoch  4, batch    22 | loss: 5.6457005CurrentTrain: epoch  4, batch    23 | loss: 5.5794406CurrentTrain: epoch  4, batch    24 | loss: 6.2281685CurrentTrain: epoch  4, batch    25 | loss: 6.1802378CurrentTrain: epoch  4, batch    26 | loss: 5.5459433CurrentTrain: epoch  4, batch    27 | loss: 5.6580353CurrentTrain: epoch  4, batch    28 | loss: 6.2193747CurrentTrain: epoch  4, batch    29 | loss: 5.5968294CurrentTrain: epoch  4, batch    30 | loss: 5.7132983CurrentTrain: epoch  4, batch    31 | loss: 5.7470083CurrentTrain: epoch  4, batch    32 | loss: 5.6156182CurrentTrain: epoch  4, batch    33 | loss: 5.6163516CurrentTrain: epoch  4, batch    34 | loss: 6.5380239CurrentTrain: epoch  4, batch    35 | loss: 5.8902683CurrentTrain: epoch  4, batch    36 | loss: 6.1161308CurrentTrain: epoch  4, batch    37 | loss: 5.4483533CurrentTrain: epoch  5, batch     0 | loss: 5.6678281CurrentTrain: epoch  5, batch     1 | loss: 5.6440048CurrentTrain: epoch  5, batch     2 | loss: 7.0262871CurrentTrain: epoch  5, batch     3 | loss: 5.5686483CurrentTrain: epoch  5, batch     4 | loss: 5.4336743CurrentTrain: epoch  5, batch     5 | loss: 5.5178580CurrentTrain: epoch  5, batch     6 | loss: 6.4584150CurrentTrain: epoch  5, batch     7 | loss: 5.6107793CurrentTrain: epoch  5, batch     8 | loss: 5.5347576CurrentTrain: epoch  5, batch     9 | loss: 5.7432175CurrentTrain: epoch  5, batch    10 | loss: 5.4574523CurrentTrain: epoch  5, batch    11 | loss: 5.4755440CurrentTrain: epoch  5, batch    12 | loss: 6.9683723CurrentTrain: epoch  5, batch    13 | loss: 5.3876162CurrentTrain: epoch  5, batch    14 | loss: 6.2451363CurrentTrain: epoch  5, batch    15 | loss: 5.5514736CurrentTrain: epoch  5, batch    16 | loss: 5.4140267CurrentTrain: epoch  5, batch    17 | loss: 5.9707265CurrentTrain: epoch  5, batch    18 | loss: 6.5844908CurrentTrain: epoch  5, batch    19 | loss: 5.4989700CurrentTrain: epoch  5, batch    20 | loss: 5.4628358CurrentTrain: epoch  5, batch    21 | loss: 5.6407456CurrentTrain: epoch  5, batch    22 | loss: 5.6195679CurrentTrain: epoch  5, batch    23 | loss: 5.4539480CurrentTrain: epoch  5, batch    24 | loss: 5.4488549CurrentTrain: epoch  5, batch    25 | loss: 5.8137388CurrentTrain: epoch  5, batch    26 | loss: 5.7469077CurrentTrain: epoch  5, batch    27 | loss: 5.5200276CurrentTrain: epoch  5, batch    28 | loss: 5.5924797CurrentTrain: epoch  5, batch    29 | loss: 5.6945210CurrentTrain: epoch  5, batch    30 | loss: 5.4503641CurrentTrain: epoch  5, batch    31 | loss: 5.5383129CurrentTrain: epoch  5, batch    32 | loss: 6.7856193CurrentTrain: epoch  5, batch    33 | loss: 5.3743048CurrentTrain: epoch  5, batch    34 | loss: 5.2956996CurrentTrain: epoch  5, batch    35 | loss: 5.3103518CurrentTrain: epoch  5, batch    36 | loss: 5.3743014CurrentTrain: epoch  5, batch    37 | loss: 5.1726522CurrentTrain: epoch  6, batch     0 | loss: 5.1546941CurrentTrain: epoch  6, batch     1 | loss: 5.2471819CurrentTrain: epoch  6, batch     2 | loss: 5.2838635CurrentTrain: epoch  6, batch     3 | loss: 5.2211337CurrentTrain: epoch  6, batch     4 | loss: 5.7656746CurrentTrain: epoch  6, batch     5 | loss: 5.2188439CurrentTrain: epoch  6, batch     6 | loss: 5.2950559CurrentTrain: epoch  6, batch     7 | loss: 5.1116362CurrentTrain: epoch  6, batch     8 | loss: 5.3747568CurrentTrain: epoch  6, batch     9 | loss: 5.7260346CurrentTrain: epoch  6, batch    10 | loss: 5.9315977CurrentTrain: epoch  6, batch    11 | loss: 5.1864643CurrentTrain: epoch  6, batch    12 | loss: 5.2163358CurrentTrain: epoch  6, batch    13 | loss: 5.3395095CurrentTrain: epoch  6, batch    14 | loss: 5.2911310CurrentTrain: epoch  6, batch    15 | loss: 5.2212682CurrentTrain: epoch  6, batch    16 | loss: 5.0731497CurrentTrain: epoch  6, batch    17 | loss: 5.7679310CurrentTrain: epoch  6, batch    18 | loss: 5.1865854CurrentTrain: epoch  6, batch    19 | loss: 5.3075132CurrentTrain: epoch  6, batch    20 | loss: 6.9341388CurrentTrain: epoch  6, batch    21 | loss: 6.0986285CurrentTrain: epoch  6, batch    22 | loss: 5.2471299CurrentTrain: epoch  6, batch    23 | loss: 5.3006535CurrentTrain: epoch  6, batch    24 | loss: 5.3750443CurrentTrain: epoch  6, batch    25 | loss: 6.3861942CurrentTrain: epoch  6, batch    26 | loss: 5.4946952CurrentTrain: epoch  6, batch    27 | loss: 5.9687462CurrentTrain: epoch  6, batch    28 | loss: 5.2740841CurrentTrain: epoch  6, batch    29 | loss: 5.2038732CurrentTrain: epoch  6, batch    30 | loss: 5.1795430CurrentTrain: epoch  6, batch    31 | loss: 5.2859445CurrentTrain: epoch  6, batch    32 | loss: 5.1865993CurrentTrain: epoch  6, batch    33 | loss: 5.5157986CurrentTrain: epoch  6, batch    34 | loss: 5.1050854CurrentTrain: epoch  6, batch    35 | loss: 5.1636062CurrentTrain: epoch  6, batch    36 | loss: 6.2740860CurrentTrain: epoch  6, batch    37 | loss: 5.1564503CurrentTrain: epoch  7, batch     0 | loss: 6.2309666CurrentTrain: epoch  7, batch     1 | loss: 5.1685524CurrentTrain: epoch  7, batch     2 | loss: 5.2090464CurrentTrain: epoch  7, batch     3 | loss: 5.7461519CurrentTrain: epoch  7, batch     4 | loss: 5.3128939CurrentTrain: epoch  7, batch     5 | loss: 5.1362686CurrentTrain: epoch  7, batch     6 | loss: 5.0690861CurrentTrain: epoch  7, batch     7 | loss: 4.9851747CurrentTrain: epoch  7, batch     8 | loss: 5.1052866CurrentTrain: epoch  7, batch     9 | loss: 5.4696269CurrentTrain: epoch  7, batch    10 | loss: 5.0038567CurrentTrain: epoch  7, batch    11 | loss: 4.9912672CurrentTrain: epoch  7, batch    12 | loss: 4.9774046CurrentTrain: epoch  7, batch    13 | loss: 5.3457804CurrentTrain: epoch  7, batch    14 | loss: 6.3870473CurrentTrain: epoch  7, batch    15 | loss: 4.8920736CurrentTrain: epoch  7, batch    16 | loss: 5.6874533CurrentTrain: epoch  7, batch    17 | loss: 6.3782206CurrentTrain: epoch  7, batch    18 | loss: 5.0137620CurrentTrain: epoch  7, batch    19 | loss: 5.5283713CurrentTrain: epoch  7, batch    20 | loss: 5.1199822CurrentTrain: epoch  7, batch    21 | loss: 5.7262125CurrentTrain: epoch  7, batch    22 | loss: 5.1321507CurrentTrain: epoch  7, batch    23 | loss: 5.2040825CurrentTrain: epoch  7, batch    24 | loss: 5.0164518CurrentTrain: epoch  7, batch    25 | loss: 5.6394639CurrentTrain: epoch  7, batch    26 | loss: 5.9746304CurrentTrain: epoch  7, batch    27 | loss: 5.0455775CurrentTrain: epoch  7, batch    28 | loss: 5.0551219CurrentTrain: epoch  7, batch    29 | loss: 5.6485915CurrentTrain: epoch  7, batch    30 | loss: 5.3268094CurrentTrain: epoch  7, batch    31 | loss: 5.0804138CurrentTrain: epoch  7, batch    32 | loss: 5.0625982CurrentTrain: epoch  7, batch    33 | loss: 5.1958942CurrentTrain: epoch  7, batch    34 | loss: 5.9017067CurrentTrain: epoch  7, batch    35 | loss: 6.0291224CurrentTrain: epoch  7, batch    36 | loss: 5.0788488CurrentTrain: epoch  7, batch    37 | loss: 5.2104483[0 0 0 0 0 0]
CurrentTrain: epoch  8, batch     0 | loss: 7.8062048CurrentTrain: epoch  8, batch     1 | loss: 8.0101042CurrentTrain: epoch  8, batch     2 | loss: 7.7058487CurrentTrain: epoch  8, batch     3 | loss: 7.6034794CurrentTrain: epoch  8, batch     4 | loss: 7.9069519CurrentTrain: epoch  8, batch     5 | loss: 8.3979959CurrentTrain: epoch  8, batch     6 | loss: 7.8132772CurrentTrain: epoch  8, batch     7 | loss: 7.3068285CurrentTrain: epoch  8, batch     8 | loss: 7.6739650CurrentTrain: epoch  8, batch     9 | loss: 7.4181089CurrentTrain: epoch  8, batch    10 | loss: 9.8789482CurrentTrain: epoch  8, batch    11 | loss: 8.3342896CurrentTrain: epoch  8, batch    12 | loss: 7.3654609CurrentTrain: epoch  8, batch    13 | loss: 8.2252111CurrentTrain: epoch  8, batch    14 | loss: 7.8348522CurrentTrain: epoch  8, batch    15 | loss: 7.6571274CurrentTrain: epoch  8, batch    16 | loss: 9.4447823CurrentTrain: epoch  8, batch    17 | loss: 7.4830914CurrentTrain: epoch  8, batch    18 | loss: 7.4447083CurrentTrain: epoch  8, batch    19 | loss: 8.1303234CurrentTrain: epoch  8, batch    20 | loss: 7.2117872CurrentTrain: epoch  8, batch    21 | loss: 7.4427876CurrentTrain: epoch  8, batch    22 | loss: 7.4113736CurrentTrain: epoch  8, batch    23 | loss: 7.1434731CurrentTrain: epoch  8, batch    24 | loss: 7.5308599CurrentTrain: epoch  8, batch    25 | loss: 8.4455833CurrentTrain: epoch  8, batch    26 | loss: 8.1994934CurrentTrain: epoch  8, batch    27 | loss: 7.4616957CurrentTrain: epoch  8, batch    28 | loss: 7.3156815CurrentTrain: epoch  8, batch    29 | loss: 7.1649327CurrentTrain: epoch  8, batch    30 | loss: 7.2361264CurrentTrain: epoch  8, batch    31 | loss: 7.2794104CurrentTrain: epoch  8, batch    32 | loss: 7.2696609CurrentTrain: epoch  8, batch    33 | loss: 7.8807096CurrentTrain: epoch  8, batch    34 | loss: 7.4331007CurrentTrain: epoch  8, batch    35 | loss: 7.2834759CurrentTrain: epoch  8, batch    36 | loss: 9.6492119CurrentTrain: epoch  8, batch    37 | loss: 8.4176264CurrentTrain: epoch  9, batch     0 | loss: 7.2189679CurrentTrain: epoch  9, batch     1 | loss: 7.0651278CurrentTrain: epoch  9, batch     2 | loss: 7.1748652CurrentTrain: epoch  9, batch     3 | loss: 7.2027149CurrentTrain: epoch  9, batch     4 | loss: 8.0861626CurrentTrain: epoch  9, batch     5 | loss: 6.9718895CurrentTrain: epoch  9, batch     6 | loss: 7.5087624CurrentTrain: epoch  9, batch     7 | loss: 10.2563238CurrentTrain: epoch  9, batch     8 | loss: 6.8708282CurrentTrain: epoch  9, batch     9 | loss: 6.9641175CurrentTrain: epoch  9, batch    10 | loss: 7.1136441CurrentTrain: epoch  9, batch    11 | loss: 6.7642937CurrentTrain: epoch  9, batch    12 | loss: 6.9925594CurrentTrain: epoch  9, batch    13 | loss: 6.9748869CurrentTrain: epoch  9, batch    14 | loss: 6.5739822CurrentTrain: epoch  9, batch    15 | loss: 6.8786168CurrentTrain: epoch  9, batch    16 | loss: 7.4311810CurrentTrain: epoch  9, batch    17 | loss: 7.2909579CurrentTrain: epoch  9, batch    18 | loss: 6.6171331CurrentTrain: epoch  9, batch    19 | loss: 7.7254238CurrentTrain: epoch  9, batch    20 | loss: 7.1378069CurrentTrain: epoch  9, batch    21 | loss: 7.7354660CurrentTrain: epoch  9, batch    22 | loss: 6.8799753CurrentTrain: epoch  9, batch    23 | loss: 6.9613523CurrentTrain: epoch  9, batch    24 | loss: 14.2500057CurrentTrain: epoch  9, batch    25 | loss: 6.9238539CurrentTrain: epoch  9, batch    26 | loss: 7.4942260CurrentTrain: epoch  9, batch    27 | loss: 6.6345568CurrentTrain: epoch  9, batch    28 | loss: 6.3778353CurrentTrain: epoch  9, batch    29 | loss: 6.7094212CurrentTrain: epoch  9, batch    30 | loss: 6.7958403CurrentTrain: epoch  9, batch    31 | loss: 7.4884367CurrentTrain: epoch  9, batch    32 | loss: 7.5497031CurrentTrain: epoch  9, batch    33 | loss: 6.8783598CurrentTrain: epoch  9, batch    34 | loss: 6.9583139CurrentTrain: epoch  9, batch    35 | loss: 7.0650921CurrentTrain: epoch  9, batch    36 | loss: 6.5616398CurrentTrain: epoch  9, batch    37 | loss: 6.7496219
